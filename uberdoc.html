<!DOCTYPE html>
<html><head><meta charset="utf-8" content="text/html" http-equiv="Content-Type" /><meta content="Clojure API for variation data, built on GATK" name="description" /><style type="text/css">/**
 * SyntaxHighlighter
 * http://alexgorbatchev.com/SyntaxHighlighter
 *
 * SyntaxHighlighter is donationware. If you are using it, please donate.
 * http://alexgorbatchev.com/SyntaxHighlighter/donate.html
 *
 * @version
 * 3.0.83 (July 02 2010)
 * 
 * @copyright
 * Copyright (C) 2004-2010 Alex Gorbatchev.
 *
 * @license
 * Dual licensed under the MIT and GPL licenses.
 */
.syntaxhighlighter a,
.syntaxhighlighter div,
.syntaxhighlighter code,
.syntaxhighlighter table,
.syntaxhighlighter table td,
.syntaxhighlighter table tr,
.syntaxhighlighter table tbody,
.syntaxhighlighter table thead,
.syntaxhighlighter table caption,
.syntaxhighlighter textarea {
  -moz-border-radius: 0 0 0 0 !important;
  -webkit-border-radius: 0 0 0 0 !important;
  background: none !important;
  border: 0 !important;
  bottom: auto !important;
  float: none !important;
  height: auto !important;
  left: auto !important;
  line-height: 1.1em !important;
/*  margin: 0 !important; */
  outline: 0 !important;
  overflow: visible !important;
  padding: 0 !important;
  position: static !important;
  right: auto !important;
  text-align: left !important;
  top: auto !important;
  vertical-align: baseline !important;
  width: auto !important;
  box-sizing: content-box !important;
  font-family: "Consolas", "Bitstream Vera Sans Mono", "Courier New", Courier, monospace !important;
  font-weight: normal !important;
  font-style: normal !important;
  min-height: inherit !important;
  min-height: auto !important;
}

.syntaxhighlighter {
/*  width: 100% !important; */
  margin: 1em 0 1em 0 !important;
  position: relative !important;
  overflow: auto !important;
}
.syntaxhighlighter.source {
  overflow: hidden !important;
}
.syntaxhighlighter .bold {
  font-weight: bold !important;
}
.syntaxhighlighter .italic {
  font-style: italic !important;
}
.syntaxhighlighter .line {
  white-space: pre !important;
}
.syntaxhighlighter table {
/*    width: 100% !important;*/
}
.syntaxhighlighter table caption {
  text-align: left !important;
  padding: .5em 0 0.5em 1em !important;
}
.syntaxhighlighter table td.code {
  width: 100% !important;
}
.syntaxhighlighter table td.code .container {
  position: relative !important;
}
.syntaxhighlighter table td.code .container textarea {
  box-sizing: border-box !important;
  position: absolute !important;
  left: 0 !important;
  top: 0 !important;
  width: 100% !important;
  height: 100% !important;
  border: none !important;
  background: white !important;
  padding-left: 1em !important;
  overflow: hidden !important;
  white-space: pre !important;
}
.syntaxhighlighter table td.gutter .line {
  text-align: right !important;
  padding: 0 0.5em 0 1em !important;
}
.syntaxhighlighter table td.code .line {
  padding: 0 1em !important;
}
.syntaxhighlighter.nogutter td.code .container textarea, .syntaxhighlighter.nogutter td.code .line {
  padding-left: 0em !important;
}
.syntaxhighlighter.show {
  display: block !important;
}
.syntaxhighlighter.collapsed table {
  display: none !important;
}
.syntaxhighlighter.collapsed .toolbar {
    display: none;
/*  padding: 0.1em 0.8em 0em 0.8em !important;
  font-size: 1em !important;
  position: static !important;
  width: auto !important;
  height: auto !important;*/
}
.syntaxhighlighter.collapsed .toolbar span {
  display: inline !important;
  margin-right: 1em !important;
}
.syntaxhighlighter.collapsed .toolbar span a {
  padding: 0 !important;
  display: none !important;
}
.syntaxhighlighter.collapsed .toolbar span a.expandSource {
  display: inline !important;
}
.syntaxhighlighter .toolbar {
    display: none;
/*  position: absolute !important;
  right: 1px !important;
  top: 1px !important;
  width: 11px !important;
  height: 11px !important;
  font-size: 10px !important;
  z-index: 10 !important;*/
}
.syntaxhighlighter .toolbar span.title {
  display: inline !important;
}
.syntaxhighlighter .toolbar a {
  display: block !important;
  text-align: center !important;
  text-decoration: none !important;
  padding-top: 1px !important;
}
.syntaxhighlighter .toolbar a.expandSource {
  display: none !important;
}
.syntaxhighlighter.ie {
  font-size: .9em !important;
  padding: 1px 0 1px 0 !important;
}
.syntaxhighlighter.ie .toolbar {
  line-height: 8px !important;
}
.syntaxhighlighter.ie .toolbar a {
  padding-top: 0px !important;
}
.syntaxhighlighter.printing .line.alt1 .content,
.syntaxhighlighter.printing .line.alt2 .content,
.syntaxhighlighter.printing .line.highlighted .number,
.syntaxhighlighter.printing .line.highlighted.alt1 .content,
.syntaxhighlighter.printing .line.highlighted.alt2 .content {
  background: none !important;
}
.syntaxhighlighter.printing .line .number {
  color: #bbbbbb !important;
}
.syntaxhighlighter.printing .line .content {
  color: black !important;
}
.syntaxhighlighter.printing .toolbar {
  display: none !important;
}
.syntaxhighlighter.printing a {
  text-decoration: none !important;
}
.syntaxhighlighter.printing .plain, .syntaxhighlighter.printing .plain a {
  color: black !important;
}
.syntaxhighlighter.printing .comments, .syntaxhighlighter.printing .comments a {
  color: #008200 !important;
}
.syntaxhighlighter.printing .string, .syntaxhighlighter.printing .string a {
  color: blue !important;
}
.syntaxhighlighter.printing .keyword {
  color: #006699 !important;
  font-weight: bold !important;
}
.syntaxhighlighter.printing .preprocessor {
  color: gray !important;
}
.syntaxhighlighter.printing .variable {
  color: #aa7700 !important;
}
.syntaxhighlighter.printing .value {
  color: #009900 !important;
}
.syntaxhighlighter.printing .functions {
  color: #ff1493 !important;
}
.syntaxhighlighter.printing .constants {
  color: #0066cc !important;
}
.syntaxhighlighter.printing .script {
  font-weight: bold !important;
}
.syntaxhighlighter.printing .color1, .syntaxhighlighter.printing .color1 a {
  color: gray !important;
}
.syntaxhighlighter.printing .color2, .syntaxhighlighter.printing .color2 a {
  color: #ff1493 !important;
}
.syntaxhighlighter.printing .color3, .syntaxhighlighter.printing .color3 a {
  color: red !important;
}
.syntaxhighlighter.printing .break, .syntaxhighlighter.printing .break a {
  color: black !important;
}
</style><style type="text/css">.syntaxhighlighter{overflow:hidden !important;}</style><style type="text/css">/**
 * http://alexgorbatchev.com/SyntaxHighlighter/donate.html
 *
 * @version
 * 3.0.83 (July 02 2010)
 * 
 * @copyright
 * Copyright (C) 2004-2010 Alex Gorbatchev.
 *
 * @license
 * Dual licensed under the MIT and GPL licenses.
 */
.syntaxhighlighter {
  background-color: transparent !important;
}
.syntaxhighlighter .line.alt1 {
  background-color: transparent !important;
}
.syntaxhighlighter .line.alt2 {
  background-color: transparent !important;
}
.syntaxhighlighter .line.highlighted.alt1, .syntaxhighlighter .line.highlighted.alt2 {
  background-color: #c3defe !important;
}
.syntaxhighlighter .line.highlighted.number {
  color: white !important;
}
.syntaxhighlighter table caption {
  color: black !important;
}
.syntaxhighlighter .gutter {
  color: #787878 !important;
}
.syntaxhighlighter .gutter .line {
  border-right: 3px solid #d4d0c8 !important;
}
.syntaxhighlighter .gutter .line.highlighted {
  background-color: #d4d0c8 !important;
  color: white !important;
}
.syntaxhighlighter.printing .line .content {
  border: none !important;
}
.syntaxhighlighter.collapsed {
  overflow: visible !important;
}
.syntaxhighlighter.collapsed .toolbar {
  color: #3f5fbf !important;
  background: white !important;
  border: 1px solid #d4d0c8 !important;
}
.syntaxhighlighter.collapsed .toolbar a {
  color: #3f5fbf !important;
}
.syntaxhighlighter.collapsed .toolbar a:hover {
  color: #aa7700 !important;
}
.syntaxhighlighter .toolbar {
  color: #a0a0a0 !important;
  background: #d4d0c8 !important;
  border: none !important;
}
.syntaxhighlighter .toolbar a {
  color: #a0a0a0 !important;
}
.syntaxhighlighter .toolbar a:hover {
  color: red !important;
}
.syntaxhighlighter .plain, .syntaxhighlighter .plain a {
  color: black !important;
}
.syntaxhighlighter .comments, .syntaxhighlighter .comments a {
  color: #3f5fbf !important;
}
.syntaxhighlighter .string, .syntaxhighlighter .string a {
  color: #2a00ff !important;
}
.syntaxhighlighter .keyword {
  color: #7f0055 !important;
}
.syntaxhighlighter .preprocessor {
  color: #646464 !important;
}
.syntaxhighlighter .variable {
  color: #aa7700 !important;
}
.syntaxhighlighter .value {
  color: #009900 !important;
}
.syntaxhighlighter .functions {
  color: #ff1493 !important;
}
.syntaxhighlighter .constants {
  color: #0066cc !important;
}
.syntaxhighlighter .script {
  font-weight: bold !important;
  color: #7f0055 !important;
  background-color: none !important;
}
.syntaxhighlighter .color1, .syntaxhighlighter .color1 a {
  color: gray !important;
}
.syntaxhighlighter .color2, .syntaxhighlighter .color2 a {
  color: #ff1493 !important;
}
.syntaxhighlighter .color3, .syntaxhighlighter .color3 a {
  color: red !important;
}

.syntaxhighlighter .xml .keyword {
  color: #3f7f7f !important;
  font-weight: normal !important;
}
.syntaxhighlighter .xml .color1, .syntaxhighlighter .xml .color1 a {
  color: #7f007f !important;
}
.syntaxhighlighter .xml .string {
  font-style: italic !important;
  color: #2a00ff !important;
}

.clojure.syntaxhighlighter .invalid { 
   background-color: #FAA !important;
}

.clojure.syntaxhighlighter .quoted {      
    font-style: italic !important;
}

.syntaxhighlighter .clojure.variable,
.syntaxhighlighter .clojure.symbol,
.syntaxhighlighter .clojure.value
{
    color: #006060 !important;
}

.syntaxhighlighter .clojure.string {
    color: #55B !important;
}

.syntaxhighlighter .clojure.functions {
    color: black !important;
}

.syntaxhighlighter .clojure.color1 {
    color: #666 !important;
}

.syntaxhighlighter .clojure.color3 {
    color: #900 !important;
}

.syntaxhighlighter .clojure.constants {
    color: #1A734D !important;
}

</style><style type="text/css">html{margin:0;padding:0;}h1{margin:0;padding:0;}h2{margin:0;padding:0;}h3{margin:0;padding:0;}h4{margin:0;padding:0;}a{color:#261A3B;}a:visited{color:#261A3B;}</style><style type="text/css">.header{margin-top:30px;}h1.project-name{display:inline;font-size:34px;}h2.project-version{display:inline;margin-left:10px;margin-top:0;font-size:18px;}.toc-link{margin-left:10px;color:#252519;font-size:12px;text-decoration:none;}.toc-link:hover{color:#5050A6;}.toc h1{margin:0;font-size:34px;}.docs-header{margin-bottom:25px;padding-bottom:10px;border-bottom:dotted #aaa 1px;}.toc h1{font-size:24px;}.toc{margin-bottom:40px;border-bottom:solid #bbb 1px;}.toc ul{padding-left:0px;margin-left:20px;margin-top:0;padding-top:0;}.toc li{padding-left:0;list-style-type:none;}.dependencies{}.dependencies table{border:none;width:99.99%;margin-left:20px;font-size:16px;}.dependencies td{padding-right:20px;;white-space:nowrap;}.dependencies .dotted{width:99%;}.dependencies .dotted hr{margin-bottom:-6px;noshade:noshade;border-top:none;color:transparent;border-left:none;border-bottom:dotted #bbb 1px;border-right:none;background-color:transparent;height:0;}.dependencies .dep-version{text-align:right;}.plugins ul{padding-left:0px;margin-left:20px;margin-top:0;padding-top:0;}.plugins li{padding-left:0;list-style-type:none;}.header p{margin-left:20px;}</style><style type="text/css">#floating-toc{position:fixed;text-align:right;overflow:hidden;top:10px;right:20px;height:20px;}#floating-toc li{margin:0;padding:0;list-style-type:none;}</style><style type="text/css">body{margin:0;padding:0;color:#252519;font-size:16px;background-color:#F5F5FF;font-family:'Palatino Linotype', 'Book Antiqua', Palatino, FreeSerif, serif;;}h1{margin-top:0;font-size:20px;}a.anchor{color:#252519;text-decoration:none;}a.anchor:hover{color:#5050A6;}table{margin-bottom:10px;border-bottom:solid #ddd 1px;;border-spacing:0;}code{display:inline;}p{margin-top:8px;}tr{margin:0px;padding:0px;}td.docs{border:none;margin:0px;padding-left:55px;width:410px;padding-right:20px;vertical-align:top;max-width:410px;background-color:#FFF;}td.docs pre{font-size:12px;overflow:hidden;}td.codes{border:none;margin:0px;padding-left:20px;width:55%;border-left:solid #E5E5EE 1px;font-size:10pt;vertical-align:top;overflow:hidden;background-color:#F5F5FF;}td.spacer{padding-bottom:40px;}pre code{display:block;padding:4px;}code{border:solid #DEDEDE 1px;padding-left:3px;padding-right:3px;font-size:14px;background-color:ghostWhite;}.syntaxhighlighter code{font-size:13px;}.footer{text-align:center;}</style><script type="text/javascript">/*!
 * jQuery JavaScript Library v1.4.4
 * http://jquery.com/
 *
 * Copyright 2010, John Resig
 * Dual licensed under the MIT or GPL Version 2 licenses.
 * http://jquery.org/license
 *
 * Includes Sizzle.js
 * http://sizzlejs.com/
 * Copyright 2010, The Dojo Foundation
 * Released under the MIT, BSD, and GPL Licenses.
 *
 * Date: Thu Nov 11 19:04:53 2010 -0500
 */
(function(E,B){function ka(a,b,d){if(d===B&&a.nodeType===1){d=a.getAttribute("data-"+b);if(typeof d==="string"){try{d=d==="true"?true:d==="false"?false:d==="null"?null:!c.isNaN(d)?parseFloat(d):Ja.test(d)?c.parseJSON(d):d}catch(e){}c.data(a,b,d)}else d=B}return d}function U(){return false}function ca(){return true}function la(a,b,d){d[0].type=a;return c.event.handle.apply(b,d)}function Ka(a){var b,d,e,f,h,l,k,o,x,r,A,C=[];f=[];h=c.data(this,this.nodeType?"events":"__events__");if(typeof h==="function")h=
h.events;if(!(a.liveFired===this||!h||!h.live||a.button&&a.type==="click")){if(a.namespace)A=RegExp("(^|\\.)"+a.namespace.split(".").join("\\.(?:.*\\.)?")+"(\\.|$)");a.liveFired=this;var J=h.live.slice(0);for(k=0;k<J.length;k++){h=J[k];h.origType.replace(X,"")===a.type?f.push(h.selector):J.splice(k--,1)}f=c(a.target).closest(f,a.currentTarget);o=0;for(x=f.length;o<x;o++){r=f[o];for(k=0;k<J.length;k++){h=J[k];if(r.selector===h.selector&&(!A||A.test(h.namespace))){l=r.elem;e=null;if(h.preType==="mouseenter"||
h.preType==="mouseleave"){a.type=h.preType;e=c(a.relatedTarget).closest(h.selector)[0]}if(!e||e!==l)C.push({elem:l,handleObj:h,level:r.level})}}}o=0;for(x=C.length;o<x;o++){f=C[o];if(d&&f.level>d)break;a.currentTarget=f.elem;a.data=f.handleObj.data;a.handleObj=f.handleObj;A=f.handleObj.origHandler.apply(f.elem,arguments);if(A===false||a.isPropagationStopped()){d=f.level;if(A===false)b=false;if(a.isImmediatePropagationStopped())break}}return b}}function Y(a,b){return(a&&a!=="*"?a+".":"")+b.replace(La,
"`").replace(Ma,"&")}function ma(a,b,d){if(c.isFunction(b))return c.grep(a,function(f,h){return!!b.call(f,h,f)===d});else if(b.nodeType)return c.grep(a,function(f){return f===b===d});else if(typeof b==="string"){var e=c.grep(a,function(f){return f.nodeType===1});if(Na.test(b))return c.filter(b,e,!d);else b=c.filter(b,e)}return c.grep(a,function(f){return c.inArray(f,b)>=0===d})}function na(a,b){var d=0;b.each(function(){if(this.nodeName===(a[d]&&a[d].nodeName)){var e=c.data(a[d++]),f=c.data(this,
e);if(e=e&&e.events){delete f.handle;f.events={};for(var h in e)for(var l in e[h])c.event.add(this,h,e[h][l],e[h][l].data)}}})}function Oa(a,b){b.src?c.ajax({url:b.src,async:false,dataType:"script"}):c.globalEval(b.text||b.textContent||b.innerHTML||"");b.parentNode&&b.parentNode.removeChild(b)}function oa(a,b,d){var e=b==="width"?a.offsetWidth:a.offsetHeight;if(d==="border")return e;c.each(b==="width"?Pa:Qa,function(){d||(e-=parseFloat(c.css(a,"padding"+this))||0);if(d==="margin")e+=parseFloat(c.css(a,
"margin"+this))||0;else e-=parseFloat(c.css(a,"border"+this+"Width"))||0});return e}function da(a,b,d,e){if(c.isArray(b)&&b.length)c.each(b,function(f,h){d||Ra.test(a)?e(a,h):da(a+"["+(typeof h==="object"||c.isArray(h)?f:"")+"]",h,d,e)});else if(!d&&b!=null&&typeof b==="object")c.isEmptyObject(b)?e(a,""):c.each(b,function(f,h){da(a+"["+f+"]",h,d,e)});else e(a,b)}function S(a,b){var d={};c.each(pa.concat.apply([],pa.slice(0,b)),function(){d[this]=a});return d}function qa(a){if(!ea[a]){var b=c("<"+
a+">").appendTo("body"),d=b.css("display");b.remove();if(d==="none"||d==="")d="block";ea[a]=d}return ea[a]}function fa(a){return c.isWindow(a)?a:a.nodeType===9?a.defaultView||a.parentWindow:false}var t=E.document,c=function(){function a(){if(!b.isReady){try{t.documentElement.doScroll("left")}catch(j){setTimeout(a,1);return}b.ready()}}var b=function(j,s){return new b.fn.init(j,s)},d=E.jQuery,e=E.$,f,h=/^(?:[^<]*(<[\w\W]+>)[^>]*$|#([\w\-]+)$)/,l=/\S/,k=/^\s+/,o=/\s+$/,x=/\W/,r=/\d/,A=/^<(\w+)\s*\/?>(?:<\/\1>)?$/,
C=/^[\],:{}\s]*$/,J=/\\(?:["\\\/bfnrt]|u[0-9a-fA-F]{4})/g,w=/"[^"\\\n\r]*"|true|false|null|-?\d+(?:\.\d*)?(?:[eE][+\-]?\d+)?/g,I=/(?:^|:|,)(?:\s*\[)+/g,L=/(webkit)[ \/]([\w.]+)/,g=/(opera)(?:.*version)?[ \/]([\w.]+)/,i=/(msie) ([\w.]+)/,n=/(mozilla)(?:.*? rv:([\w.]+))?/,m=navigator.userAgent,p=false,q=[],u,y=Object.prototype.toString,F=Object.prototype.hasOwnProperty,M=Array.prototype.push,N=Array.prototype.slice,O=String.prototype.trim,D=Array.prototype.indexOf,R={};b.fn=b.prototype={init:function(j,
s){var v,z,H;if(!j)return this;if(j.nodeType){this.context=this[0]=j;this.length=1;return this}if(j==="body"&&!s&&t.body){this.context=t;this[0]=t.body;this.selector="body";this.length=1;return this}if(typeof j==="string")if((v=h.exec(j))&&(v[1]||!s))if(v[1]){H=s?s.ownerDocument||s:t;if(z=A.exec(j))if(b.isPlainObject(s)){j=[t.createElement(z[1])];b.fn.attr.call(j,s,true)}else j=[H.createElement(z[1])];else{z=b.buildFragment([v[1]],[H]);j=(z.cacheable?z.fragment.cloneNode(true):z.fragment).childNodes}return b.merge(this,
j)}else{if((z=t.getElementById(v[2]))&&z.parentNode){if(z.id!==v[2])return f.find(j);this.length=1;this[0]=z}this.context=t;this.selector=j;return this}else if(!s&&!x.test(j)){this.selector=j;this.context=t;j=t.getElementsByTagName(j);return b.merge(this,j)}else return!s||s.jquery?(s||f).find(j):b(s).find(j);else if(b.isFunction(j))return f.ready(j);if(j.selector!==B){this.selector=j.selector;this.context=j.context}return b.makeArray(j,this)},selector:"",jquery:"1.4.4",length:0,size:function(){return this.length},
toArray:function(){return N.call(this,0)},get:function(j){return j==null?this.toArray():j<0?this.slice(j)[0]:this[j]},pushStack:function(j,s,v){var z=b();b.isArray(j)?M.apply(z,j):b.merge(z,j);z.prevObject=this;z.context=this.context;if(s==="find")z.selector=this.selector+(this.selector?" ":"")+v;else if(s)z.selector=this.selector+"."+s+"("+v+")";return z},each:function(j,s){return b.each(this,j,s)},ready:function(j){b.bindReady();if(b.isReady)j.call(t,b);else q&&q.push(j);return this},eq:function(j){return j===
-1?this.slice(j):this.slice(j,+j+1)},first:function(){return this.eq(0)},last:function(){return this.eq(-1)},slice:function(){return this.pushStack(N.apply(this,arguments),"slice",N.call(arguments).join(","))},map:function(j){return this.pushStack(b.map(this,function(s,v){return j.call(s,v,s)}))},end:function(){return this.prevObject||b(null)},push:M,sort:[].sort,splice:[].splice};b.fn.init.prototype=b.fn;b.extend=b.fn.extend=function(){var j,s,v,z,H,G=arguments[0]||{},K=1,Q=arguments.length,ga=false;
if(typeof G==="boolean"){ga=G;G=arguments[1]||{};K=2}if(typeof G!=="object"&&!b.isFunction(G))G={};if(Q===K){G=this;--K}for(;K<Q;K++)if((j=arguments[K])!=null)for(s in j){v=G[s];z=j[s];if(G!==z)if(ga&&z&&(b.isPlainObject(z)||(H=b.isArray(z)))){if(H){H=false;v=v&&b.isArray(v)?v:[]}else v=v&&b.isPlainObject(v)?v:{};G[s]=b.extend(ga,v,z)}else if(z!==B)G[s]=z}return G};b.extend({noConflict:function(j){E.$=e;if(j)E.jQuery=d;return b},isReady:false,readyWait:1,ready:function(j){j===true&&b.readyWait--;
if(!b.readyWait||j!==true&&!b.isReady){if(!t.body)return setTimeout(b.ready,1);b.isReady=true;if(!(j!==true&&--b.readyWait>0))if(q){var s=0,v=q;for(q=null;j=v[s++];)j.call(t,b);b.fn.trigger&&b(t).trigger("ready").unbind("ready")}}},bindReady:function(){if(!p){p=true;if(t.readyState==="complete")return setTimeout(b.ready,1);if(t.addEventListener){t.addEventListener("DOMContentLoaded",u,false);E.addEventListener("load",b.ready,false)}else if(t.attachEvent){t.attachEvent("onreadystatechange",u);E.attachEvent("onload",
b.ready);var j=false;try{j=E.frameElement==null}catch(s){}t.documentElement.doScroll&&j&&a()}}},isFunction:function(j){return b.type(j)==="function"},isArray:Array.isArray||function(j){return b.type(j)==="array"},isWindow:function(j){return j&&typeof j==="object"&&"setInterval"in j},isNaN:function(j){return j==null||!r.test(j)||isNaN(j)},type:function(j){return j==null?String(j):R[y.call(j)]||"object"},isPlainObject:function(j){if(!j||b.type(j)!=="object"||j.nodeType||b.isWindow(j))return false;if(j.constructor&&
!F.call(j,"constructor")&&!F.call(j.constructor.prototype,"isPrototypeOf"))return false;for(var s in j);return s===B||F.call(j,s)},isEmptyObject:function(j){for(var s in j)return false;return true},error:function(j){throw j;},parseJSON:function(j){if(typeof j!=="string"||!j)return null;j=b.trim(j);if(C.test(j.replace(J,"@").replace(w,"]").replace(I,"")))return E.JSON&&E.JSON.parse?E.JSON.parse(j):(new Function("return "+j))();else b.error("Invalid JSON: "+j)},noop:function(){},globalEval:function(j){if(j&&
l.test(j)){var s=t.getElementsByTagName("head")[0]||t.documentElement,v=t.createElement("script");v.type="text/javascript";if(b.support.scriptEval)v.appendChild(t.createTextNode(j));else v.text=j;s.insertBefore(v,s.firstChild);s.removeChild(v)}},nodeName:function(j,s){return j.nodeName&&j.nodeName.toUpperCase()===s.toUpperCase()},each:function(j,s,v){var z,H=0,G=j.length,K=G===B||b.isFunction(j);if(v)if(K)for(z in j){if(s.apply(j[z],v)===false)break}else for(;H<G;){if(s.apply(j[H++],v)===false)break}else if(K)for(z in j){if(s.call(j[z],
z,j[z])===false)break}else for(v=j[0];H<G&&s.call(v,H,v)!==false;v=j[++H]);return j},trim:O?function(j){return j==null?"":O.call(j)}:function(j){return j==null?"":j.toString().replace(k,"").replace(o,"")},makeArray:function(j,s){var v=s||[];if(j!=null){var z=b.type(j);j.length==null||z==="string"||z==="function"||z==="regexp"||b.isWindow(j)?M.call(v,j):b.merge(v,j)}return v},inArray:function(j,s){if(s.indexOf)return s.indexOf(j);for(var v=0,z=s.length;v<z;v++)if(s[v]===j)return v;return-1},merge:function(j,
s){var v=j.length,z=0;if(typeof s.length==="number")for(var H=s.length;z<H;z++)j[v++]=s[z];else for(;s[z]!==B;)j[v++]=s[z++];j.length=v;return j},grep:function(j,s,v){var z=[],H;v=!!v;for(var G=0,K=j.length;G<K;G++){H=!!s(j[G],G);v!==H&&z.push(j[G])}return z},map:function(j,s,v){for(var z=[],H,G=0,K=j.length;G<K;G++){H=s(j[G],G,v);if(H!=null)z[z.length]=H}return z.concat.apply([],z)},guid:1,proxy:function(j,s,v){if(arguments.length===2)if(typeof s==="string"){v=j;j=v[s];s=B}else if(s&&!b.isFunction(s)){v=
s;s=B}if(!s&&j)s=function(){return j.apply(v||this,arguments)};if(j)s.guid=j.guid=j.guid||s.guid||b.guid++;return s},access:function(j,s,v,z,H,G){var K=j.length;if(typeof s==="object"){for(var Q in s)b.access(j,Q,s[Q],z,H,v);return j}if(v!==B){z=!G&&z&&b.isFunction(v);for(Q=0;Q<K;Q++)H(j[Q],s,z?v.call(j[Q],Q,H(j[Q],s)):v,G);return j}return K?H(j[0],s):B},now:function(){return(new Date).getTime()},uaMatch:function(j){j=j.toLowerCase();j=L.exec(j)||g.exec(j)||i.exec(j)||j.indexOf("compatible")<0&&n.exec(j)||
[];return{browser:j[1]||"",version:j[2]||"0"}},browser:{}});b.each("Boolean Number String Function Array Date RegExp Object".split(" "),function(j,s){R["[object "+s+"]"]=s.toLowerCase()});m=b.uaMatch(m);if(m.browser){b.browser[m.browser]=true;b.browser.version=m.version}if(b.browser.webkit)b.browser.safari=true;if(D)b.inArray=function(j,s){return D.call(s,j)};if(!/\s/.test("\u00a0")){k=/^[\s\xA0]+/;o=/[\s\xA0]+$/}f=b(t);if(t.addEventListener)u=function(){t.removeEventListener("DOMContentLoaded",u,
false);b.ready()};else if(t.attachEvent)u=function(){if(t.readyState==="complete"){t.detachEvent("onreadystatechange",u);b.ready()}};return E.jQuery=E.$=b}();(function(){c.support={};var a=t.documentElement,b=t.createElement("script"),d=t.createElement("div"),e="script"+c.now();d.style.display="none";d.innerHTML="   <link/><table></table><a href='/a' style='color:red;float:left;opacity:.55;'>a</a><input type='checkbox'/>";var f=d.getElementsByTagName("*"),h=d.getElementsByTagName("a")[0],l=t.createElement("select"),
k=l.appendChild(t.createElement("option"));if(!(!f||!f.length||!h)){c.support={leadingWhitespace:d.firstChild.nodeType===3,tbody:!d.getElementsByTagName("tbody").length,htmlSerialize:!!d.getElementsByTagName("link").length,style:/red/.test(h.getAttribute("style")),hrefNormalized:h.getAttribute("href")==="/a",opacity:/^0.55$/.test(h.style.opacity),cssFloat:!!h.style.cssFloat,checkOn:d.getElementsByTagName("input")[0].value==="on",optSelected:k.selected,deleteExpando:true,optDisabled:false,checkClone:false,
scriptEval:false,noCloneEvent:true,boxModel:null,inlineBlockNeedsLayout:false,shrinkWrapBlocks:false,reliableHiddenOffsets:true};l.disabled=true;c.support.optDisabled=!k.disabled;b.type="text/javascript";try{b.appendChild(t.createTextNode("window."+e+"=1;"))}catch(o){}a.insertBefore(b,a.firstChild);if(E[e]){c.support.scriptEval=true;delete E[e]}try{delete b.test}catch(x){c.support.deleteExpando=false}a.removeChild(b);if(d.attachEvent&&d.fireEvent){d.attachEvent("onclick",function r(){c.support.noCloneEvent=
false;d.detachEvent("onclick",r)});d.cloneNode(true).fireEvent("onclick")}d=t.createElement("div");d.innerHTML="<input type='radio' name='radiotest' checked='checked'/>";a=t.createDocumentFragment();a.appendChild(d.firstChild);c.support.checkClone=a.cloneNode(true).cloneNode(true).lastChild.checked;c(function(){var r=t.createElement("div");r.style.width=r.style.paddingLeft="1px";t.body.appendChild(r);c.boxModel=c.support.boxModel=r.offsetWidth===2;if("zoom"in r.style){r.style.display="inline";r.style.zoom=
1;c.support.inlineBlockNeedsLayout=r.offsetWidth===2;r.style.display="";r.innerHTML="<div style='width:4px;'></div>";c.support.shrinkWrapBlocks=r.offsetWidth!==2}r.innerHTML="<table><tr><td style='padding:0;display:none'></td><td>t</td></tr></table>";var A=r.getElementsByTagName("td");c.support.reliableHiddenOffsets=A[0].offsetHeight===0;A[0].style.display="";A[1].style.display="none";c.support.reliableHiddenOffsets=c.support.reliableHiddenOffsets&&A[0].offsetHeight===0;r.innerHTML="";t.body.removeChild(r).style.display=
"none"});a=function(r){var A=t.createElement("div");r="on"+r;var C=r in A;if(!C){A.setAttribute(r,"return;");C=typeof A[r]==="function"}return C};c.support.submitBubbles=a("submit");c.support.changeBubbles=a("change");a=b=d=f=h=null}})();var ra={},Ja=/^(?:\{.*\}|\[.*\])$/;c.extend({cache:{},uuid:0,expando:"jQuery"+c.now(),noData:{embed:true,object:"clsid:D27CDB6E-AE6D-11cf-96B8-444553540000",applet:true},data:function(a,b,d){if(c.acceptData(a)){a=a==E?ra:a;var e=a.nodeType,f=e?a[c.expando]:null,h=
c.cache;if(!(e&&!f&&typeof b==="string"&&d===B)){if(e)f||(a[c.expando]=f=++c.uuid);else h=a;if(typeof b==="object")if(e)h[f]=c.extend(h[f],b);else c.extend(h,b);else if(e&&!h[f])h[f]={};a=e?h[f]:h;if(d!==B)a[b]=d;return typeof b==="string"?a[b]:a}}},removeData:function(a,b){if(c.acceptData(a)){a=a==E?ra:a;var d=a.nodeType,e=d?a[c.expando]:a,f=c.cache,h=d?f[e]:e;if(b){if(h){delete h[b];d&&c.isEmptyObject(h)&&c.removeData(a)}}else if(d&&c.support.deleteExpando)delete a[c.expando];else if(a.removeAttribute)a.removeAttribute(c.expando);
else if(d)delete f[e];else for(var l in a)delete a[l]}},acceptData:function(a){if(a.nodeName){var b=c.noData[a.nodeName.toLowerCase()];if(b)return!(b===true||a.getAttribute("classid")!==b)}return true}});c.fn.extend({data:function(a,b){var d=null;if(typeof a==="undefined"){if(this.length){var e=this[0].attributes,f;d=c.data(this[0]);for(var h=0,l=e.length;h<l;h++){f=e[h].name;if(f.indexOf("data-")===0){f=f.substr(5);ka(this[0],f,d[f])}}}return d}else if(typeof a==="object")return this.each(function(){c.data(this,
a)});var k=a.split(".");k[1]=k[1]?"."+k[1]:"";if(b===B){d=this.triggerHandler("getData"+k[1]+"!",[k[0]]);if(d===B&&this.length){d=c.data(this[0],a);d=ka(this[0],a,d)}return d===B&&k[1]?this.data(k[0]):d}else return this.each(function(){var o=c(this),x=[k[0],b];o.triggerHandler("setData"+k[1]+"!",x);c.data(this,a,b);o.triggerHandler("changeData"+k[1]+"!",x)})},removeData:function(a){return this.each(function(){c.removeData(this,a)})}});c.extend({queue:function(a,b,d){if(a){b=(b||"fx")+"queue";var e=
c.data(a,b);if(!d)return e||[];if(!e||c.isArray(d))e=c.data(a,b,c.makeArray(d));else e.push(d);return e}},dequeue:function(a,b){b=b||"fx";var d=c.queue(a,b),e=d.shift();if(e==="inprogress")e=d.shift();if(e){b==="fx"&&d.unshift("inprogress");e.call(a,function(){c.dequeue(a,b)})}}});c.fn.extend({queue:function(a,b){if(typeof a!=="string"){b=a;a="fx"}if(b===B)return c.queue(this[0],a);return this.each(function(){var d=c.queue(this,a,b);a==="fx"&&d[0]!=="inprogress"&&c.dequeue(this,a)})},dequeue:function(a){return this.each(function(){c.dequeue(this,
a)})},delay:function(a,b){a=c.fx?c.fx.speeds[a]||a:a;b=b||"fx";return this.queue(b,function(){var d=this;setTimeout(function(){c.dequeue(d,b)},a)})},clearQueue:function(a){return this.queue(a||"fx",[])}});var sa=/[\n\t]/g,ha=/\s+/,Sa=/\r/g,Ta=/^(?:href|src|style)$/,Ua=/^(?:button|input)$/i,Va=/^(?:button|input|object|select|textarea)$/i,Wa=/^a(?:rea)?$/i,ta=/^(?:radio|checkbox)$/i;c.props={"for":"htmlFor","class":"className",readonly:"readOnly",maxlength:"maxLength",cellspacing:"cellSpacing",rowspan:"rowSpan",
colspan:"colSpan",tabindex:"tabIndex",usemap:"useMap",frameborder:"frameBorder"};c.fn.extend({attr:function(a,b){return c.access(this,a,b,true,c.attr)},removeAttr:function(a){return this.each(function(){c.attr(this,a,"");this.nodeType===1&&this.removeAttribute(a)})},addClass:function(a){if(c.isFunction(a))return this.each(function(x){var r=c(this);r.addClass(a.call(this,x,r.attr("class")))});if(a&&typeof a==="string")for(var b=(a||"").split(ha),d=0,e=this.length;d<e;d++){var f=this[d];if(f.nodeType===
1)if(f.className){for(var h=" "+f.className+" ",l=f.className,k=0,o=b.length;k<o;k++)if(h.indexOf(" "+b[k]+" ")<0)l+=" "+b[k];f.className=c.trim(l)}else f.className=a}return this},removeClass:function(a){if(c.isFunction(a))return this.each(function(o){var x=c(this);x.removeClass(a.call(this,o,x.attr("class")))});if(a&&typeof a==="string"||a===B)for(var b=(a||"").split(ha),d=0,e=this.length;d<e;d++){var f=this[d];if(f.nodeType===1&&f.className)if(a){for(var h=(" "+f.className+" ").replace(sa," "),
l=0,k=b.length;l<k;l++)h=h.replace(" "+b[l]+" "," ");f.className=c.trim(h)}else f.className=""}return this},toggleClass:function(a,b){var d=typeof a,e=typeof b==="boolean";if(c.isFunction(a))return this.each(function(f){var h=c(this);h.toggleClass(a.call(this,f,h.attr("class"),b),b)});return this.each(function(){if(d==="string")for(var f,h=0,l=c(this),k=b,o=a.split(ha);f=o[h++];){k=e?k:!l.hasClass(f);l[k?"addClass":"removeClass"](f)}else if(d==="undefined"||d==="boolean"){this.className&&c.data(this,
"__className__",this.className);this.className=this.className||a===false?"":c.data(this,"__className__")||""}})},hasClass:function(a){a=" "+a+" ";for(var b=0,d=this.length;b<d;b++)if((" "+this[b].className+" ").replace(sa," ").indexOf(a)>-1)return true;return false},val:function(a){if(!arguments.length){var b=this[0];if(b){if(c.nodeName(b,"option")){var d=b.attributes.value;return!d||d.specified?b.value:b.text}if(c.nodeName(b,"select")){var e=b.selectedIndex;d=[];var f=b.options;b=b.type==="select-one";
if(e<0)return null;var h=b?e:0;for(e=b?e+1:f.length;h<e;h++){var l=f[h];if(l.selected&&(c.support.optDisabled?!l.disabled:l.getAttribute("disabled")===null)&&(!l.parentNode.disabled||!c.nodeName(l.parentNode,"optgroup"))){a=c(l).val();if(b)return a;d.push(a)}}return d}if(ta.test(b.type)&&!c.support.checkOn)return b.getAttribute("value")===null?"on":b.value;return(b.value||"").replace(Sa,"")}return B}var k=c.isFunction(a);return this.each(function(o){var x=c(this),r=a;if(this.nodeType===1){if(k)r=
a.call(this,o,x.val());if(r==null)r="";else if(typeof r==="number")r+="";else if(c.isArray(r))r=c.map(r,function(C){return C==null?"":C+""});if(c.isArray(r)&&ta.test(this.type))this.checked=c.inArray(x.val(),r)>=0;else if(c.nodeName(this,"select")){var A=c.makeArray(r);c("option",this).each(function(){this.selected=c.inArray(c(this).val(),A)>=0});if(!A.length)this.selectedIndex=-1}else this.value=r}})}});c.extend({attrFn:{val:true,css:true,html:true,text:true,data:true,width:true,height:true,offset:true},
attr:function(a,b,d,e){if(!a||a.nodeType===3||a.nodeType===8)return B;if(e&&b in c.attrFn)return c(a)[b](d);e=a.nodeType!==1||!c.isXMLDoc(a);var f=d!==B;b=e&&c.props[b]||b;var h=Ta.test(b);if((b in a||a[b]!==B)&&e&&!h){if(f){b==="type"&&Ua.test(a.nodeName)&&a.parentNode&&c.error("type property can't be changed");if(d===null)a.nodeType===1&&a.removeAttribute(b);else a[b]=d}if(c.nodeName(a,"form")&&a.getAttributeNode(b))return a.getAttributeNode(b).nodeValue;if(b==="tabIndex")return(b=a.getAttributeNode("tabIndex"))&&
b.specified?b.value:Va.test(a.nodeName)||Wa.test(a.nodeName)&&a.href?0:B;return a[b]}if(!c.support.style&&e&&b==="style"){if(f)a.style.cssText=""+d;return a.style.cssText}f&&a.setAttribute(b,""+d);if(!a.attributes[b]&&a.hasAttribute&&!a.hasAttribute(b))return B;a=!c.support.hrefNormalized&&e&&h?a.getAttribute(b,2):a.getAttribute(b);return a===null?B:a}});var X=/\.(.*)$/,ia=/^(?:textarea|input|select)$/i,La=/\./g,Ma=/ /g,Xa=/[^\w\s.|`]/g,Ya=function(a){return a.replace(Xa,"\\$&")},ua={focusin:0,focusout:0};
c.event={add:function(a,b,d,e){if(!(a.nodeType===3||a.nodeType===8)){if(c.isWindow(a)&&a!==E&&!a.frameElement)a=E;if(d===false)d=U;else if(!d)return;var f,h;if(d.handler){f=d;d=f.handler}if(!d.guid)d.guid=c.guid++;if(h=c.data(a)){var l=a.nodeType?"events":"__events__",k=h[l],o=h.handle;if(typeof k==="function"){o=k.handle;k=k.events}else if(!k){a.nodeType||(h[l]=h=function(){});h.events=k={}}if(!o)h.handle=o=function(){return typeof c!=="undefined"&&!c.event.triggered?c.event.handle.apply(o.elem,
arguments):B};o.elem=a;b=b.split(" ");for(var x=0,r;l=b[x++];){h=f?c.extend({},f):{handler:d,data:e};if(l.indexOf(".")>-1){r=l.split(".");l=r.shift();h.namespace=r.slice(0).sort().join(".")}else{r=[];h.namespace=""}h.type=l;if(!h.guid)h.guid=d.guid;var A=k[l],C=c.event.special[l]||{};if(!A){A=k[l]=[];if(!C.setup||C.setup.call(a,e,r,o)===false)if(a.addEventListener)a.addEventListener(l,o,false);else a.attachEvent&&a.attachEvent("on"+l,o)}if(C.add){C.add.call(a,h);if(!h.handler.guid)h.handler.guid=
d.guid}A.push(h);c.event.global[l]=true}a=null}}},global:{},remove:function(a,b,d,e){if(!(a.nodeType===3||a.nodeType===8)){if(d===false)d=U;var f,h,l=0,k,o,x,r,A,C,J=a.nodeType?"events":"__events__",w=c.data(a),I=w&&w[J];if(w&&I){if(typeof I==="function"){w=I;I=I.events}if(b&&b.type){d=b.handler;b=b.type}if(!b||typeof b==="string"&&b.charAt(0)==="."){b=b||"";for(f in I)c.event.remove(a,f+b)}else{for(b=b.split(" ");f=b[l++];){r=f;k=f.indexOf(".")<0;o=[];if(!k){o=f.split(".");f=o.shift();x=RegExp("(^|\\.)"+
c.map(o.slice(0).sort(),Ya).join("\\.(?:.*\\.)?")+"(\\.|$)")}if(A=I[f])if(d){r=c.event.special[f]||{};for(h=e||0;h<A.length;h++){C=A[h];if(d.guid===C.guid){if(k||x.test(C.namespace)){e==null&&A.splice(h--,1);r.remove&&r.remove.call(a,C)}if(e!=null)break}}if(A.length===0||e!=null&&A.length===1){if(!r.teardown||r.teardown.call(a,o)===false)c.removeEvent(a,f,w.handle);delete I[f]}}else for(h=0;h<A.length;h++){C=A[h];if(k||x.test(C.namespace)){c.event.remove(a,r,C.handler,h);A.splice(h--,1)}}}if(c.isEmptyObject(I)){if(b=
w.handle)b.elem=null;delete w.events;delete w.handle;if(typeof w==="function")c.removeData(a,J);else c.isEmptyObject(w)&&c.removeData(a)}}}}},trigger:function(a,b,d,e){var f=a.type||a;if(!e){a=typeof a==="object"?a[c.expando]?a:c.extend(c.Event(f),a):c.Event(f);if(f.indexOf("!")>=0){a.type=f=f.slice(0,-1);a.exclusive=true}if(!d){a.stopPropagation();c.event.global[f]&&c.each(c.cache,function(){this.events&&this.events[f]&&c.event.trigger(a,b,this.handle.elem)})}if(!d||d.nodeType===3||d.nodeType===
8)return B;a.result=B;a.target=d;b=c.makeArray(b);b.unshift(a)}a.currentTarget=d;(e=d.nodeType?c.data(d,"handle"):(c.data(d,"__events__")||{}).handle)&&e.apply(d,b);e=d.parentNode||d.ownerDocument;try{if(!(d&&d.nodeName&&c.noData[d.nodeName.toLowerCase()]))if(d["on"+f]&&d["on"+f].apply(d,b)===false){a.result=false;a.preventDefault()}}catch(h){}if(!a.isPropagationStopped()&&e)c.event.trigger(a,b,e,true);else if(!a.isDefaultPrevented()){var l;e=a.target;var k=f.replace(X,""),o=c.nodeName(e,"a")&&k===
"click",x=c.event.special[k]||{};if((!x._default||x._default.call(d,a)===false)&&!o&&!(e&&e.nodeName&&c.noData[e.nodeName.toLowerCase()])){try{if(e[k]){if(l=e["on"+k])e["on"+k]=null;c.event.triggered=true;e[k]()}}catch(r){}if(l)e["on"+k]=l;c.event.triggered=false}}},handle:function(a){var b,d,e,f;d=[];var h=c.makeArray(arguments);a=h[0]=c.event.fix(a||E.event);a.currentTarget=this;b=a.type.indexOf(".")<0&&!a.exclusive;if(!b){e=a.type.split(".");a.type=e.shift();d=e.slice(0).sort();e=RegExp("(^|\\.)"+
d.join("\\.(?:.*\\.)?")+"(\\.|$)")}a.namespace=a.namespace||d.join(".");f=c.data(this,this.nodeType?"events":"__events__");if(typeof f==="function")f=f.events;d=(f||{})[a.type];if(f&&d){d=d.slice(0);f=0;for(var l=d.length;f<l;f++){var k=d[f];if(b||e.test(k.namespace)){a.handler=k.handler;a.data=k.data;a.handleObj=k;k=k.handler.apply(this,h);if(k!==B){a.result=k;if(k===false){a.preventDefault();a.stopPropagation()}}if(a.isImmediatePropagationStopped())break}}}return a.result},props:"altKey attrChange attrName bubbles button cancelable charCode clientX clientY ctrlKey currentTarget data detail eventPhase fromElement handler keyCode layerX layerY metaKey newValue offsetX offsetY pageX pageY prevValue relatedNode relatedTarget screenX screenY shiftKey srcElement target toElement view wheelDelta which".split(" "),
fix:function(a){if(a[c.expando])return a;var b=a;a=c.Event(b);for(var d=this.props.length,e;d;){e=this.props[--d];a[e]=b[e]}if(!a.target)a.target=a.srcElement||t;if(a.target.nodeType===3)a.target=a.target.parentNode;if(!a.relatedTarget&&a.fromElement)a.relatedTarget=a.fromElement===a.target?a.toElement:a.fromElement;if(a.pageX==null&&a.clientX!=null){b=t.documentElement;d=t.body;a.pageX=a.clientX+(b&&b.scrollLeft||d&&d.scrollLeft||0)-(b&&b.clientLeft||d&&d.clientLeft||0);a.pageY=a.clientY+(b&&b.scrollTop||
d&&d.scrollTop||0)-(b&&b.clientTop||d&&d.clientTop||0)}if(a.which==null&&(a.charCode!=null||a.keyCode!=null))a.which=a.charCode!=null?a.charCode:a.keyCode;if(!a.metaKey&&a.ctrlKey)a.metaKey=a.ctrlKey;if(!a.which&&a.button!==B)a.which=a.button&1?1:a.button&2?3:a.button&4?2:0;return a},guid:1E8,proxy:c.proxy,special:{ready:{setup:c.bindReady,teardown:c.noop},live:{add:function(a){c.event.add(this,Y(a.origType,a.selector),c.extend({},a,{handler:Ka,guid:a.handler.guid}))},remove:function(a){c.event.remove(this,
Y(a.origType,a.selector),a)}},beforeunload:{setup:function(a,b,d){if(c.isWindow(this))this.onbeforeunload=d},teardown:function(a,b){if(this.onbeforeunload===b)this.onbeforeunload=null}}}};c.removeEvent=t.removeEventListener?function(a,b,d){a.removeEventListener&&a.removeEventListener(b,d,false)}:function(a,b,d){a.detachEvent&&a.detachEvent("on"+b,d)};c.Event=function(a){if(!this.preventDefault)return new c.Event(a);if(a&&a.type){this.originalEvent=a;this.type=a.type}else this.type=a;this.timeStamp=
c.now();this[c.expando]=true};c.Event.prototype={preventDefault:function(){this.isDefaultPrevented=ca;var a=this.originalEvent;if(a)if(a.preventDefault)a.preventDefault();else a.returnValue=false},stopPropagation:function(){this.isPropagationStopped=ca;var a=this.originalEvent;if(a){a.stopPropagation&&a.stopPropagation();a.cancelBubble=true}},stopImmediatePropagation:function(){this.isImmediatePropagationStopped=ca;this.stopPropagation()},isDefaultPrevented:U,isPropagationStopped:U,isImmediatePropagationStopped:U};
var va=function(a){var b=a.relatedTarget;try{for(;b&&b!==this;)b=b.parentNode;if(b!==this){a.type=a.data;c.event.handle.apply(this,arguments)}}catch(d){}},wa=function(a){a.type=a.data;c.event.handle.apply(this,arguments)};c.each({mouseenter:"mouseover",mouseleave:"mouseout"},function(a,b){c.event.special[a]={setup:function(d){c.event.add(this,b,d&&d.selector?wa:va,a)},teardown:function(d){c.event.remove(this,b,d&&d.selector?wa:va)}}});if(!c.support.submitBubbles)c.event.special.submit={setup:function(){if(this.nodeName.toLowerCase()!==
"form"){c.event.add(this,"click.specialSubmit",function(a){var b=a.target,d=b.type;if((d==="submit"||d==="image")&&c(b).closest("form").length){a.liveFired=B;return la("submit",this,arguments)}});c.event.add(this,"keypress.specialSubmit",function(a){var b=a.target,d=b.type;if((d==="text"||d==="password")&&c(b).closest("form").length&&a.keyCode===13){a.liveFired=B;return la("submit",this,arguments)}})}else return false},teardown:function(){c.event.remove(this,".specialSubmit")}};if(!c.support.changeBubbles){var V,
xa=function(a){var b=a.type,d=a.value;if(b==="radio"||b==="checkbox")d=a.checked;else if(b==="select-multiple")d=a.selectedIndex>-1?c.map(a.options,function(e){return e.selected}).join("-"):"";else if(a.nodeName.toLowerCase()==="select")d=a.selectedIndex;return d},Z=function(a,b){var d=a.target,e,f;if(!(!ia.test(d.nodeName)||d.readOnly)){e=c.data(d,"_change_data");f=xa(d);if(a.type!=="focusout"||d.type!=="radio")c.data(d,"_change_data",f);if(!(e===B||f===e))if(e!=null||f){a.type="change";a.liveFired=
B;return c.event.trigger(a,b,d)}}};c.event.special.change={filters:{focusout:Z,beforedeactivate:Z,click:function(a){var b=a.target,d=b.type;if(d==="radio"||d==="checkbox"||b.nodeName.toLowerCase()==="select")return Z.call(this,a)},keydown:function(a){var b=a.target,d=b.type;if(a.keyCode===13&&b.nodeName.toLowerCase()!=="textarea"||a.keyCode===32&&(d==="checkbox"||d==="radio")||d==="select-multiple")return Z.call(this,a)},beforeactivate:function(a){a=a.target;c.data(a,"_change_data",xa(a))}},setup:function(){if(this.type===
"file")return false;for(var a in V)c.event.add(this,a+".specialChange",V[a]);return ia.test(this.nodeName)},teardown:function(){c.event.remove(this,".specialChange");return ia.test(this.nodeName)}};V=c.event.special.change.filters;V.focus=V.beforeactivate}t.addEventListener&&c.each({focus:"focusin",blur:"focusout"},function(a,b){function d(e){e=c.event.fix(e);e.type=b;return c.event.trigger(e,null,e.target)}c.event.special[b]={setup:function(){ua[b]++===0&&t.addEventListener(a,d,true)},teardown:function(){--ua[b]===
0&&t.removeEventListener(a,d,true)}}});c.each(["bind","one"],function(a,b){c.fn[b]=function(d,e,f){if(typeof d==="object"){for(var h in d)this[b](h,e,d[h],f);return this}if(c.isFunction(e)||e===false){f=e;e=B}var l=b==="one"?c.proxy(f,function(o){c(this).unbind(o,l);return f.apply(this,arguments)}):f;if(d==="unload"&&b!=="one")this.one(d,e,f);else{h=0;for(var k=this.length;h<k;h++)c.event.add(this[h],d,l,e)}return this}});c.fn.extend({unbind:function(a,b){if(typeof a==="object"&&!a.preventDefault)for(var d in a)this.unbind(d,
a[d]);else{d=0;for(var e=this.length;d<e;d++)c.event.remove(this[d],a,b)}return this},delegate:function(a,b,d,e){return this.live(b,d,e,a)},undelegate:function(a,b,d){return arguments.length===0?this.unbind("live"):this.die(b,null,d,a)},trigger:function(a,b){return this.each(function(){c.event.trigger(a,b,this)})},triggerHandler:function(a,b){if(this[0]){var d=c.Event(a);d.preventDefault();d.stopPropagation();c.event.trigger(d,b,this[0]);return d.result}},toggle:function(a){for(var b=arguments,d=
1;d<b.length;)c.proxy(a,b[d++]);return this.click(c.proxy(a,function(e){var f=(c.data(this,"lastToggle"+a.guid)||0)%d;c.data(this,"lastToggle"+a.guid,f+1);e.preventDefault();return b[f].apply(this,arguments)||false}))},hover:function(a,b){return this.mouseenter(a).mouseleave(b||a)}});var ya={focus:"focusin",blur:"focusout",mouseenter:"mouseover",mouseleave:"mouseout"};c.each(["live","die"],function(a,b){c.fn[b]=function(d,e,f,h){var l,k=0,o,x,r=h||this.selector;h=h?this:c(this.context);if(typeof d===
"object"&&!d.preventDefault){for(l in d)h[b](l,e,d[l],r);return this}if(c.isFunction(e)){f=e;e=B}for(d=(d||"").split(" ");(l=d[k++])!=null;){o=X.exec(l);x="";if(o){x=o[0];l=l.replace(X,"")}if(l==="hover")d.push("mouseenter"+x,"mouseleave"+x);else{o=l;if(l==="focus"||l==="blur"){d.push(ya[l]+x);l+=x}else l=(ya[l]||l)+x;if(b==="live"){x=0;for(var A=h.length;x<A;x++)c.event.add(h[x],"live."+Y(l,r),{data:e,selector:r,handler:f,origType:l,origHandler:f,preType:o})}else h.unbind("live."+Y(l,r),f)}}return this}});
c.each("blur focus focusin focusout load resize scroll unload click dblclick mousedown mouseup mousemove mouseover mouseout mouseenter mouseleave change select submit keydown keypress keyup error".split(" "),function(a,b){c.fn[b]=function(d,e){if(e==null){e=d;d=null}return arguments.length>0?this.bind(b,d,e):this.trigger(b)};if(c.attrFn)c.attrFn[b]=true});E.attachEvent&&!E.addEventListener&&c(E).bind("unload",function(){for(var a in c.cache)if(c.cache[a].handle)try{c.event.remove(c.cache[a].handle.elem)}catch(b){}});
(function(){function a(g,i,n,m,p,q){p=0;for(var u=m.length;p<u;p++){var y=m[p];if(y){var F=false;for(y=y[g];y;){if(y.sizcache===n){F=m[y.sizset];break}if(y.nodeType===1&&!q){y.sizcache=n;y.sizset=p}if(y.nodeName.toLowerCase()===i){F=y;break}y=y[g]}m[p]=F}}}function b(g,i,n,m,p,q){p=0;for(var u=m.length;p<u;p++){var y=m[p];if(y){var F=false;for(y=y[g];y;){if(y.sizcache===n){F=m[y.sizset];break}if(y.nodeType===1){if(!q){y.sizcache=n;y.sizset=p}if(typeof i!=="string"){if(y===i){F=true;break}}else if(k.filter(i,
[y]).length>0){F=y;break}}y=y[g]}m[p]=F}}}var d=/((?:\((?:\([^()]+\)|[^()]+)+\)|\[(?:\[[^\[\]]*\]|['"][^'"]*['"]|[^\[\]'"]+)+\]|\\.|[^ >+~,(\[\\]+)+|[>+~])(\s*,\s*)?((?:.|\r|\n)*)/g,e=0,f=Object.prototype.toString,h=false,l=true;[0,0].sort(function(){l=false;return 0});var k=function(g,i,n,m){n=n||[];var p=i=i||t;if(i.nodeType!==1&&i.nodeType!==9)return[];if(!g||typeof g!=="string")return n;var q,u,y,F,M,N=true,O=k.isXML(i),D=[],R=g;do{d.exec("");if(q=d.exec(R)){R=q[3];D.push(q[1]);if(q[2]){F=q[3];
break}}}while(q);if(D.length>1&&x.exec(g))if(D.length===2&&o.relative[D[0]])u=L(D[0]+D[1],i);else for(u=o.relative[D[0]]?[i]:k(D.shift(),i);D.length;){g=D.shift();if(o.relative[g])g+=D.shift();u=L(g,u)}else{if(!m&&D.length>1&&i.nodeType===9&&!O&&o.match.ID.test(D[0])&&!o.match.ID.test(D[D.length-1])){q=k.find(D.shift(),i,O);i=q.expr?k.filter(q.expr,q.set)[0]:q.set[0]}if(i){q=m?{expr:D.pop(),set:C(m)}:k.find(D.pop(),D.length===1&&(D[0]==="~"||D[0]==="+")&&i.parentNode?i.parentNode:i,O);u=q.expr?k.filter(q.expr,
q.set):q.set;if(D.length>0)y=C(u);else N=false;for(;D.length;){q=M=D.pop();if(o.relative[M])q=D.pop();else M="";if(q==null)q=i;o.relative[M](y,q,O)}}else y=[]}y||(y=u);y||k.error(M||g);if(f.call(y)==="[object Array]")if(N)if(i&&i.nodeType===1)for(g=0;y[g]!=null;g++){if(y[g]&&(y[g]===true||y[g].nodeType===1&&k.contains(i,y[g])))n.push(u[g])}else for(g=0;y[g]!=null;g++)y[g]&&y[g].nodeType===1&&n.push(u[g]);else n.push.apply(n,y);else C(y,n);if(F){k(F,p,n,m);k.uniqueSort(n)}return n};k.uniqueSort=function(g){if(w){h=
l;g.sort(w);if(h)for(var i=1;i<g.length;i++)g[i]===g[i-1]&&g.splice(i--,1)}return g};k.matches=function(g,i){return k(g,null,null,i)};k.matchesSelector=function(g,i){return k(i,null,null,[g]).length>0};k.find=function(g,i,n){var m;if(!g)return[];for(var p=0,q=o.order.length;p<q;p++){var u,y=o.order[p];if(u=o.leftMatch[y].exec(g)){var F=u[1];u.splice(1,1);if(F.substr(F.length-1)!=="\\"){u[1]=(u[1]||"").replace(/\\/g,"");m=o.find[y](u,i,n);if(m!=null){g=g.replace(o.match[y],"");break}}}}m||(m=i.getElementsByTagName("*"));
return{set:m,expr:g}};k.filter=function(g,i,n,m){for(var p,q,u=g,y=[],F=i,M=i&&i[0]&&k.isXML(i[0]);g&&i.length;){for(var N in o.filter)if((p=o.leftMatch[N].exec(g))!=null&&p[2]){var O,D,R=o.filter[N];D=p[1];q=false;p.splice(1,1);if(D.substr(D.length-1)!=="\\"){if(F===y)y=[];if(o.preFilter[N])if(p=o.preFilter[N](p,F,n,y,m,M)){if(p===true)continue}else q=O=true;if(p)for(var j=0;(D=F[j])!=null;j++)if(D){O=R(D,p,j,F);var s=m^!!O;if(n&&O!=null)if(s)q=true;else F[j]=false;else if(s){y.push(D);q=true}}if(O!==
B){n||(F=y);g=g.replace(o.match[N],"");if(!q)return[];break}}}if(g===u)if(q==null)k.error(g);else break;u=g}return F};k.error=function(g){throw"Syntax error, unrecognized expression: "+g;};var o=k.selectors={order:["ID","NAME","TAG"],match:{ID:/#((?:[\w\u00c0-\uFFFF\-]|\\.)+)/,CLASS:/\.((?:[\w\u00c0-\uFFFF\-]|\\.)+)/,NAME:/\[name=['"]*((?:[\w\u00c0-\uFFFF\-]|\\.)+)['"]*\]/,ATTR:/\[\s*((?:[\w\u00c0-\uFFFF\-]|\\.)+)\s*(?:(\S?=)\s*(['"]*)(.*?)\3|)\s*\]/,TAG:/^((?:[\w\u00c0-\uFFFF\*\-]|\\.)+)/,CHILD:/:(only|nth|last|first)-child(?:\((even|odd|[\dn+\-]*)\))?/,
POS:/:(nth|eq|gt|lt|first|last|even|odd)(?:\((\d*)\))?(?=[^\-]|$)/,PSEUDO:/:((?:[\w\u00c0-\uFFFF\-]|\\.)+)(?:\((['"]?)((?:\([^\)]+\)|[^\(\)]*)+)\2\))?/},leftMatch:{},attrMap:{"class":"className","for":"htmlFor"},attrHandle:{href:function(g){return g.getAttribute("href")}},relative:{"+":function(g,i){var n=typeof i==="string",m=n&&!/\W/.test(i);n=n&&!m;if(m)i=i.toLowerCase();m=0;for(var p=g.length,q;m<p;m++)if(q=g[m]){for(;(q=q.previousSibling)&&q.nodeType!==1;);g[m]=n||q&&q.nodeName.toLowerCase()===
i?q||false:q===i}n&&k.filter(i,g,true)},">":function(g,i){var n,m=typeof i==="string",p=0,q=g.length;if(m&&!/\W/.test(i))for(i=i.toLowerCase();p<q;p++){if(n=g[p]){n=n.parentNode;g[p]=n.nodeName.toLowerCase()===i?n:false}}else{for(;p<q;p++)if(n=g[p])g[p]=m?n.parentNode:n.parentNode===i;m&&k.filter(i,g,true)}},"":function(g,i,n){var m,p=e++,q=b;if(typeof i==="string"&&!/\W/.test(i)){m=i=i.toLowerCase();q=a}q("parentNode",i,p,g,m,n)},"~":function(g,i,n){var m,p=e++,q=b;if(typeof i==="string"&&!/\W/.test(i)){m=
i=i.toLowerCase();q=a}q("previousSibling",i,p,g,m,n)}},find:{ID:function(g,i,n){if(typeof i.getElementById!=="undefined"&&!n)return(g=i.getElementById(g[1]))&&g.parentNode?[g]:[]},NAME:function(g,i){if(typeof i.getElementsByName!=="undefined"){for(var n=[],m=i.getElementsByName(g[1]),p=0,q=m.length;p<q;p++)m[p].getAttribute("name")===g[1]&&n.push(m[p]);return n.length===0?null:n}},TAG:function(g,i){return i.getElementsByTagName(g[1])}},preFilter:{CLASS:function(g,i,n,m,p,q){g=" "+g[1].replace(/\\/g,
"")+" ";if(q)return g;q=0;for(var u;(u=i[q])!=null;q++)if(u)if(p^(u.className&&(" "+u.className+" ").replace(/[\t\n]/g," ").indexOf(g)>=0))n||m.push(u);else if(n)i[q]=false;return false},ID:function(g){return g[1].replace(/\\/g,"")},TAG:function(g){return g[1].toLowerCase()},CHILD:function(g){if(g[1]==="nth"){var i=/(-?)(\d*)n((?:\+|-)?\d*)/.exec(g[2]==="even"&&"2n"||g[2]==="odd"&&"2n+1"||!/\D/.test(g[2])&&"0n+"+g[2]||g[2]);g[2]=i[1]+(i[2]||1)-0;g[3]=i[3]-0}g[0]=e++;return g},ATTR:function(g,i,n,
m,p,q){i=g[1].replace(/\\/g,"");if(!q&&o.attrMap[i])g[1]=o.attrMap[i];if(g[2]==="~=")g[4]=" "+g[4]+" ";return g},PSEUDO:function(g,i,n,m,p){if(g[1]==="not")if((d.exec(g[3])||"").length>1||/^\w/.test(g[3]))g[3]=k(g[3],null,null,i);else{g=k.filter(g[3],i,n,true^p);n||m.push.apply(m,g);return false}else if(o.match.POS.test(g[0])||o.match.CHILD.test(g[0]))return true;return g},POS:function(g){g.unshift(true);return g}},filters:{enabled:function(g){return g.disabled===false&&g.type!=="hidden"},disabled:function(g){return g.disabled===
true},checked:function(g){return g.checked===true},selected:function(g){return g.selected===true},parent:function(g){return!!g.firstChild},empty:function(g){return!g.firstChild},has:function(g,i,n){return!!k(n[3],g).length},header:function(g){return/h\d/i.test(g.nodeName)},text:function(g){return"text"===g.type},radio:function(g){return"radio"===g.type},checkbox:function(g){return"checkbox"===g.type},file:function(g){return"file"===g.type},password:function(g){return"password"===g.type},submit:function(g){return"submit"===
g.type},image:function(g){return"image"===g.type},reset:function(g){return"reset"===g.type},button:function(g){return"button"===g.type||g.nodeName.toLowerCase()==="button"},input:function(g){return/input|select|textarea|button/i.test(g.nodeName)}},setFilters:{first:function(g,i){return i===0},last:function(g,i,n,m){return i===m.length-1},even:function(g,i){return i%2===0},odd:function(g,i){return i%2===1},lt:function(g,i,n){return i<n[3]-0},gt:function(g,i,n){return i>n[3]-0},nth:function(g,i,n){return n[3]-
0===i},eq:function(g,i,n){return n[3]-0===i}},filter:{PSEUDO:function(g,i,n,m){var p=i[1],q=o.filters[p];if(q)return q(g,n,i,m);else if(p==="contains")return(g.textContent||g.innerText||k.getText([g])||"").indexOf(i[3])>=0;else if(p==="not"){i=i[3];n=0;for(m=i.length;n<m;n++)if(i[n]===g)return false;return true}else k.error("Syntax error, unrecognized expression: "+p)},CHILD:function(g,i){var n=i[1],m=g;switch(n){case "only":case "first":for(;m=m.previousSibling;)if(m.nodeType===1)return false;if(n===
"first")return true;m=g;case "last":for(;m=m.nextSibling;)if(m.nodeType===1)return false;return true;case "nth":n=i[2];var p=i[3];if(n===1&&p===0)return true;var q=i[0],u=g.parentNode;if(u&&(u.sizcache!==q||!g.nodeIndex)){var y=0;for(m=u.firstChild;m;m=m.nextSibling)if(m.nodeType===1)m.nodeIndex=++y;u.sizcache=q}m=g.nodeIndex-p;return n===0?m===0:m%n===0&&m/n>=0}},ID:function(g,i){return g.nodeType===1&&g.getAttribute("id")===i},TAG:function(g,i){return i==="*"&&g.nodeType===1||g.nodeName.toLowerCase()===
i},CLASS:function(g,i){return(" "+(g.className||g.getAttribute("class"))+" ").indexOf(i)>-1},ATTR:function(g,i){var n=i[1];n=o.attrHandle[n]?o.attrHandle[n](g):g[n]!=null?g[n]:g.getAttribute(n);var m=n+"",p=i[2],q=i[4];return n==null?p==="!=":p==="="?m===q:p==="*="?m.indexOf(q)>=0:p==="~="?(" "+m+" ").indexOf(q)>=0:!q?m&&n!==false:p==="!="?m!==q:p==="^="?m.indexOf(q)===0:p==="$="?m.substr(m.length-q.length)===q:p==="|="?m===q||m.substr(0,q.length+1)===q+"-":false},POS:function(g,i,n,m){var p=o.setFilters[i[2]];
if(p)return p(g,n,i,m)}}},x=o.match.POS,r=function(g,i){return"\\"+(i-0+1)},A;for(A in o.match){o.match[A]=RegExp(o.match[A].source+/(?![^\[]*\])(?![^\(]*\))/.source);o.leftMatch[A]=RegExp(/(^(?:.|\r|\n)*?)/.source+o.match[A].source.replace(/\\(\d+)/g,r))}var C=function(g,i){g=Array.prototype.slice.call(g,0);if(i){i.push.apply(i,g);return i}return g};try{Array.prototype.slice.call(t.documentElement.childNodes,0)}catch(J){C=function(g,i){var n=0,m=i||[];if(f.call(g)==="[object Array]")Array.prototype.push.apply(m,
g);else if(typeof g.length==="number")for(var p=g.length;n<p;n++)m.push(g[n]);else for(;g[n];n++)m.push(g[n]);return m}}var w,I;if(t.documentElement.compareDocumentPosition)w=function(g,i){if(g===i){h=true;return 0}if(!g.compareDocumentPosition||!i.compareDocumentPosition)return g.compareDocumentPosition?-1:1;return g.compareDocumentPosition(i)&4?-1:1};else{w=function(g,i){var n,m,p=[],q=[];n=g.parentNode;m=i.parentNode;var u=n;if(g===i){h=true;return 0}else if(n===m)return I(g,i);else if(n){if(!m)return 1}else return-1;
for(;u;){p.unshift(u);u=u.parentNode}for(u=m;u;){q.unshift(u);u=u.parentNode}n=p.length;m=q.length;for(u=0;u<n&&u<m;u++)if(p[u]!==q[u])return I(p[u],q[u]);return u===n?I(g,q[u],-1):I(p[u],i,1)};I=function(g,i,n){if(g===i)return n;for(g=g.nextSibling;g;){if(g===i)return-1;g=g.nextSibling}return 1}}k.getText=function(g){for(var i="",n,m=0;g[m];m++){n=g[m];if(n.nodeType===3||n.nodeType===4)i+=n.nodeValue;else if(n.nodeType!==8)i+=k.getText(n.childNodes)}return i};(function(){var g=t.createElement("div"),
i="script"+(new Date).getTime(),n=t.documentElement;g.innerHTML="<a name='"+i+"'/>";n.insertBefore(g,n.firstChild);if(t.getElementById(i)){o.find.ID=function(m,p,q){if(typeof p.getElementById!=="undefined"&&!q)return(p=p.getElementById(m[1]))?p.id===m[1]||typeof p.getAttributeNode!=="undefined"&&p.getAttributeNode("id").nodeValue===m[1]?[p]:B:[]};o.filter.ID=function(m,p){var q=typeof m.getAttributeNode!=="undefined"&&m.getAttributeNode("id");return m.nodeType===1&&q&&q.nodeValue===p}}n.removeChild(g);
n=g=null})();(function(){var g=t.createElement("div");g.appendChild(t.createComment(""));if(g.getElementsByTagName("*").length>0)o.find.TAG=function(i,n){var m=n.getElementsByTagName(i[1]);if(i[1]==="*"){for(var p=[],q=0;m[q];q++)m[q].nodeType===1&&p.push(m[q]);m=p}return m};g.innerHTML="<a href='#'></a>";if(g.firstChild&&typeof g.firstChild.getAttribute!=="undefined"&&g.firstChild.getAttribute("href")!=="#")o.attrHandle.href=function(i){return i.getAttribute("href",2)};g=null})();t.querySelectorAll&&
function(){var g=k,i=t.createElement("div");i.innerHTML="<p class='TEST'></p>";if(!(i.querySelectorAll&&i.querySelectorAll(".TEST").length===0)){k=function(m,p,q,u){p=p||t;m=m.replace(/\=\s*([^'"\]]*)\s*\]/g,"='$1']");if(!u&&!k.isXML(p))if(p.nodeType===9)try{return C(p.querySelectorAll(m),q)}catch(y){}else if(p.nodeType===1&&p.nodeName.toLowerCase()!=="object"){var F=p.getAttribute("id"),M=F||"__sizzle__";F||p.setAttribute("id",M);try{return C(p.querySelectorAll("#"+M+" "+m),q)}catch(N){}finally{F||
p.removeAttribute("id")}}return g(m,p,q,u)};for(var n in g)k[n]=g[n];i=null}}();(function(){var g=t.documentElement,i=g.matchesSelector||g.mozMatchesSelector||g.webkitMatchesSelector||g.msMatchesSelector,n=false;try{i.call(t.documentElement,"[test!='']:sizzle")}catch(m){n=true}if(i)k.matchesSelector=function(p,q){q=q.replace(/\=\s*([^'"\]]*)\s*\]/g,"='$1']");if(!k.isXML(p))try{if(n||!o.match.PSEUDO.test(q)&&!/!=/.test(q))return i.call(p,q)}catch(u){}return k(q,null,null,[p]).length>0}})();(function(){var g=
t.createElement("div");g.innerHTML="<div class='test e'></div><div class='test'></div>";if(!(!g.getElementsByClassName||g.getElementsByClassName("e").length===0)){g.lastChild.className="e";if(g.getElementsByClassName("e").length!==1){o.order.splice(1,0,"CLASS");o.find.CLASS=function(i,n,m){if(typeof n.getElementsByClassName!=="undefined"&&!m)return n.getElementsByClassName(i[1])};g=null}}})();k.contains=t.documentElement.contains?function(g,i){return g!==i&&(g.contains?g.contains(i):true)}:t.documentElement.compareDocumentPosition?
function(g,i){return!!(g.compareDocumentPosition(i)&16)}:function(){return false};k.isXML=function(g){return(g=(g?g.ownerDocument||g:0).documentElement)?g.nodeName!=="HTML":false};var L=function(g,i){for(var n,m=[],p="",q=i.nodeType?[i]:i;n=o.match.PSEUDO.exec(g);){p+=n[0];g=g.replace(o.match.PSEUDO,"")}g=o.relative[g]?g+"*":g;n=0;for(var u=q.length;n<u;n++)k(g,q[n],m);return k.filter(p,m)};c.find=k;c.expr=k.selectors;c.expr[":"]=c.expr.filters;c.unique=k.uniqueSort;c.text=k.getText;c.isXMLDoc=k.isXML;
c.contains=k.contains})();var Za=/Until$/,$a=/^(?:parents|prevUntil|prevAll)/,ab=/,/,Na=/^.[^:#\[\.,]*$/,bb=Array.prototype.slice,cb=c.expr.match.POS;c.fn.extend({find:function(a){for(var b=this.pushStack("","find",a),d=0,e=0,f=this.length;e<f;e++){d=b.length;c.find(a,this[e],b);if(e>0)for(var h=d;h<b.length;h++)for(var l=0;l<d;l++)if(b[l]===b[h]){b.splice(h--,1);break}}return b},has:function(a){var b=c(a);return this.filter(function(){for(var d=0,e=b.length;d<e;d++)if(c.contains(this,b[d]))return true})},
not:function(a){return this.pushStack(ma(this,a,false),"not",a)},filter:function(a){return this.pushStack(ma(this,a,true),"filter",a)},is:function(a){return!!a&&c.filter(a,this).length>0},closest:function(a,b){var d=[],e,f,h=this[0];if(c.isArray(a)){var l,k={},o=1;if(h&&a.length){e=0;for(f=a.length;e<f;e++){l=a[e];k[l]||(k[l]=c.expr.match.POS.test(l)?c(l,b||this.context):l)}for(;h&&h.ownerDocument&&h!==b;){for(l in k){e=k[l];if(e.jquery?e.index(h)>-1:c(h).is(e))d.push({selector:l,elem:h,level:o})}h=
h.parentNode;o++}}return d}l=cb.test(a)?c(a,b||this.context):null;e=0;for(f=this.length;e<f;e++)for(h=this[e];h;)if(l?l.index(h)>-1:c.find.matchesSelector(h,a)){d.push(h);break}else{h=h.parentNode;if(!h||!h.ownerDocument||h===b)break}d=d.length>1?c.unique(d):d;return this.pushStack(d,"closest",a)},index:function(a){if(!a||typeof a==="string")return c.inArray(this[0],a?c(a):this.parent().children());return c.inArray(a.jquery?a[0]:a,this)},add:function(a,b){var d=typeof a==="string"?c(a,b||this.context):
c.makeArray(a),e=c.merge(this.get(),d);return this.pushStack(!d[0]||!d[0].parentNode||d[0].parentNode.nodeType===11||!e[0]||!e[0].parentNode||e[0].parentNode.nodeType===11?e:c.unique(e))},andSelf:function(){return this.add(this.prevObject)}});c.each({parent:function(a){return(a=a.parentNode)&&a.nodeType!==11?a:null},parents:function(a){return c.dir(a,"parentNode")},parentsUntil:function(a,b,d){return c.dir(a,"parentNode",d)},next:function(a){return c.nth(a,2,"nextSibling")},prev:function(a){return c.nth(a,
2,"previousSibling")},nextAll:function(a){return c.dir(a,"nextSibling")},prevAll:function(a){return c.dir(a,"previousSibling")},nextUntil:function(a,b,d){return c.dir(a,"nextSibling",d)},prevUntil:function(a,b,d){return c.dir(a,"previousSibling",d)},siblings:function(a){return c.sibling(a.parentNode.firstChild,a)},children:function(a){return c.sibling(a.firstChild)},contents:function(a){return c.nodeName(a,"iframe")?a.contentDocument||a.contentWindow.document:c.makeArray(a.childNodes)}},function(a,
b){c.fn[a]=function(d,e){var f=c.map(this,b,d);Za.test(a)||(e=d);if(e&&typeof e==="string")f=c.filter(e,f);f=this.length>1?c.unique(f):f;if((this.length>1||ab.test(e))&&$a.test(a))f=f.reverse();return this.pushStack(f,a,bb.call(arguments).join(","))}});c.extend({filter:function(a,b,d){if(d)a=":not("+a+")";return b.length===1?c.find.matchesSelector(b[0],a)?[b[0]]:[]:c.find.matches(a,b)},dir:function(a,b,d){var e=[];for(a=a[b];a&&a.nodeType!==9&&(d===B||a.nodeType!==1||!c(a).is(d));){a.nodeType===1&&
e.push(a);a=a[b]}return e},nth:function(a,b,d){b=b||1;for(var e=0;a;a=a[d])if(a.nodeType===1&&++e===b)break;return a},sibling:function(a,b){for(var d=[];a;a=a.nextSibling)a.nodeType===1&&a!==b&&d.push(a);return d}});var za=/ jQuery\d+="(?:\d+|null)"/g,$=/^\s+/,Aa=/<(?!area|br|col|embed|hr|img|input|link|meta|param)(([\w:]+)[^>]*)\/>/ig,Ba=/<([\w:]+)/,db=/<tbody/i,eb=/<|&#?\w+;/,Ca=/<(?:script|object|embed|option|style)/i,Da=/checked\s*(?:[^=]|=\s*.checked.)/i,fb=/\=([^="'>\s]+\/)>/g,P={option:[1,
"<select multiple='multiple'>","</select>"],legend:[1,"<fieldset>","</fieldset>"],thead:[1,"<table>","</table>"],tr:[2,"<table><tbody>","</tbody></table>"],td:[3,"<table><tbody><tr>","</tr></tbody></table>"],col:[2,"<table><tbody></tbody><colgroup>","</colgroup></table>"],area:[1,"<map>","</map>"],_default:[0,"",""]};P.optgroup=P.option;P.tbody=P.tfoot=P.colgroup=P.caption=P.thead;P.th=P.td;if(!c.support.htmlSerialize)P._default=[1,"div<div>","</div>"];c.fn.extend({text:function(a){if(c.isFunction(a))return this.each(function(b){var d=
c(this);d.text(a.call(this,b,d.text()))});if(typeof a!=="object"&&a!==B)return this.empty().append((this[0]&&this[0].ownerDocument||t).createTextNode(a));return c.text(this)},wrapAll:function(a){if(c.isFunction(a))return this.each(function(d){c(this).wrapAll(a.call(this,d))});if(this[0]){var b=c(a,this[0].ownerDocument).eq(0).clone(true);this[0].parentNode&&b.insertBefore(this[0]);b.map(function(){for(var d=this;d.firstChild&&d.firstChild.nodeType===1;)d=d.firstChild;return d}).append(this)}return this},
wrapInner:function(a){if(c.isFunction(a))return this.each(function(b){c(this).wrapInner(a.call(this,b))});return this.each(function(){var b=c(this),d=b.contents();d.length?d.wrapAll(a):b.append(a)})},wrap:function(a){return this.each(function(){c(this).wrapAll(a)})},unwrap:function(){return this.parent().each(function(){c.nodeName(this,"body")||c(this).replaceWith(this.childNodes)}).end()},append:function(){return this.domManip(arguments,true,function(a){this.nodeType===1&&this.appendChild(a)})},
prepend:function(){return this.domManip(arguments,true,function(a){this.nodeType===1&&this.insertBefore(a,this.firstChild)})},before:function(){if(this[0]&&this[0].parentNode)return this.domManip(arguments,false,function(b){this.parentNode.insertBefore(b,this)});else if(arguments.length){var a=c(arguments[0]);a.push.apply(a,this.toArray());return this.pushStack(a,"before",arguments)}},after:function(){if(this[0]&&this[0].parentNode)return this.domManip(arguments,false,function(b){this.parentNode.insertBefore(b,
this.nextSibling)});else if(arguments.length){var a=this.pushStack(this,"after",arguments);a.push.apply(a,c(arguments[0]).toArray());return a}},remove:function(a,b){for(var d=0,e;(e=this[d])!=null;d++)if(!a||c.filter(a,[e]).length){if(!b&&e.nodeType===1){c.cleanData(e.getElementsByTagName("*"));c.cleanData([e])}e.parentNode&&e.parentNode.removeChild(e)}return this},empty:function(){for(var a=0,b;(b=this[a])!=null;a++)for(b.nodeType===1&&c.cleanData(b.getElementsByTagName("*"));b.firstChild;)b.removeChild(b.firstChild);
return this},clone:function(a){var b=this.map(function(){if(!c.support.noCloneEvent&&!c.isXMLDoc(this)){var d=this.outerHTML,e=this.ownerDocument;if(!d){d=e.createElement("div");d.appendChild(this.cloneNode(true));d=d.innerHTML}return c.clean([d.replace(za,"").replace(fb,'="$1">').replace($,"")],e)[0]}else return this.cloneNode(true)});if(a===true){na(this,b);na(this.find("*"),b.find("*"))}return b},html:function(a){if(a===B)return this[0]&&this[0].nodeType===1?this[0].innerHTML.replace(za,""):null;
else if(typeof a==="string"&&!Ca.test(a)&&(c.support.leadingWhitespace||!$.test(a))&&!P[(Ba.exec(a)||["",""])[1].toLowerCase()]){a=a.replace(Aa,"<$1></$2>");try{for(var b=0,d=this.length;b<d;b++)if(this[b].nodeType===1){c.cleanData(this[b].getElementsByTagName("*"));this[b].innerHTML=a}}catch(e){this.empty().append(a)}}else c.isFunction(a)?this.each(function(f){var h=c(this);h.html(a.call(this,f,h.html()))}):this.empty().append(a);return this},replaceWith:function(a){if(this[0]&&this[0].parentNode){if(c.isFunction(a))return this.each(function(b){var d=
c(this),e=d.html();d.replaceWith(a.call(this,b,e))});if(typeof a!=="string")a=c(a).detach();return this.each(function(){var b=this.nextSibling,d=this.parentNode;c(this).remove();b?c(b).before(a):c(d).append(a)})}else return this.pushStack(c(c.isFunction(a)?a():a),"replaceWith",a)},detach:function(a){return this.remove(a,true)},domManip:function(a,b,d){var e,f,h,l=a[0],k=[];if(!c.support.checkClone&&arguments.length===3&&typeof l==="string"&&Da.test(l))return this.each(function(){c(this).domManip(a,
b,d,true)});if(c.isFunction(l))return this.each(function(x){var r=c(this);a[0]=l.call(this,x,b?r.html():B);r.domManip(a,b,d)});if(this[0]){e=l&&l.parentNode;e=c.support.parentNode&&e&&e.nodeType===11&&e.childNodes.length===this.length?{fragment:e}:c.buildFragment(a,this,k);h=e.fragment;if(f=h.childNodes.length===1?h=h.firstChild:h.firstChild){b=b&&c.nodeName(f,"tr");f=0;for(var o=this.length;f<o;f++)d.call(b?c.nodeName(this[f],"table")?this[f].getElementsByTagName("tbody")[0]||this[f].appendChild(this[f].ownerDocument.createElement("tbody")):
this[f]:this[f],f>0||e.cacheable||this.length>1?h.cloneNode(true):h)}k.length&&c.each(k,Oa)}return this}});c.buildFragment=function(a,b,d){var e,f,h;b=b&&b[0]?b[0].ownerDocument||b[0]:t;if(a.length===1&&typeof a[0]==="string"&&a[0].length<512&&b===t&&!Ca.test(a[0])&&(c.support.checkClone||!Da.test(a[0]))){f=true;if(h=c.fragments[a[0]])if(h!==1)e=h}if(!e){e=b.createDocumentFragment();c.clean(a,b,e,d)}if(f)c.fragments[a[0]]=h?e:1;return{fragment:e,cacheable:f}};c.fragments={};c.each({appendTo:"append",
prependTo:"prepend",insertBefore:"before",insertAfter:"after",replaceAll:"replaceWith"},function(a,b){c.fn[a]=function(d){var e=[];d=c(d);var f=this.length===1&&this[0].parentNode;if(f&&f.nodeType===11&&f.childNodes.length===1&&d.length===1){d[b](this[0]);return this}else{f=0;for(var h=d.length;f<h;f++){var l=(f>0?this.clone(true):this).get();c(d[f])[b](l);e=e.concat(l)}return this.pushStack(e,a,d.selector)}}});c.extend({clean:function(a,b,d,e){b=b||t;if(typeof b.createElement==="undefined")b=b.ownerDocument||
b[0]&&b[0].ownerDocument||t;for(var f=[],h=0,l;(l=a[h])!=null;h++){if(typeof l==="number")l+="";if(l){if(typeof l==="string"&&!eb.test(l))l=b.createTextNode(l);else if(typeof l==="string"){l=l.replace(Aa,"<$1></$2>");var k=(Ba.exec(l)||["",""])[1].toLowerCase(),o=P[k]||P._default,x=o[0],r=b.createElement("div");for(r.innerHTML=o[1]+l+o[2];x--;)r=r.lastChild;if(!c.support.tbody){x=db.test(l);k=k==="table"&&!x?r.firstChild&&r.firstChild.childNodes:o[1]==="<table>"&&!x?r.childNodes:[];for(o=k.length-
1;o>=0;--o)c.nodeName(k[o],"tbody")&&!k[o].childNodes.length&&k[o].parentNode.removeChild(k[o])}!c.support.leadingWhitespace&&$.test(l)&&r.insertBefore(b.createTextNode($.exec(l)[0]),r.firstChild);l=r.childNodes}if(l.nodeType)f.push(l);else f=c.merge(f,l)}}if(d)for(h=0;f[h];h++)if(e&&c.nodeName(f[h],"script")&&(!f[h].type||f[h].type.toLowerCase()==="text/javascript"))e.push(f[h].parentNode?f[h].parentNode.removeChild(f[h]):f[h]);else{f[h].nodeType===1&&f.splice.apply(f,[h+1,0].concat(c.makeArray(f[h].getElementsByTagName("script"))));
d.appendChild(f[h])}return f},cleanData:function(a){for(var b,d,e=c.cache,f=c.event.special,h=c.support.deleteExpando,l=0,k;(k=a[l])!=null;l++)if(!(k.nodeName&&c.noData[k.nodeName.toLowerCase()]))if(d=k[c.expando]){if((b=e[d])&&b.events)for(var o in b.events)f[o]?c.event.remove(k,o):c.removeEvent(k,o,b.handle);if(h)delete k[c.expando];else k.removeAttribute&&k.removeAttribute(c.expando);delete e[d]}}});var Ea=/alpha\([^)]*\)/i,gb=/opacity=([^)]*)/,hb=/-([a-z])/ig,ib=/([A-Z])/g,Fa=/^-?\d+(?:px)?$/i,
jb=/^-?\d/,kb={position:"absolute",visibility:"hidden",display:"block"},Pa=["Left","Right"],Qa=["Top","Bottom"],W,Ga,aa,lb=function(a,b){return b.toUpperCase()};c.fn.css=function(a,b){if(arguments.length===2&&b===B)return this;return c.access(this,a,b,true,function(d,e,f){return f!==B?c.style(d,e,f):c.css(d,e)})};c.extend({cssHooks:{opacity:{get:function(a,b){if(b){var d=W(a,"opacity","opacity");return d===""?"1":d}else return a.style.opacity}}},cssNumber:{zIndex:true,fontWeight:true,opacity:true,
zoom:true,lineHeight:true},cssProps:{"float":c.support.cssFloat?"cssFloat":"styleFloat"},style:function(a,b,d,e){if(!(!a||a.nodeType===3||a.nodeType===8||!a.style)){var f,h=c.camelCase(b),l=a.style,k=c.cssHooks[h];b=c.cssProps[h]||h;if(d!==B){if(!(typeof d==="number"&&isNaN(d)||d==null)){if(typeof d==="number"&&!c.cssNumber[h])d+="px";if(!k||!("set"in k)||(d=k.set(a,d))!==B)try{l[b]=d}catch(o){}}}else{if(k&&"get"in k&&(f=k.get(a,false,e))!==B)return f;return l[b]}}},css:function(a,b,d){var e,f=c.camelCase(b),
h=c.cssHooks[f];b=c.cssProps[f]||f;if(h&&"get"in h&&(e=h.get(a,true,d))!==B)return e;else if(W)return W(a,b,f)},swap:function(a,b,d){var e={},f;for(f in b){e[f]=a.style[f];a.style[f]=b[f]}d.call(a);for(f in b)a.style[f]=e[f]},camelCase:function(a){return a.replace(hb,lb)}});c.curCSS=c.css;c.each(["height","width"],function(a,b){c.cssHooks[b]={get:function(d,e,f){var h;if(e){if(d.offsetWidth!==0)h=oa(d,b,f);else c.swap(d,kb,function(){h=oa(d,b,f)});if(h<=0){h=W(d,b,b);if(h==="0px"&&aa)h=aa(d,b,b);
if(h!=null)return h===""||h==="auto"?"0px":h}if(h<0||h==null){h=d.style[b];return h===""||h==="auto"?"0px":h}return typeof h==="string"?h:h+"px"}},set:function(d,e){if(Fa.test(e)){e=parseFloat(e);if(e>=0)return e+"px"}else return e}}});if(!c.support.opacity)c.cssHooks.opacity={get:function(a,b){return gb.test((b&&a.currentStyle?a.currentStyle.filter:a.style.filter)||"")?parseFloat(RegExp.$1)/100+"":b?"1":""},set:function(a,b){var d=a.style;d.zoom=1;var e=c.isNaN(b)?"":"alpha(opacity="+b*100+")",f=
d.filter||"";d.filter=Ea.test(f)?f.replace(Ea,e):d.filter+" "+e}};if(t.defaultView&&t.defaultView.getComputedStyle)Ga=function(a,b,d){var e;d=d.replace(ib,"-$1").toLowerCase();if(!(b=a.ownerDocument.defaultView))return B;if(b=b.getComputedStyle(a,null)){e=b.getPropertyValue(d);if(e===""&&!c.contains(a.ownerDocument.documentElement,a))e=c.style(a,d)}return e};if(t.documentElement.currentStyle)aa=function(a,b){var d,e,f=a.currentStyle&&a.currentStyle[b],h=a.style;if(!Fa.test(f)&&jb.test(f)){d=h.left;
e=a.runtimeStyle.left;a.runtimeStyle.left=a.currentStyle.left;h.left=b==="fontSize"?"1em":f||0;f=h.pixelLeft+"px";h.left=d;a.runtimeStyle.left=e}return f===""?"auto":f};W=Ga||aa;if(c.expr&&c.expr.filters){c.expr.filters.hidden=function(a){var b=a.offsetHeight;return a.offsetWidth===0&&b===0||!c.support.reliableHiddenOffsets&&(a.style.display||c.css(a,"display"))==="none"};c.expr.filters.visible=function(a){return!c.expr.filters.hidden(a)}}var mb=c.now(),nb=/<script\b[^<]*(?:(?!<\/script>)<[^<]*)*<\/script>/gi,
ob=/^(?:select|textarea)/i,pb=/^(?:color|date|datetime|email|hidden|month|number|password|range|search|tel|text|time|url|week)$/i,qb=/^(?:GET|HEAD)$/,Ra=/\[\]$/,T=/\=\?(&|$)/,ja=/\?/,rb=/([?&])_=[^&]*/,sb=/^(\w+:)?\/\/([^\/?#]+)/,tb=/%20/g,ub=/#.*$/,Ha=c.fn.load;c.fn.extend({load:function(a,b,d){if(typeof a!=="string"&&Ha)return Ha.apply(this,arguments);else if(!this.length)return this;var e=a.indexOf(" ");if(e>=0){var f=a.slice(e,a.length);a=a.slice(0,e)}e="GET";if(b)if(c.isFunction(b)){d=b;b=null}else if(typeof b===
"object"){b=c.param(b,c.ajaxSettings.traditional);e="POST"}var h=this;c.ajax({url:a,type:e,dataType:"html",data:b,complete:function(l,k){if(k==="success"||k==="notmodified")h.html(f?c("<div>").append(l.responseText.replace(nb,"")).find(f):l.responseText);d&&h.each(d,[l.responseText,k,l])}});return this},serialize:function(){return c.param(this.serializeArray())},serializeArray:function(){return this.map(function(){return this.elements?c.makeArray(this.elements):this}).filter(function(){return this.name&&
!this.disabled&&(this.checked||ob.test(this.nodeName)||pb.test(this.type))}).map(function(a,b){var d=c(this).val();return d==null?null:c.isArray(d)?c.map(d,function(e){return{name:b.name,value:e}}):{name:b.name,value:d}}).get()}});c.each("ajaxStart ajaxStop ajaxComplete ajaxError ajaxSuccess ajaxSend".split(" "),function(a,b){c.fn[b]=function(d){return this.bind(b,d)}});c.extend({get:function(a,b,d,e){if(c.isFunction(b)){e=e||d;d=b;b=null}return c.ajax({type:"GET",url:a,data:b,success:d,dataType:e})},
getScript:function(a,b){return c.get(a,null,b,"script")},getJSON:function(a,b,d){return c.get(a,b,d,"json")},post:function(a,b,d,e){if(c.isFunction(b)){e=e||d;d=b;b={}}return c.ajax({type:"POST",url:a,data:b,success:d,dataType:e})},ajaxSetup:function(a){c.extend(c.ajaxSettings,a)},ajaxSettings:{url:location.href,global:true,type:"GET",contentType:"application/x-www-form-urlencoded",processData:true,async:true,xhr:function(){return new E.XMLHttpRequest},accepts:{xml:"application/xml, text/xml",html:"text/html",
script:"text/javascript, application/javascript",json:"application/json, text/javascript",text:"text/plain",_default:"*/*"}},ajax:function(a){var b=c.extend(true,{},c.ajaxSettings,a),d,e,f,h=b.type.toUpperCase(),l=qb.test(h);b.url=b.url.replace(ub,"");b.context=a&&a.context!=null?a.context:b;if(b.data&&b.processData&&typeof b.data!=="string")b.data=c.param(b.data,b.traditional);if(b.dataType==="jsonp"){if(h==="GET")T.test(b.url)||(b.url+=(ja.test(b.url)?"&":"?")+(b.jsonp||"callback")+"=?");else if(!b.data||
!T.test(b.data))b.data=(b.data?b.data+"&":"")+(b.jsonp||"callback")+"=?";b.dataType="json"}if(b.dataType==="json"&&(b.data&&T.test(b.data)||T.test(b.url))){d=b.jsonpCallback||"jsonp"+mb++;if(b.data)b.data=(b.data+"").replace(T,"="+d+"$1");b.url=b.url.replace(T,"="+d+"$1");b.dataType="script";var k=E[d];E[d]=function(m){if(c.isFunction(k))k(m);else{E[d]=B;try{delete E[d]}catch(p){}}f=m;c.handleSuccess(b,w,e,f);c.handleComplete(b,w,e,f);r&&r.removeChild(A)}}if(b.dataType==="script"&&b.cache===null)b.cache=
false;if(b.cache===false&&l){var o=c.now(),x=b.url.replace(rb,"$1_="+o);b.url=x+(x===b.url?(ja.test(b.url)?"&":"?")+"_="+o:"")}if(b.data&&l)b.url+=(ja.test(b.url)?"&":"?")+b.data;b.global&&c.active++===0&&c.event.trigger("ajaxStart");o=(o=sb.exec(b.url))&&(o[1]&&o[1].toLowerCase()!==location.protocol||o[2].toLowerCase()!==location.host);if(b.dataType==="script"&&h==="GET"&&o){var r=t.getElementsByTagName("head")[0]||t.documentElement,A=t.createElement("script");if(b.scriptCharset)A.charset=b.scriptCharset;
A.src=b.url;if(!d){var C=false;A.onload=A.onreadystatechange=function(){if(!C&&(!this.readyState||this.readyState==="loaded"||this.readyState==="complete")){C=true;c.handleSuccess(b,w,e,f);c.handleComplete(b,w,e,f);A.onload=A.onreadystatechange=null;r&&A.parentNode&&r.removeChild(A)}}}r.insertBefore(A,r.firstChild);return B}var J=false,w=b.xhr();if(w){b.username?w.open(h,b.url,b.async,b.username,b.password):w.open(h,b.url,b.async);try{if(b.data!=null&&!l||a&&a.contentType)w.setRequestHeader("Content-Type",
b.contentType);if(b.ifModified){c.lastModified[b.url]&&w.setRequestHeader("If-Modified-Since",c.lastModified[b.url]);c.etag[b.url]&&w.setRequestHeader("If-None-Match",c.etag[b.url])}o||w.setRequestHeader("X-Requested-With","XMLHttpRequest");w.setRequestHeader("Accept",b.dataType&&b.accepts[b.dataType]?b.accepts[b.dataType]+", */*; q=0.01":b.accepts._default)}catch(I){}if(b.beforeSend&&b.beforeSend.call(b.context,w,b)===false){b.global&&c.active--===1&&c.event.trigger("ajaxStop");w.abort();return false}b.global&&
c.triggerGlobal(b,"ajaxSend",[w,b]);var L=w.onreadystatechange=function(m){if(!w||w.readyState===0||m==="abort"){J||c.handleComplete(b,w,e,f);J=true;if(w)w.onreadystatechange=c.noop}else if(!J&&w&&(w.readyState===4||m==="timeout")){J=true;w.onreadystatechange=c.noop;e=m==="timeout"?"timeout":!c.httpSuccess(w)?"error":b.ifModified&&c.httpNotModified(w,b.url)?"notmodified":"success";var p;if(e==="success")try{f=c.httpData(w,b.dataType,b)}catch(q){e="parsererror";p=q}if(e==="success"||e==="notmodified")d||
c.handleSuccess(b,w,e,f);else c.handleError(b,w,e,p);d||c.handleComplete(b,w,e,f);m==="timeout"&&w.abort();if(b.async)w=null}};try{var g=w.abort;w.abort=function(){w&&Function.prototype.call.call(g,w);L("abort")}}catch(i){}b.async&&b.timeout>0&&setTimeout(function(){w&&!J&&L("timeout")},b.timeout);try{w.send(l||b.data==null?null:b.data)}catch(n){c.handleError(b,w,null,n);c.handleComplete(b,w,e,f)}b.async||L();return w}},param:function(a,b){var d=[],e=function(h,l){l=c.isFunction(l)?l():l;d[d.length]=
encodeURIComponent(h)+"="+encodeURIComponent(l)};if(b===B)b=c.ajaxSettings.traditional;if(c.isArray(a)||a.jquery)c.each(a,function(){e(this.name,this.value)});else for(var f in a)da(f,a[f],b,e);return d.join("&").replace(tb,"+")}});c.extend({active:0,lastModified:{},etag:{},handleError:function(a,b,d,e){a.error&&a.error.call(a.context,b,d,e);a.global&&c.triggerGlobal(a,"ajaxError",[b,a,e])},handleSuccess:function(a,b,d,e){a.success&&a.success.call(a.context,e,d,b);a.global&&c.triggerGlobal(a,"ajaxSuccess",
[b,a])},handleComplete:function(a,b,d){a.complete&&a.complete.call(a.context,b,d);a.global&&c.triggerGlobal(a,"ajaxComplete",[b,a]);a.global&&c.active--===1&&c.event.trigger("ajaxStop")},triggerGlobal:function(a,b,d){(a.context&&a.context.url==null?c(a.context):c.event).trigger(b,d)},httpSuccess:function(a){try{return!a.status&&location.protocol==="file:"||a.status>=200&&a.status<300||a.status===304||a.status===1223}catch(b){}return false},httpNotModified:function(a,b){var d=a.getResponseHeader("Last-Modified"),
e=a.getResponseHeader("Etag");if(d)c.lastModified[b]=d;if(e)c.etag[b]=e;return a.status===304},httpData:function(a,b,d){var e=a.getResponseHeader("content-type")||"",f=b==="xml"||!b&&e.indexOf("xml")>=0;a=f?a.responseXML:a.responseText;f&&a.documentElement.nodeName==="parsererror"&&c.error("parsererror");if(d&&d.dataFilter)a=d.dataFilter(a,b);if(typeof a==="string")if(b==="json"||!b&&e.indexOf("json")>=0)a=c.parseJSON(a);else if(b==="script"||!b&&e.indexOf("javascript")>=0)c.globalEval(a);return a}});
if(E.ActiveXObject)c.ajaxSettings.xhr=function(){if(E.location.protocol!=="file:")try{return new E.XMLHttpRequest}catch(a){}try{return new E.ActiveXObject("Microsoft.XMLHTTP")}catch(b){}};c.support.ajax=!!c.ajaxSettings.xhr();var ea={},vb=/^(?:toggle|show|hide)$/,wb=/^([+\-]=)?([\d+.\-]+)(.*)$/,ba,pa=[["height","marginTop","marginBottom","paddingTop","paddingBottom"],["width","marginLeft","marginRight","paddingLeft","paddingRight"],["opacity"]];c.fn.extend({show:function(a,b,d){if(a||a===0)return this.animate(S("show",
3),a,b,d);else{d=0;for(var e=this.length;d<e;d++){a=this[d];b=a.style.display;if(!c.data(a,"olddisplay")&&b==="none")b=a.style.display="";b===""&&c.css(a,"display")==="none"&&c.data(a,"olddisplay",qa(a.nodeName))}for(d=0;d<e;d++){a=this[d];b=a.style.display;if(b===""||b==="none")a.style.display=c.data(a,"olddisplay")||""}return this}},hide:function(a,b,d){if(a||a===0)return this.animate(S("hide",3),a,b,d);else{a=0;for(b=this.length;a<b;a++){d=c.css(this[a],"display");d!=="none"&&c.data(this[a],"olddisplay",
d)}for(a=0;a<b;a++)this[a].style.display="none";return this}},_toggle:c.fn.toggle,toggle:function(a,b,d){var e=typeof a==="boolean";if(c.isFunction(a)&&c.isFunction(b))this._toggle.apply(this,arguments);else a==null||e?this.each(function(){var f=e?a:c(this).is(":hidden");c(this)[f?"show":"hide"]()}):this.animate(S("toggle",3),a,b,d);return this},fadeTo:function(a,b,d,e){return this.filter(":hidden").css("opacity",0).show().end().animate({opacity:b},a,d,e)},animate:function(a,b,d,e){var f=c.speed(b,
d,e);if(c.isEmptyObject(a))return this.each(f.complete);return this[f.queue===false?"each":"queue"](function(){var h=c.extend({},f),l,k=this.nodeType===1,o=k&&c(this).is(":hidden"),x=this;for(l in a){var r=c.camelCase(l);if(l!==r){a[r]=a[l];delete a[l];l=r}if(a[l]==="hide"&&o||a[l]==="show"&&!o)return h.complete.call(this);if(k&&(l==="height"||l==="width")){h.overflow=[this.style.overflow,this.style.overflowX,this.style.overflowY];if(c.css(this,"display")==="inline"&&c.css(this,"float")==="none")if(c.support.inlineBlockNeedsLayout)if(qa(this.nodeName)===
"inline")this.style.display="inline-block";else{this.style.display="inline";this.style.zoom=1}else this.style.display="inline-block"}if(c.isArray(a[l])){(h.specialEasing=h.specialEasing||{})[l]=a[l][1];a[l]=a[l][0]}}if(h.overflow!=null)this.style.overflow="hidden";h.curAnim=c.extend({},a);c.each(a,function(A,C){var J=new c.fx(x,h,A);if(vb.test(C))J[C==="toggle"?o?"show":"hide":C](a);else{var w=wb.exec(C),I=J.cur()||0;if(w){var L=parseFloat(w[2]),g=w[3]||"px";if(g!=="px"){c.style(x,A,(L||1)+g);I=(L||
1)/J.cur()*I;c.style(x,A,I+g)}if(w[1])L=(w[1]==="-="?-1:1)*L+I;J.custom(I,L,g)}else J.custom(I,C,"")}});return true})},stop:function(a,b){var d=c.timers;a&&this.queue([]);this.each(function(){for(var e=d.length-1;e>=0;e--)if(d[e].elem===this){b&&d[e](true);d.splice(e,1)}});b||this.dequeue();return this}});c.each({slideDown:S("show",1),slideUp:S("hide",1),slideToggle:S("toggle",1),fadeIn:{opacity:"show"},fadeOut:{opacity:"hide"},fadeToggle:{opacity:"toggle"}},function(a,b){c.fn[a]=function(d,e,f){return this.animate(b,
d,e,f)}});c.extend({speed:function(a,b,d){var e=a&&typeof a==="object"?c.extend({},a):{complete:d||!d&&b||c.isFunction(a)&&a,duration:a,easing:d&&b||b&&!c.isFunction(b)&&b};e.duration=c.fx.off?0:typeof e.duration==="number"?e.duration:e.duration in c.fx.speeds?c.fx.speeds[e.duration]:c.fx.speeds._default;e.old=e.complete;e.complete=function(){e.queue!==false&&c(this).dequeue();c.isFunction(e.old)&&e.old.call(this)};return e},easing:{linear:function(a,b,d,e){return d+e*a},swing:function(a,b,d,e){return(-Math.cos(a*
Math.PI)/2+0.5)*e+d}},timers:[],fx:function(a,b,d){this.options=b;this.elem=a;this.prop=d;if(!b.orig)b.orig={}}});c.fx.prototype={update:function(){this.options.step&&this.options.step.call(this.elem,this.now,this);(c.fx.step[this.prop]||c.fx.step._default)(this)},cur:function(){if(this.elem[this.prop]!=null&&(!this.elem.style||this.elem.style[this.prop]==null))return this.elem[this.prop];var a=parseFloat(c.css(this.elem,this.prop));return a&&a>-1E4?a:0},custom:function(a,b,d){function e(l){return f.step(l)}
var f=this,h=c.fx;this.startTime=c.now();this.start=a;this.end=b;this.unit=d||this.unit||"px";this.now=this.start;this.pos=this.state=0;e.elem=this.elem;if(e()&&c.timers.push(e)&&!ba)ba=setInterval(h.tick,h.interval)},show:function(){this.options.orig[this.prop]=c.style(this.elem,this.prop);this.options.show=true;this.custom(this.prop==="width"||this.prop==="height"?1:0,this.cur());c(this.elem).show()},hide:function(){this.options.orig[this.prop]=c.style(this.elem,this.prop);this.options.hide=true;
this.custom(this.cur(),0)},step:function(a){var b=c.now(),d=true;if(a||b>=this.options.duration+this.startTime){this.now=this.end;this.pos=this.state=1;this.update();this.options.curAnim[this.prop]=true;for(var e in this.options.curAnim)if(this.options.curAnim[e]!==true)d=false;if(d){if(this.options.overflow!=null&&!c.support.shrinkWrapBlocks){var f=this.elem,h=this.options;c.each(["","X","Y"],function(k,o){f.style["overflow"+o]=h.overflow[k]})}this.options.hide&&c(this.elem).hide();if(this.options.hide||
this.options.show)for(var l in this.options.curAnim)c.style(this.elem,l,this.options.orig[l]);this.options.complete.call(this.elem)}return false}else{a=b-this.startTime;this.state=a/this.options.duration;b=this.options.easing||(c.easing.swing?"swing":"linear");this.pos=c.easing[this.options.specialEasing&&this.options.specialEasing[this.prop]||b](this.state,a,0,1,this.options.duration);this.now=this.start+(this.end-this.start)*this.pos;this.update()}return true}};c.extend(c.fx,{tick:function(){for(var a=
c.timers,b=0;b<a.length;b++)a[b]()||a.splice(b--,1);a.length||c.fx.stop()},interval:13,stop:function(){clearInterval(ba);ba=null},speeds:{slow:600,fast:200,_default:400},step:{opacity:function(a){c.style(a.elem,"opacity",a.now)},_default:function(a){if(a.elem.style&&a.elem.style[a.prop]!=null)a.elem.style[a.prop]=(a.prop==="width"||a.prop==="height"?Math.max(0,a.now):a.now)+a.unit;else a.elem[a.prop]=a.now}}});if(c.expr&&c.expr.filters)c.expr.filters.animated=function(a){return c.grep(c.timers,function(b){return a===
b.elem}).length};var xb=/^t(?:able|d|h)$/i,Ia=/^(?:body|html)$/i;c.fn.offset="getBoundingClientRect"in t.documentElement?function(a){var b=this[0],d;if(a)return this.each(function(l){c.offset.setOffset(this,a,l)});if(!b||!b.ownerDocument)return null;if(b===b.ownerDocument.body)return c.offset.bodyOffset(b);try{d=b.getBoundingClientRect()}catch(e){}var f=b.ownerDocument,h=f.documentElement;if(!d||!c.contains(h,b))return d||{top:0,left:0};b=f.body;f=fa(f);return{top:d.top+(f.pageYOffset||c.support.boxModel&&
h.scrollTop||b.scrollTop)-(h.clientTop||b.clientTop||0),left:d.left+(f.pageXOffset||c.support.boxModel&&h.scrollLeft||b.scrollLeft)-(h.clientLeft||b.clientLeft||0)}}:function(a){var b=this[0];if(a)return this.each(function(x){c.offset.setOffset(this,a,x)});if(!b||!b.ownerDocument)return null;if(b===b.ownerDocument.body)return c.offset.bodyOffset(b);c.offset.initialize();var d,e=b.offsetParent,f=b.ownerDocument,h=f.documentElement,l=f.body;d=(f=f.defaultView)?f.getComputedStyle(b,null):b.currentStyle;
for(var k=b.offsetTop,o=b.offsetLeft;(b=b.parentNode)&&b!==l&&b!==h;){if(c.offset.supportsFixedPosition&&d.position==="fixed")break;d=f?f.getComputedStyle(b,null):b.currentStyle;k-=b.scrollTop;o-=b.scrollLeft;if(b===e){k+=b.offsetTop;o+=b.offsetLeft;if(c.offset.doesNotAddBorder&&!(c.offset.doesAddBorderForTableAndCells&&xb.test(b.nodeName))){k+=parseFloat(d.borderTopWidth)||0;o+=parseFloat(d.borderLeftWidth)||0}e=b.offsetParent}if(c.offset.subtractsBorderForOverflowNotVisible&&d.overflow!=="visible"){k+=
parseFloat(d.borderTopWidth)||0;o+=parseFloat(d.borderLeftWidth)||0}d=d}if(d.position==="relative"||d.position==="static"){k+=l.offsetTop;o+=l.offsetLeft}if(c.offset.supportsFixedPosition&&d.position==="fixed"){k+=Math.max(h.scrollTop,l.scrollTop);o+=Math.max(h.scrollLeft,l.scrollLeft)}return{top:k,left:o}};c.offset={initialize:function(){var a=t.body,b=t.createElement("div"),d,e,f,h=parseFloat(c.css(a,"marginTop"))||0;c.extend(b.style,{position:"absolute",top:0,left:0,margin:0,border:0,width:"1px",
height:"1px",visibility:"hidden"});b.innerHTML="<div style='position:absolute;top:0;left:0;margin:0;border:5px solid #000;padding:0;width:1px;height:1px;'><div></div></div><table style='position:absolute;top:0;left:0;margin:0;border:5px solid #000;padding:0;width:1px;height:1px;' cellpadding='0' cellspacing='0'><tr><td></td></tr></table>";a.insertBefore(b,a.firstChild);d=b.firstChild;e=d.firstChild;f=d.nextSibling.firstChild.firstChild;this.doesNotAddBorder=e.offsetTop!==5;this.doesAddBorderForTableAndCells=
f.offsetTop===5;e.style.position="fixed";e.style.top="20px";this.supportsFixedPosition=e.offsetTop===20||e.offsetTop===15;e.style.position=e.style.top="";d.style.overflow="hidden";d.style.position="relative";this.subtractsBorderForOverflowNotVisible=e.offsetTop===-5;this.doesNotIncludeMarginInBodyOffset=a.offsetTop!==h;a.removeChild(b);c.offset.initialize=c.noop},bodyOffset:function(a){var b=a.offsetTop,d=a.offsetLeft;c.offset.initialize();if(c.offset.doesNotIncludeMarginInBodyOffset){b+=parseFloat(c.css(a,
"marginTop"))||0;d+=parseFloat(c.css(a,"marginLeft"))||0}return{top:b,left:d}},setOffset:function(a,b,d){var e=c.css(a,"position");if(e==="static")a.style.position="relative";var f=c(a),h=f.offset(),l=c.css(a,"top"),k=c.css(a,"left"),o=e==="absolute"&&c.inArray("auto",[l,k])>-1;e={};var x={};if(o)x=f.position();l=o?x.top:parseInt(l,10)||0;k=o?x.left:parseInt(k,10)||0;if(c.isFunction(b))b=b.call(a,d,h);if(b.top!=null)e.top=b.top-h.top+l;if(b.left!=null)e.left=b.left-h.left+k;"using"in b?b.using.call(a,
e):f.css(e)}};c.fn.extend({position:function(){if(!this[0])return null;var a=this[0],b=this.offsetParent(),d=this.offset(),e=Ia.test(b[0].nodeName)?{top:0,left:0}:b.offset();d.top-=parseFloat(c.css(a,"marginTop"))||0;d.left-=parseFloat(c.css(a,"marginLeft"))||0;e.top+=parseFloat(c.css(b[0],"borderTopWidth"))||0;e.left+=parseFloat(c.css(b[0],"borderLeftWidth"))||0;return{top:d.top-e.top,left:d.left-e.left}},offsetParent:function(){return this.map(function(){for(var a=this.offsetParent||t.body;a&&!Ia.test(a.nodeName)&&
c.css(a,"position")==="static";)a=a.offsetParent;return a})}});c.each(["Left","Top"],function(a,b){var d="scroll"+b;c.fn[d]=function(e){var f=this[0],h;if(!f)return null;if(e!==B)return this.each(function(){if(h=fa(this))h.scrollTo(!a?e:c(h).scrollLeft(),a?e:c(h).scrollTop());else this[d]=e});else return(h=fa(f))?"pageXOffset"in h?h[a?"pageYOffset":"pageXOffset"]:c.support.boxModel&&h.document.documentElement[d]||h.document.body[d]:f[d]}});c.each(["Height","Width"],function(a,b){var d=b.toLowerCase();
c.fn["inner"+b]=function(){return this[0]?parseFloat(c.css(this[0],d,"padding")):null};c.fn["outer"+b]=function(e){return this[0]?parseFloat(c.css(this[0],d,e?"margin":"border")):null};c.fn[d]=function(e){var f=this[0];if(!f)return e==null?null:this;if(c.isFunction(e))return this.each(function(l){var k=c(this);k[d](e.call(this,l,k[d]()))});if(c.isWindow(f))return f.document.compatMode==="CSS1Compat"&&f.document.documentElement["client"+b]||f.document.body["client"+b];else if(f.nodeType===9)return Math.max(f.documentElement["client"+
b],f.body["scroll"+b],f.documentElement["scroll"+b],f.body["offset"+b],f.documentElement["offset"+b]);else if(e===B){f=c.css(f,d);var h=parseFloat(f);return c.isNaN(h)?f:h}else return this.css(d,typeof e==="string"?e:e+"px")}})})(window);
</script><script type="text/javascript">//XRegExp 1.5.0 <xregexp.com> MIT License
var XRegExp;if(XRegExp){throw Error("can't load XRegExp twice in the same frame")}(function(){XRegExp=function(w,r){var q=[],u=XRegExp.OUTSIDE_CLASS,x=0,p,s,v,t,y;if(XRegExp.isRegExp(w)){if(r!==undefined){throw TypeError("can't supply flags when constructing one RegExp from another")}return j(w)}if(g){throw Error("can't call the XRegExp constructor within token definition functions")}r=r||"";p={hasNamedCapture:false,captureNames:[],hasFlag:function(z){return r.indexOf(z)>-1},setFlag:function(z){r+=z}};while(x<w.length){s=o(w,x,u,p);if(s){q.push(s.output);x+=(s.match[0].length||1)}else{if(v=m.exec.call(i[u],w.slice(x))){q.push(v[0]);x+=v[0].length}else{t=w.charAt(x);if(t==="["){u=XRegExp.INSIDE_CLASS}else{if(t==="]"){u=XRegExp.OUTSIDE_CLASS}}q.push(t);x++}}}y=RegExp(q.join(""),m.replace.call(r,h,""));y._xregexp={source:w,captureNames:p.hasNamedCapture?p.captureNames:null};return y};XRegExp.version="1.5.0";XRegExp.INSIDE_CLASS=1;XRegExp.OUTSIDE_CLASS=2;var c=/\$(?:(\d\d?|[$&`'])|{([$\w]+)})/g,h=/[^gimy]+|([\s\S])(?=[\s\S]*\1)/g,n=/^(?:[?*+]|{\d+(?:,\d*)?})\??/,g=false,k=[],m={exec:RegExp.prototype.exec,test:RegExp.prototype.test,match:String.prototype.match,replace:String.prototype.replace,split:String.prototype.split},a=m.exec.call(/()??/,"")[1]===undefined,e=function(){var p=/^/g;m.test.call(p,"");return !p.lastIndex}(),f=function(){var p=/x/g;m.replace.call("x",p,"");return !p.lastIndex}(),b=RegExp.prototype.sticky!==undefined,i={};i[XRegExp.INSIDE_CLASS]=/^(?:\\(?:[0-3][0-7]{0,2}|[4-7][0-7]?|x[\dA-Fa-f]{2}|u[\dA-Fa-f]{4}|c[A-Za-z]|[\s\S]))/;i[XRegExp.OUTSIDE_CLASS]=/^(?:\\(?:0(?:[0-3][0-7]{0,2}|[4-7][0-7]?)?|[1-9]\d*|x[\dA-Fa-f]{2}|u[\dA-Fa-f]{4}|c[A-Za-z]|[\s\S])|\(\?[:=!]|[?*+]\?|{\d+(?:,\d*)?}\??)/;XRegExp.addToken=function(s,r,q,p){k.push({pattern:j(s,"g"+(b?"y":"")),handler:r,scope:q||XRegExp.OUTSIDE_CLASS,trigger:p||null})};XRegExp.cache=function(r,p){var q=r+"/"+(p||"");return XRegExp.cache[q]||(XRegExp.cache[q]=XRegExp(r,p))};XRegExp.copyAsGlobal=function(p){return j(p,"g")};XRegExp.escape=function(p){return p.replace(/[-[\]{}()*+?.,\\^$|#\s]/g,"\\$&")};XRegExp.execAt=function(s,r,t,q){r=j(r,"g"+((q&&b)?"y":""));r.lastIndex=t=t||0;var p=r.exec(s);if(q){return(p&&p.index===t)?p:null}else{return p}};XRegExp.freezeTokens=function(){XRegExp.addToken=function(){throw Error("can't run addToken after freezeTokens")}};XRegExp.isRegExp=function(p){return Object.prototype.toString.call(p)==="[object RegExp]"};XRegExp.iterate=function(u,p,v,s){var t=j(p,"g"),r=-1,q;while(q=t.exec(u)){v.call(s,q,++r,u,t);if(t.lastIndex===q.index){t.lastIndex++}}if(p.global){p.lastIndex=0}};XRegExp.matchChain=function(q,p){return function r(s,x){var v=p[x].regex?p[x]:{regex:p[x]},u=j(v.regex,"g"),w=[],t;for(t=0;t<s.length;t++){XRegExp.iterate(s[t],u,function(y){w.push(v.backref?(y[v.backref]||""):y[0])})}return((x===p.length-1)||!w.length)?w:r(w,x+1)}([q],0)};RegExp.prototype.apply=function(q,p){return this.exec(p[0])};RegExp.prototype.call=function(p,q){return this.exec(q)};RegExp.prototype.exec=function(t){var r=m.exec.apply(this,arguments),q,p;if(r){if(!a&&r.length>1&&l(r,"")>-1){p=RegExp(this.source,m.replace.call(d(this),"g",""));m.replace.call(t.slice(r.index),p,function(){for(var u=1;u<arguments.length-2;u++){if(arguments[u]===undefined){r[u]=undefined}}})}if(this._xregexp&&this._xregexp.captureNames){for(var s=1;s<r.length;s++){q=this._xregexp.captureNames[s-1];if(q){r[q]=r[s]}}}if(!e&&this.global&&!r[0].length&&(this.lastIndex>r.index)){this.lastIndex--}}return r};if(!e){RegExp.prototype.test=function(q){var p=m.exec.call(this,q);if(p&&this.global&&!p[0].length&&(this.lastIndex>p.index)){this.lastIndex--}return !!p}}String.prototype.match=function(q){if(!XRegExp.isRegExp(q)){q=RegExp(q)}if(q.global){var p=m.match.apply(this,arguments);q.lastIndex=0;return p}return q.exec(this)};String.prototype.replace=function(r,s){var t=XRegExp.isRegExp(r),q,p,u;if(t&&typeof s.valueOf()==="string"&&s.indexOf("${")===-1&&f){return m.replace.apply(this,arguments)}if(!t){r=r+""}else{if(r._xregexp){q=r._xregexp.captureNames}}if(typeof s==="function"){p=m.replace.call(this,r,function(){if(q){arguments[0]=new String(arguments[0]);for(var v=0;v<q.length;v++){if(q[v]){arguments[0][q[v]]=arguments[v+1]}}}if(t&&r.global){r.lastIndex=arguments[arguments.length-2]+arguments[0].length}return s.apply(null,arguments)})}else{u=this+"";p=m.replace.call(u,r,function(){var v=arguments;return m.replace.call(s,c,function(x,w,A){if(w){switch(w){case"$":return"$";case"&":return v[0];case"`":return v[v.length-1].slice(0,v[v.length-2]);case"'":return v[v.length-1].slice(v[v.length-2]+v[0].length);default:var y="";w=+w;if(!w){return x}while(w>v.length-3){y=String.prototype.slice.call(w,-1)+y;w=Math.floor(w/10)}return(w?v[w]||"":"$")+y}}else{var z=+A;if(z<=v.length-3){return v[z]}z=q?l(q,A):-1;return z>-1?v[z+1]:x}})})}if(t&&r.global){r.lastIndex=0}return p};String.prototype.split=function(u,p){if(!XRegExp.isRegExp(u)){return m.split.apply(this,arguments)}var w=this+"",r=[],v=0,t,q;if(p===undefined||+p<0){p=Infinity}else{p=Math.floor(+p);if(!p){return[]}}u=XRegExp.copyAsGlobal(u);while(t=u.exec(w)){if(u.lastIndex>v){r.push(w.slice(v,t.index));if(t.length>1&&t.index<w.length){Array.prototype.push.apply(r,t.slice(1))}q=t[0].length;v=u.lastIndex;if(r.length>=p){break}}if(u.lastIndex===t.index){u.lastIndex++}}if(v===w.length){if(!m.test.call(u,"")||q){r.push("")}}else{r.push(w.slice(v))}return r.length>p?r.slice(0,p):r};function j(r,q){if(!XRegExp.isRegExp(r)){throw TypeError("type RegExp expected")}var p=r._xregexp;r=XRegExp(r.source,d(r)+(q||""));if(p){r._xregexp={source:p.source,captureNames:p.captureNames?p.captureNames.slice(0):null}}return r}function d(p){return(p.global?"g":"")+(p.ignoreCase?"i":"")+(p.multiline?"m":"")+(p.extended?"x":"")+(p.sticky?"y":"")}function o(v,u,w,p){var r=k.length,y,s,x;g=true;try{while(r--){x=k[r];if((w&x.scope)&&(!x.trigger||x.trigger.call(p))){x.pattern.lastIndex=u;s=x.pattern.exec(v);if(s&&s.index===u){y={output:x.handler.call(p,s,w),match:s};break}}}}catch(q){throw q}finally{g=false}return y}function l(s,q,r){if(Array.prototype.indexOf){return s.indexOf(q,r)}for(var p=r||0;p<s.length;p++){if(s[p]===q){return p}}return -1}XRegExp.addToken(/\(\?#[^)]*\)/,function(p){return m.test.call(n,p.input.slice(p.index+p[0].length))?"":"(?:)"});XRegExp.addToken(/\((?!\?)/,function(){this.captureNames.push(null);return"("});XRegExp.addToken(/\(\?<([$\w]+)>/,function(p){this.captureNames.push(p[1]);this.hasNamedCapture=true;return"("});XRegExp.addToken(/\\k<([\w$]+)>/,function(q){var p=l(this.captureNames,q[1]);return p>-1?"\\"+(p+1)+(isNaN(q.input.charAt(q.index+q[0].length))?"":"(?:)"):q[0]});XRegExp.addToken(/\[\^?]/,function(p){return p[0]==="[]"?"\\b\\B":"[\\s\\S]"});XRegExp.addToken(/^\(\?([imsx]+)\)/,function(p){this.setFlag(p[1]);return""});XRegExp.addToken(/(?:\s+|#.*)+/,function(p){return m.test.call(n,p.input.slice(p.index+p[0].length))?"":"(?:)"},XRegExp.OUTSIDE_CLASS,function(){return this.hasFlag("x")});XRegExp.addToken(/\./,function(){return"[\\s\\S]"},XRegExp.OUTSIDE_CLASS,function(){return this.hasFlag("s")})})();
</script><script type="text/javascript">/**
 * SyntaxHighlighter
 * http://alexgorbatchev.com/SyntaxHighlighter
 *
 * SyntaxHighlighter is donationware. If you are using it, please donate.
 * http://alexgorbatchev.com/SyntaxHighlighter/donate.html
 *
 * @version
 * 3.0.83 (July 02 2010)
 * 
 * @copyright
 * Copyright (C) 2004-2010 Alex Gorbatchev.
 *
 * @license
 * Dual licensed under the MIT and GPL licenses.
 */
//
// Begin anonymous function. This is used to contain local scope variables without polutting global scope.
//
var SyntaxHighlighter = function() { 

// CommonJS
if (typeof(require) != 'undefined' && typeof(XRegExp) == 'undefined')
{
	XRegExp = require('XRegExp').XRegExp;
}

// Shortcut object which will be assigned to the SyntaxHighlighter variable.
// This is a shorthand for local reference in order to avoid long namespace 
// references to SyntaxHighlighter.whatever...
var sh = {
	defaults : {
		/** Additional CSS class names to be added to highlighter elements. */
		'class-name' : '',
		
		/** First line number. */
		'first-line' : 1,
		
		/**
		 * Pads line numbers. Possible values are:
		 *
		 *   false - don't pad line numbers.
		 *   true  - automaticaly pad numbers with minimum required number of leading zeroes.
		 *   [int] - length up to which pad line numbers.
		 */
		'pad-line-numbers' : false,
		
		/** Lines to highlight. */
		'highlight' : null,
		
		/** Title to be displayed above the code block. */
		'title' : null,
		
		/** Enables or disables smart tabs. */
		'smart-tabs' : true,
		
		/** Gets or sets tab size. */
		'tab-size' : 4,
		
		/** Enables or disables gutter. */
		'gutter' : true,
		
		/** Enables or disables toolbar. */
		'toolbar' : true,
		
		/** Enables quick code copy and paste from double click. */
		'quick-code' : true,
		
		/** Forces code view to be collapsed. */
		'collapse' : false,
		
		/** Enables or disables automatic links. */
		'auto-links' : true,
		
		/** Gets or sets light mode. Equavalent to turning off gutter and toolbar. */
		'light' : false,
		
		'html-script' : false
	},
	
	config : {
		space : '&nbsp;',
		
		/** Enables use of <SCRIPT type="syntaxhighlighter" /> tags. */
		useScriptTags : true,
		
		/** Blogger mode flag. */
		bloggerMode : false,
		
		stripBrs : false,
		
		/** Name of the tag that SyntaxHighlighter will automatically look for. */
		tagName : 'pre',
		
		strings : {
			expandSource : 'expand source',
			help : '?',
			alert: 'SyntaxHighlighter\n\n',
			noBrush : 'Can\'t find brush for: ',
			brushNotHtmlScript : 'Brush wasn\'t configured for html-script option: ',
			
			// this is populated by the build script
			aboutDialog : '<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><title>About SyntaxHighlighter</title></head><body style="font-family:Geneva,Arial,Helvetica,sans-serif;background-color:#fff;color:#000;font-size:1em;text-align:center;"><div style="text-align:center;margin-top:1.5em;"><div style="font-size:xx-large;">SyntaxHighlighter</div><div style="font-size:.75em;margin-bottom:3em;"><div>version 3.0.83 (July 02 2010)</div><div><a href="http://alexgorbatchev.com/SyntaxHighlighter" target="_blank" style="color:#005896">http://alexgorbatchev.com/SyntaxHighlighter</a></div><div>JavaScript code syntax highlighter.</div><div>Copyright 2004-2010 Alex Gorbatchev.</div></div><div>If you like this script, please <a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=2930402" style="color:#005896">donate</a> to <br/>keep development active!</div></div></body></html>'
		}
	},
	
	/** Internal 'global' variables. */
	vars : {
		discoveredBrushes : null,
		highlighters : {}
	},
	
	/** This object is populated by user included external brush files. */
	brushes : {},

	/** Common regular expressions. */
	regexLib : {
		multiLineCComments			: /\/\*[\s\S]*?\*\//gm,
		singleLineCComments			: /\/\/.*$/gm,
		singleLinePerlComments		: /#.*$/gm,
		doubleQuotedString			: /"([^\\"\n]|\\.)*"/g,
		singleQuotedString			: /'([^\\'\n]|\\.)*'/g,
		multiLineDoubleQuotedString	: new XRegExp('"([^\\\\"]|\\\\.)*"', 'gs'),
		multiLineSingleQuotedString	: new XRegExp("'([^\\\\']|\\\\.)*'", 'gs'),
		xmlComments					: /(&lt;|<)!--[\s\S]*?--(&gt;|>)/gm,
		url							: /\w+:\/\/[\w-.\/?%&=:@;]*/g,
		
		/** <?= ?> tags. */
		phpScriptTags 				: { left: /(&lt;|<)\?=?/g, right: /\?(&gt;|>)/g },
		
		/** <%= %> tags. */
		aspScriptTags				: { left: /(&lt;|<)%=?/g, right: /%(&gt;|>)/g },
		
		scriptScriptTags			: { left: /(&lt;|<)\s*script.*?(&gt;|>)/gi, right: /(&lt;|<)\/\s*script\s*(&gt;|>)/gi }
	},

	toolbar: {
		/**
		 * Generates HTML markup for the toolbar.
		 * @param {Highlighter} highlighter Highlighter instance.
		 * @return {String} Returns HTML markup.
		 */
		getHtml: function(highlighter)
		{
			var html = '<div class="toolbar">',
				items = sh.toolbar.items,
				list = items.list
				;
			
			function defaultGetHtml(highlighter, name)
			{
				return sh.toolbar.getButtonHtml(highlighter, name, sh.config.strings[name]);
			};
			
			for (var i = 0; i < list.length; i++)
				html += (items[list[i]].getHtml || defaultGetHtml)(highlighter, list[i]);
			
			html += '</div>';
			
			return html;
		},
		
		/**
		 * Generates HTML markup for a regular button in the toolbar.
		 * @param {Highlighter} highlighter Highlighter instance.
		 * @param {String} commandName		Command name that would be executed.
		 * @param {String} label			Label text to display.
		 * @return {String}					Returns HTML markup.
		 */
		getButtonHtml: function(highlighter, commandName, label)
		{
			return '<span><a href="#" class="toolbar_item'
				+ ' command_' + commandName
				+ ' ' + commandName
				+ '">' + label + '</a></span>'
				;
		},
		
		/**
		 * Event handler for a toolbar anchor.
		 */
		handler: function(e)
		{
			var target = e.target,
				className = target.className || ''
				;

			function getValue(name)
			{
				var r = new RegExp(name + '_(\\w+)'),
					match = r.exec(className)
					;

				return match ? match[1] : null;
			};
			
			var highlighter = getHighlighterById(findParentElement(target, '.syntaxhighlighter').id),
				commandName = getValue('command')
				;
			
			// execute the toolbar command
			if (highlighter && commandName)
				sh.toolbar.items[commandName].execute(highlighter);

			// disable default A click behaviour
			e.preventDefault();
		},
		
		/** Collection of toolbar items. */
		items : {
			// Ordered lis of items in the toolbar. Can't expect `for (var n in items)` to be consistent.
			list: ['expandSource', 'help'],

			expandSource: {
				getHtml: function(highlighter)
				{
					if (highlighter.getParam('collapse') != true)
						return '';
						
					var title = highlighter.getParam('title');
					return sh.toolbar.getButtonHtml(highlighter, 'expandSource', title ? title : sh.config.strings.expandSource);
				},
			
				execute: function(highlighter)
				{
					var div = getHighlighterDivById(highlighter.id);
					removeClass(div, 'collapsed');
				}
			},

			/** Command to display the about dialog window. */
			help: {
				execute: function(highlighter)
				{	
					var wnd = popup('', '_blank', 500, 250, 'scrollbars=0'),
						doc = wnd.document
						;
					
					doc.write(sh.config.strings.aboutDialog);
					doc.close();
					wnd.focus();
				}
			}
		}
	},

	/**
	 * Finds all elements on the page which should be processes by SyntaxHighlighter.
	 *
	 * @param {Object} globalParams		Optional parameters which override element's 
	 * 									parameters. Only used if element is specified.
	 * 
	 * @param {Object} element	Optional element to highlight. If none is
	 * 							provided, all elements in the current document 
	 * 							are returned which qualify.
	 *
	 * @return {Array}	Returns list of <code>{ target: DOMElement, params: Object }</code> objects.
	 */
	findElements: function(globalParams, element)
	{
		var elements = element ? [element] : toArray(document.getElementsByTagName(sh.config.tagName)), 
			conf = sh.config,
			result = []
			;

		// support for <SCRIPT TYPE="syntaxhighlighter" /> feature
		if (conf.useScriptTags)
			elements = elements.concat(getSyntaxHighlighterScriptTags());

		if (elements.length === 0) 
			return result;
	
		for (var i = 0; i < elements.length; i++) 
		{
			var item = {
				target: elements[i], 
				// local params take precedence over globals
				params: merge(globalParams, parseParams(elements[i].className))
			};

			if (item.params['brush'] == null)
				continue;
				
			result.push(item);
		}
		
		return result;
	},

	/**
	 * Shorthand to highlight all elements on the page that are marked as 
	 * SyntaxHighlighter source code.
	 * 
	 * @param {Object} globalParams		Optional parameters which override element's 
	 * 									parameters. Only used if element is specified.
	 * 
	 * @param {Object} element	Optional element to highlight. If none is
	 * 							provided, all elements in the current document 
	 * 							are highlighted.
	 */ 
	highlight: function(globalParams, element)
	{
		var elements = this.findElements(globalParams, element),
			propertyName = 'innerHTML', 
			highlighter = null,
			conf = sh.config
			;

		if (elements.length === 0) 
			return;
	
		for (var i = 0; i < elements.length; i++) 
		{
			var element = elements[i],
				target = element.target,
				params = element.params,
				brushName = params.brush,
				code
				;

			if (brushName == null)
				continue;

			// Instantiate a brush
			if (params['html-script'] == 'true' || sh.defaults['html-script'] == true) 
			{
				highlighter = new sh.HtmlScript(brushName);
				brushName = 'htmlscript';
			}
			else
			{
				var brush = findBrush(brushName);
				
				if (brush)
					highlighter = new brush();
				else
					continue;
			}
			
			code = target[propertyName];
			
			// remove CDATA from <SCRIPT/> tags if it's present
			if (conf.useScriptTags)
				code = stripCData(code);
				
			// Inject title if the attribute is present
			if ((target.title || '') != '')
				params.title = target.title;
				
			params['brush'] = brushName;
			highlighter.init(params);
			element = highlighter.getDiv(code);
			
			// carry over ID
			if ((target.id || '') != '')
				element.id = target.id;
			
			target.parentNode.replaceChild(element, target);
		}
	},

	/**
	 * Main entry point for the SyntaxHighlighter.
	 * @param {Object} params Optional params to apply to all highlighted elements.
	 */
	all: function(params)
	{
		attachEvent(
			window,
			'load',
			function() { sh.highlight(params); }
		);
	}
}; // end of sh

sh['all']			= sh.all;
sh['highlight']		= sh.highlight;

/**
 * Checks if target DOM elements has specified CSS class.
 * @param {DOMElement} target Target DOM element to check.
 * @param {String} className Name of the CSS class to check for.
 * @return {Boolean} Returns true if class name is present, false otherwise.
 */
function hasClass(target, className)
{
	return target.className.indexOf(className) != -1;
};

/**
 * Adds CSS class name to the target DOM element.
 * @param {DOMElement} target Target DOM element.
 * @param {String} className New CSS class to add.
 */
function addClass(target, className)
{
	if (!hasClass(target, className))
		target.className += ' ' + className;
};

/**
 * Removes CSS class name from the target DOM element.
 * @param {DOMElement} target Target DOM element.
 * @param {String} className CSS class to remove.
 */
function removeClass(target, className)
{
	target.className = target.className.replace(className, '');
};

/**
 * Converts the source to array object. Mostly used for function arguments and 
 * lists returned by getElementsByTagName() which aren't Array objects.
 * @param {List} source Source list.
 * @return {Array} Returns array.
 */
function toArray(source)
{
	var result = [];
	
	for (var i = 0; i < source.length; i++) 
		result.push(source[i]);
		
	return result;
};

/**
 * Splits block of text into lines.
 * @param {String} block Block of text.
 * @return {Array} Returns array of lines.
 */
function splitLines(block)
{
	return block.split('\n');
}

/**
 * Generates HTML ID for the highlighter.
 * @param {String} highlighterId Highlighter ID.
 * @return {String} Returns HTML ID.
 */
function getHighlighterId(id)
{
	var prefix = 'highlighter_';
	return id.indexOf(prefix) == 0 ? id : prefix + id;
};

/**
 * Finds Highlighter instance by ID.
 * @param {String} highlighterId Highlighter ID.
 * @return {Highlighter} Returns instance of the highlighter.
 */
function getHighlighterById(id)
{
	return sh.vars.highlighters[getHighlighterId(id)];
};

/**
 * Finds highlighter's DIV container.
 * @param {String} highlighterId Highlighter ID.
 * @return {Element} Returns highlighter's DIV element.
 */
function getHighlighterDivById(id)
{
	return document.getElementById(getHighlighterId(id));
};

/**
 * Stores highlighter so that getHighlighterById() can do its thing. Each
 * highlighter must call this method to preserve itself.
 * @param {Highilghter} highlighter Highlighter instance.
 */
function storeHighlighter(highlighter)
{
	sh.vars.highlighters[getHighlighterId(highlighter.id)] = highlighter;
};

/**
 * Looks for a child or parent node which has specified classname.
 * Equivalent to jQuery's $(container).find(".className")
 * @param {Element} target Target element.
 * @param {String} search Class name or node name to look for.
 * @param {Boolean} reverse If set to true, will go up the node tree instead of down.
 * @return {Element} Returns found child or parent element on null.
 */
function findElement(target, search, reverse /* optional */)
{
	if (target == null)
		return null;
		
	var nodes			= reverse != true ? target.childNodes : [ target.parentNode ],
		propertyToFind	= { '#' : 'id', '.' : 'className' }[search.substr(0, 1)] || 'nodeName',
		expectedValue,
		found
		;

	expectedValue = propertyToFind != 'nodeName'
		? search.substr(1)
		: search.toUpperCase()
		;
		
	// main return of the found node
	if ((target[propertyToFind] || '').indexOf(expectedValue) != -1)
		return target;
	
	for (var i = 0; nodes && i < nodes.length && found == null; i++)
		found = findElement(nodes[i], search, reverse);
	
	return found;
};

/**
 * Looks for a parent node which has specified classname.
 * This is an alias to <code>findElement(container, className, true)</code>.
 * @param {Element} target Target element.
 * @param {String} className Class name to look for.
 * @return {Element} Returns found parent element on null.
 */
function findParentElement(target, className)
{
	return findElement(target, className, true);
};

/**
 * Finds an index of element in the array.
 * @ignore
 * @param {Object} searchElement
 * @param {Number} fromIndex
 * @return {Number} Returns index of element if found; -1 otherwise.
 */
function indexOf(array, searchElement, fromIndex)
{
	fromIndex = Math.max(fromIndex || 0, 0);

	for (var i = fromIndex; i < array.length; i++)
		if(array[i] == searchElement)
			return i;
	
	return -1;
};

/**
 * Generates a unique element ID.
 */
function guid(prefix)
{
	return (prefix || '') + Math.round(Math.random() * 1000000).toString();
};

/**
 * Merges two objects. Values from obj2 override values in obj1.
 * Function is NOT recursive and works only for one dimensional objects.
 * @param {Object} obj1 First object.
 * @param {Object} obj2 Second object.
 * @return {Object} Returns combination of both objects.
 */
function merge(obj1, obj2)
{
	var result = {}, name;

	for (name in obj1) 
		result[name] = obj1[name];
	
	for (name in obj2) 
		result[name] = obj2[name];
		
	return result;
};

/**
 * Attempts to convert string to boolean.
 * @param {String} value Input string.
 * @return {Boolean} Returns true if input was "true", false if input was "false" and value otherwise.
 */
function toBoolean(value)
{
	var result = { "true" : true, "false" : false }[value];
	return result == null ? value : result;
};

/**
 * Opens up a centered popup window.
 * @param {String} url		URL to open in the window.
 * @param {String} name		Popup name.
 * @param {int} width		Popup width.
 * @param {int} height		Popup height.
 * @param {String} options	window.open() options.
 * @return {Window}			Returns window instance.
 */
function popup(url, name, width, height, options)
{
	var x = (screen.width - width) / 2,
		y = (screen.height - height) / 2
		;
		
	options +=	', left=' + x + 
				', top=' + y +
				', width=' + width +
				', height=' + height
		;
	options = options.replace(/^,/, '');

	var win = window.open(url, name, options);
	win.focus();
	return win;
};

/**
 * Adds event handler to the target object.
 * @param {Object} obj		Target object.
 * @param {String} type		Name of the event.
 * @param {Function} func	Handling function.
 */
function attachEvent(obj, type, func, scope)
{
	function handler(e)
	{
		e = e || window.event;
		
		if (!e.target)
		{
			e.target = e.srcElement;
			e.preventDefault = function()
			{
				this.returnValue = false;
			};
		}
			
		func.call(scope || window, e);
	};
	
	if (obj.attachEvent) 
	{
		obj.attachEvent('on' + type, handler);
	}
	else 
	{
		obj.addEventListener(type, handler, false);
	}
};

/**
 * Displays an alert.
 * @param {String} str String to display.
 */
function alert(str)
{
	window.alert(sh.config.strings.alert + str);
};

/**
 * Finds a brush by its alias.
 *
 * @param {String} alias		Brush alias.
 * @param {Boolean} showAlert	Suppresses the alert if false.
 * @return {Brush}				Returns bursh constructor if found, null otherwise.
 */
function findBrush(alias, showAlert)
{
	var brushes = sh.vars.discoveredBrushes,
		result = null
		;
	
	if (brushes == null) 
	{
		brushes = {};
		
		// Find all brushes
		for (var brush in sh.brushes) 
		{
			var info = sh.brushes[brush],
				aliases = info.aliases
				;
			
			if (aliases == null) 
				continue;
			
			// keep the brush name
			info.brushName = brush.toLowerCase();
			
			for (var i = 0; i < aliases.length; i++) 
				brushes[aliases[i]] = brush;
		}
		
		sh.vars.discoveredBrushes = brushes;
	}
	
	result = sh.brushes[brushes[alias]];

	if (result == null && showAlert != false)
		alert(sh.config.strings.noBrush + alias);
	
	return result;
};

/**
 * Executes a callback on each line and replaces each line with result from the callback.
 * @param {Object} str			Input string.
 * @param {Object} callback		Callback function taking one string argument and returning a string.
 */
function eachLine(str, callback)
{
	var lines = splitLines(str);
	
	for (var i = 0; i < lines.length; i++)
		lines[i] = callback(lines[i], i);
		
	return lines.join('\n');
};

/**
 * This is a special trim which only removes first and last empty lines
 * and doesn't affect valid leading space on the first line.
 * 
 * @param {String} str   Input string
 * @return {String}      Returns string without empty first and last lines.
 */
function trimFirstAndLastLines(str)
{
	return str.replace(/^[ ]*[\n]+|[\n]*[ ]*$/g, '');
};

/**
 * Parses key/value pairs into hash object.
 * 
 * Understands the following formats:
 * - name: word;
 * - name: [word, word];
 * - name: "string";
 * - name: 'string';
 * 
 * For example:
 *   name1: value; name2: [value, value]; name3: 'value'
 *   
 * @param {String} str    Input string.
 * @return {Object}       Returns deserialized object.
 */
function parseParams(str)
{
	var match, 
		result = {},
		arrayRegex = new XRegExp("^\\[(?<values>(.*?))\\]$"),
		regex = new XRegExp(
			"(?<name>[\\w-]+)" +
			"\\s*:\\s*" +
			"(?<value>" +
				"[\\w-%#]+|" +		// word
				"\\[.*?\\]|" +		// [] array
				'".*?"|' +			// "" string
				"'.*?'" +			// '' string
			")\\s*;?",
			"g"
		)
		;

	while ((match = regex.exec(str)) != null) 
	{
		var value = match.value
			.replace(/^['"]|['"]$/g, '') // strip quotes from end of strings
			;
		
		// try to parse array value
		if (value != null && arrayRegex.test(value))
		{
			var m = arrayRegex.exec(value);
			value = m.values.length > 0 ? m.values.split(/\s*,\s*/) : [];
		}
		
		result[match.name] = value;
	}
	
	return result;
};

/**
 * Wraps each line of the string into <code/> tag with given style applied to it.
 * 
 * @param {String} str   Input string.
 * @param {String} css   Style name to apply to the string.
 * @return {String}      Returns input string with each line surrounded by <span/> tag.
 */
function wrapLinesWithCode(str, css)
{
	if (str == null || str.length == 0 || str == '\n') 
		return str;

	str = str.replace(/</g, '&lt;');

	// Replace two or more sequential spaces with &nbsp; leaving last space untouched.
	str = str.replace(/ {2,}/g, function(m)
	{
		var spaces = '';
		
		for (var i = 0; i < m.length - 1; i++)
			spaces += sh.config.space;
		
		return spaces + ' ';
	});

	// Split each line and apply <span class="...">...</span> to them so that
	// leading spaces aren't included.
	if (css != null) 
		str = eachLine(str, function(line)
		{
			if (line.length == 0) 
				return '';
			
			var spaces = '';
			
			line = line.replace(/^(&nbsp;| )+/, function(s)
			{
				spaces = s;
				return '';
			});
			
			if (line.length == 0) 
				return spaces;
			
			return spaces + '<code class="' + css + '">' + line + '</code>';
		});

	return str;
};

/**
 * Pads number with zeros until it's length is the same as given length.
 * 
 * @param {Number} number	Number to pad.
 * @param {Number} length	Max string length with.
 * @return {String}			Returns a string padded with proper amount of '0'.
 */
function padNumber(number, length)
{
	var result = number.toString();
	
	while (result.length < length)
		result = '0' + result;
	
	return result;
};

/**
 * Replaces tabs with spaces.
 * 
 * @param {String} code		Source code.
 * @param {Number} tabSize	Size of the tab.
 * @return {String}			Returns code with all tabs replaces by spaces.
 */
function processTabs(code, tabSize)
{
	var tab = '';
	
	for (var i = 0; i < tabSize; i++)
		tab += ' ';

	return code.replace(/\t/g, tab);
};

/**
 * Replaces tabs with smart spaces.
 * 
 * @param {String} code    Code to fix the tabs in.
 * @param {Number} tabSize Number of spaces in a column.
 * @return {String}        Returns code with all tabs replaces with roper amount of spaces.
 */
function processSmartTabs(code, tabSize)
{
	var lines = splitLines(code),
		tab = '\t',
		spaces = ''
		;
	
	// Create a string with 1000 spaces to copy spaces from... 
	// It's assumed that there would be no indentation longer than that.
	for (var i = 0; i < 50; i++) 
		spaces += '                    '; // 20 spaces * 50
			
	// This function inserts specified amount of spaces in the string
	// where a tab is while removing that given tab.
	function insertSpaces(line, pos, count)
	{
		return line.substr(0, pos)
			+ spaces.substr(0, count)
			+ line.substr(pos + 1, line.length) // pos + 1 will get rid of the tab
			;
	};

	// Go through all the lines and do the 'smart tabs' magic.
	code = eachLine(code, function(line)
	{
		if (line.indexOf(tab) == -1) 
			return line;
		
		var pos = 0;
		
		while ((pos = line.indexOf(tab)) != -1) 
		{
			// This is pretty much all there is to the 'smart tabs' logic.
			// Based on the position within the line and size of a tab,
			// calculate the amount of spaces we need to insert.
			var spaces = tabSize - pos % tabSize;
			line = insertSpaces(line, pos, spaces);
		}
		
		return line;
	});
	
	return code;
};

/**
 * Performs various string fixes based on configuration.
 */
function fixInputString(str)
{
	var br = /<br\s*\/?>|&lt;br\s*\/?&gt;/gi;
	
	if (sh.config.bloggerMode == true)
		str = str.replace(br, '\n');

	if (sh.config.stripBrs == true)
		str = str.replace(br, '');
		
	return str;
};

/**
 * Removes all white space at the begining and end of a string.
 * 
 * @param {String} str   String to trim.
 * @return {String}      Returns string without leading and following white space characters.
 */
function trim(str)
{
	return str.replace(/^\s+|\s+$/g, '');
};

/**
 * Unindents a block of text by the lowest common indent amount.
 * @param {String} str   Text to unindent.
 * @return {String}      Returns unindented text block.
 */
function unindent(str)
{
	var lines = splitLines(fixInputString(str)),
		indents = new Array(),
		regex = /^\s*/,
		min = 1000
		;
	
	// go through every line and check for common number of indents
	for (var i = 0; i < lines.length && min > 0; i++) 
	{
		var line = lines[i];
		
		if (trim(line).length == 0) 
			continue;
		
		var matches = regex.exec(line);
		
		// In the event that just one line doesn't have leading white space
		// we can't unindent anything, so bail completely.
		if (matches == null) 
			return str;
			
		min = Math.min(matches[0].length, min);
	}
	
	// trim minimum common number of white space from the begining of every line
	if (min > 0) 
		for (var i = 0; i < lines.length; i++) 
			lines[i] = lines[i].substr(min);
	
	return lines.join('\n');
};

/**
 * Callback method for Array.sort() which sorts matches by
 * index position and then by length.
 * 
 * @param {Match} m1	Left object.
 * @param {Match} m2    Right object.
 * @return {Number}     Returns -1, 0 or -1 as a comparison result.
 */
function matchesSortCallback(m1, m2)
{
	// sort matches by index first
	if(m1.index < m2.index)
		return -1;
	else if(m1.index > m2.index)
		return 1;
	else
	{
		// if index is the same, sort by length
		if(m1.length < m2.length)
			return -1;
		else if(m1.length > m2.length)
			return 1;
	}
	
	return 0;
};

/**
 * Executes given regular expression on provided code and returns all
 * matches that are found.
 * 
 * @param {String} code    Code to execute regular expression on.
 * @param {Object} regex   Regular expression item info from <code>regexList</code> collection.
 * @return {Array}         Returns a list of Match objects.
 */ 
function getMatches(code, regexInfo)
{
	function defaultAdd(match, regexInfo)
	{
		return match[0];
	};
	
	var index = 0,
		match = null,
		matches = [],
		func = regexInfo.func ? regexInfo.func : defaultAdd
		;
	
	while((match = regexInfo.regex.exec(code)) != null)
	{
		var resultMatch = func(match, regexInfo);
		
		if (typeof(resultMatch) == 'string')
			resultMatch = [new sh.Match(resultMatch, match.index, regexInfo.css)];

		matches = matches.concat(resultMatch);
	}
	
	return matches;
};

/**
 * Turns all URLs in the code into <a/> tags.
 * @param {String} code Input code.
 * @return {String} Returns code with </a> tags.
 */
function processUrls(code)
{
	var gt = /(.*)((&gt;|&lt;).*)/;
	
	return code.replace(sh.regexLib.url, function(m)
	{
		var suffix = '',
			match = null
			;
		
		// We include &lt; and &gt; in the URL for the common cases like <http://google.com>
		// The problem is that they get transformed into &lt;http://google.com&gt;
		// Where as &gt; easily looks like part of the URL string.
	
		if (match = gt.exec(m))
		{
			m = match[1];
			suffix = match[2];
		}
		
		return '<a href="' + m + '">' + m + '</a>' + suffix;
	});
};

/**
 * Finds all <SCRIPT TYPE="syntaxhighlighter" /> elementss.
 * @return {Array} Returns array of all found SyntaxHighlighter tags.
 */
function getSyntaxHighlighterScriptTags()
{
	var tags = document.getElementsByTagName('script'),
		result = []
		;
	
	for (var i = 0; i < tags.length; i++)
		if (tags[i].type == 'syntaxhighlighter')
			result.push(tags[i]);
			
	return result;
};

/**
 * Strips <![CDATA[]]> from <SCRIPT /> content because it should be used
 * there in most cases for XHTML compliance.
 * @param {String} original	Input code.
 * @return {String} Returns code without leading <![CDATA[]]> tags.
 */
function stripCData(original)
{
	var left = '<![CDATA[',
		right = ']]>',
		// for some reason IE inserts some leading blanks here
		copy = trim(original),
		changed = false,
		leftLength = left.length,
		rightLength = right.length
		;
	
	if (copy.indexOf(left) == 0)
	{
		copy = copy.substring(leftLength);
		changed = true;
	}
	
	var copyLength = copy.length;
	
	if (copy.indexOf(right) == copyLength - rightLength)
	{
		copy = copy.substring(0, copyLength - rightLength);
		changed = true;
	}
	
	return changed ? copy : original;
};


/**
 * Quick code mouse double click handler.
 */
function quickCodeHandler(e)
{
	var target = e.target,
		highlighterDiv = findParentElement(target, '.syntaxhighlighter'),
		container = findParentElement(target, '.container'),
		textarea = document.createElement('textarea'),
		highlighter
		;

	if (!container || !highlighterDiv || findElement(container, 'textarea'))
		return;

	highlighter = getHighlighterById(highlighterDiv.id);
	
	// add source class name
	addClass(highlighterDiv, 'source');

	// Have to go over each line and grab it's text, can't just do it on the
	// container because Firefox loses all \n where as Webkit doesn't.
	var lines = container.childNodes,
		code = []
		;
	
	for (var i = 0; i < lines.length; i++)
		code.push(lines[i].innerText || lines[i].textContent);
	
	// using \r instead of \r or \r\n makes this work equally well on IE, FF and Webkit
	code = code.join('\r');
	
	// inject <textarea/> tag
	textarea.appendChild(document.createTextNode(code));
	container.appendChild(textarea);
	
	// preselect all text
	textarea.focus();
	textarea.select();
	
	// set up handler for lost focus
	attachEvent(textarea, 'blur', function(e)
	{
		textarea.parentNode.removeChild(textarea);
		removeClass(highlighterDiv, 'source');
	});
};

/**
 * Match object.
 */
sh.Match = function(value, index, css)
{
	this.value = value;
	this.index = index;
	this.length = value.length;
	this.css = css;
	this.brushName = null;
};

sh.Match.prototype.toString = function()
{
	return this.value;
};

/**
 * Simulates HTML code with a scripting language embedded.
 * 
 * @param {String} scriptBrushName Brush name of the scripting language.
 */
sh.HtmlScript = function(scriptBrushName)
{
	var brushClass = findBrush(scriptBrushName),
		scriptBrush,
		xmlBrush = new sh.brushes.Xml(),
		bracketsRegex = null,
		ref = this,
		methodsToExpose = 'getDiv getHtml init'.split(' ')
		;

	if (brushClass == null)
		return;
	
	scriptBrush = new brushClass();
	
	for(var i = 0; i < methodsToExpose.length; i++)
		// make a closure so we don't lose the name after i changes
		(function() {
			var name = methodsToExpose[i];
			
			ref[name] = function()
			{
				return xmlBrush[name].apply(xmlBrush, arguments);
			};
		})();
	
	if (scriptBrush.htmlScript == null)
	{
		alert(sh.config.strings.brushNotHtmlScript + scriptBrushName);
		return;
	}
	
	xmlBrush.regexList.push(
		{ regex: scriptBrush.htmlScript.code, func: process }
	);
	
	function offsetMatches(matches, offset)
	{
		for (var j = 0; j < matches.length; j++) 
			matches[j].index += offset;
	}
	
	function process(match, info)
	{
		var code = match.code,
			matches = [],
			regexList = scriptBrush.regexList,
			offset = match.index + match.left.length,
			htmlScript = scriptBrush.htmlScript,
			result
			;

		// add all matches from the code
		for (var i = 0; i < regexList.length; i++)
		{
			result = getMatches(code, regexList[i]);
			offsetMatches(result, offset);
			matches = matches.concat(result);
		}
		
		// add left script bracket
		if (htmlScript.left != null && match.left != null)
		{
			result = getMatches(match.left, htmlScript.left);
			offsetMatches(result, match.index);
			matches = matches.concat(result);
		}
		
		// add right script bracket
		if (htmlScript.right != null && match.right != null)
		{
			result = getMatches(match.right, htmlScript.right);
			offsetMatches(result, match.index + match[0].lastIndexOf(match.right));
			matches = matches.concat(result);
		}
		
		for (var j = 0; j < matches.length; j++)
			matches[j].brushName = brushClass.brushName;
			
		return matches;
	}
};

/**
 * Main Highlither class.
 * @constructor
 */
sh.Highlighter = function()
{
	// not putting any code in here because of the prototype inheritance
};

sh.Highlighter.prototype = {
	/**
	 * Returns value of the parameter passed to the highlighter.
	 * @param {String} name				Name of the parameter.
	 * @param {Object} defaultValue		Default value.
	 * @return {Object}					Returns found value or default value otherwise.
	 */
	getParam: function(name, defaultValue)
	{
		var result = this.params[name];
		return toBoolean(result == null ? defaultValue : result);
	},
	
	/**
	 * Shortcut to document.createElement().
	 * @param {String} name		Name of the element to create (DIV, A, etc).
	 * @return {HTMLElement}	Returns new HTML element.
	 */
	create: function(name)
	{
		return document.createElement(name);
	},
	
	/**
	 * Applies all regular expression to the code and stores all found
	 * matches in the `this.matches` array.
	 * @param {Array} regexList		List of regular expressions.
	 * @param {String} code			Source code.
	 * @return {Array}				Returns list of matches.
	 */
	findMatches: function(regexList, code)
	{
		var result = [];
		
		if (regexList != null)
			for (var i = 0; i < regexList.length; i++) 
				// BUG: length returns len+1 for array if methods added to prototype chain (oising@gmail.com)
				if (typeof (regexList[i]) == "object")
					result = result.concat(getMatches(code, regexList[i]));
		
		// sort and remove nested the matches
		return this.removeNestedMatches(result.sort(matchesSortCallback));
	},
	
	/**
	 * Checks to see if any of the matches are inside of other matches. 
	 * This process would get rid of highligted strings inside comments, 
	 * keywords inside strings and so on.
	 */
	removeNestedMatches: function(matches)
	{
		// Optimized by Jose Prado (http://joseprado.com)
		for (var i = 0; i < matches.length; i++) 
		{ 
			if (matches[i] === null)
				continue;
			
			var itemI = matches[i],
				itemIEndPos = itemI.index + itemI.length
				;
			
			for (var j = i + 1; j < matches.length && matches[i] !== null; j++) 
			{
				var itemJ = matches[j];
				
				if (itemJ === null) 
					continue;
				else if (itemJ.index > itemIEndPos) 
					break;
				else if (itemJ.index == itemI.index && itemJ.length > itemI.length)
					matches[i] = null;
				else if (itemJ.index >= itemI.index && itemJ.index < itemIEndPos) 
					matches[j] = null;
			}
		}
		
		return matches;
	},
	
	/**
	 * Creates an array containing integer line numbers starting from the 'first-line' param.
	 * @return {Array} Returns array of integers.
	 */
	figureOutLineNumbers: function(code)
	{
		var lines = [],
			firstLine = parseInt(this.getParam('first-line'))
			;
		
		eachLine(code, function(line, index)
		{
			lines.push(index + firstLine);
		});
		
		return lines;
	},
	
	/**
	 * Determines if specified line number is in the highlighted list.
	 */
	isLineHighlighted: function(lineNumber)
	{
		var list = this.getParam('highlight', []);
		
		if (typeof(list) != 'object' && list.push == null) 
			list = [ list ];
		
		return indexOf(list, lineNumber.toString()) != -1;
	},
	
	/**
	 * Generates HTML markup for a single line of code while determining alternating line style.
	 * @param {Integer} lineNumber	Line number.
	 * @param {String} code Line	HTML markup.
	 * @return {String}				Returns HTML markup.
	 */
	getLineHtml: function(lineIndex, lineNumber, code)
	{
		var classes = [
			'line',
			'number' + lineNumber,
			'index' + lineIndex,
			'alt' + (lineNumber % 2 == 0 ? 1 : 2).toString()
		];
		
		if (this.isLineHighlighted(lineNumber))
		 	classes.push('highlighted');
		
		if (lineNumber == 0)
			classes.push('break');
			
		return '<div class="' + classes.join(' ') + '">' + code + '</div>';
	},
	
	/**
	 * Generates HTML markup for line number column.
	 * @param {String} code			Complete code HTML markup.
	 * @param {Array} lineNumbers	Calculated line numbers.
	 * @return {String}				Returns HTML markup.
	 */
	getLineNumbersHtml: function(code, lineNumbers)
	{
		var html = '',
			count = splitLines(code).length,
			firstLine = parseInt(this.getParam('first-line')),
			pad = this.getParam('pad-line-numbers')
			;
		
		if (pad == true)
			pad = (firstLine + count - 1).toString().length;
		else if (isNaN(pad) == true)
			pad = 0;
			
		for (var i = 0; i < count; i++)
		{
			var lineNumber = lineNumbers ? lineNumbers[i] : firstLine + i,
				code = lineNumber == 0 ? sh.config.space : padNumber(lineNumber, pad)
				;
				
			html += this.getLineHtml(i, lineNumber, code);
		}
		
		return html;
	},
	
	/**
	 * Splits block of text into individual DIV lines.
	 * @param {String} code			Code to highlight.
	 * @param {Array} lineNumbers	Calculated line numbers.
	 * @return {String}				Returns highlighted code in HTML form.
	 */
	getCodeLinesHtml: function(html, lineNumbers)
	{
		html = trim(html);
		
		var lines = splitLines(html),
			padLength = this.getParam('pad-line-numbers'),
			firstLine = parseInt(this.getParam('first-line')),
			html = '',
			brushName = this.getParam('brush')
			;

		for (var i = 0; i < lines.length; i++)
		{
			var line = lines[i],
				indent = /^(&nbsp;|\s)+/.exec(line),
				spaces = null,
				lineNumber = lineNumbers ? lineNumbers[i] : firstLine + i;
				;

			if (indent != null)
			{
				spaces = indent[0].toString();
				line = line.substr(spaces.length);
				spaces = spaces.replace(' ', sh.config.space);
			}

			line = trim(line);
			
			if (line.length == 0)
				line = sh.config.space;
			
			html += this.getLineHtml(
				i,
				lineNumber, 
				(spaces != null ? '<code class="' + brushName + ' spaces">' + spaces + '</code>' : '') + line
			);
		}
		
		return html;
	},
	
	/**
	 * Returns HTML for the table title or empty string if title is null.
	 */
	getTitleHtml: function(title)
	{
		return title ? '<caption>' + title + '</caption>' : '';
	},
	
	/**
	 * Finds all matches in the source code.
	 * @param {String} code		Source code to process matches in.
	 * @param {Array} matches	Discovered regex matches.
	 * @return {String} Returns formatted HTML with processed mathes.
	 */
	getMatchesHtml: function(code, matches)
	{
		var pos = 0, 
			result = '',
			brushName = this.getParam('brush', '')
			;
		
		function getBrushNameCss(match)
		{
			var result = match ? (match.brushName || brushName) : brushName;
			return result ? result + ' ' : '';
		};
		
		// Finally, go through the final list of matches and pull the all
		// together adding everything in between that isn't a match.
		for (var i = 0; i < matches.length; i++) 
		{
			var match = matches[i],
				matchBrushName
				;
			
			if (match === null || match.length === 0) 
				continue;
			
			matchBrushName = getBrushNameCss(match);
			
			result += wrapLinesWithCode(code.substr(pos, match.index - pos), matchBrushName + 'plain')
					+ wrapLinesWithCode(match.value, matchBrushName + match.css)
					;

			pos = match.index + match.length + (match.offset || 0);
		}

		// don't forget to add whatever's remaining in the string
		result += wrapLinesWithCode(code.substr(pos), getBrushNameCss() + 'plain');

		return result;
	},
	
	/**
	 * Generates HTML markup for the whole syntax highlighter.
	 * @param {String} code Source code.
	 * @return {String} Returns HTML markup.
	 */
	getHtml: function(code)
	{
		var html = '',
			classes = [ 'syntaxhighlighter' ],
			tabSize,
			matches,
			lineNumbers
			;
		
		// process light mode
		if (this.getParam('light') == true)
			this.params.toolbar = this.params.gutter = false;

		className = 'syntaxhighlighter';

		if (this.getParam('collapse') == true)
			classes.push('collapsed');
		
		if ((gutter = this.getParam('gutter')) == false)
			classes.push('nogutter');

		// add custom user style name
		classes.push(this.getParam('class-name'));

		// add brush alias to the class name for custom CSS
		classes.push(this.getParam('brush'));

		code = trimFirstAndLastLines(code)
			.replace(/\r/g, ' ') // IE lets these buggers through
			;

		tabSize = this.getParam('tab-size');

		// replace tabs with spaces
		code = this.getParam('smart-tabs') == true
			? processSmartTabs(code, tabSize)
			: processTabs(code, tabSize)
			;

		// unindent code by the common indentation
		code = unindent(code);

		if (gutter)
			lineNumbers = this.figureOutLineNumbers(code);
		
		// find matches in the code using brushes regex list
		matches = this.findMatches(this.regexList, code);
		// processes found matches into the html
		html = this.getMatchesHtml(code, matches);
		// finally, split all lines so that they wrap well
		html = this.getCodeLinesHtml(html, lineNumbers);

		// finally, process the links
		if (this.getParam('auto-links'))
			html = processUrls(html);
		
		if (typeof(navigator) != 'undefined' && navigator.userAgent && navigator.userAgent.match(/MSIE/))
			classes.push('ie');
		
		html = 
			'<div id="' + getHighlighterId(this.id) + '" class="' + classes.join(' ') + '">'
				+ (this.getParam('toolbar') ? sh.toolbar.getHtml(this) : '')
				+ '<table border="0" cellpadding="0" cellspacing="0">'
					+ this.getTitleHtml(this.getParam('title'))
					+ '<tbody>'
						+ '<tr>'
							+ (gutter ? '<td class="gutter">' + this.getLineNumbersHtml(code) + '</td>' : '')
							+ '<td class="code">'
								+ '<div class="container">'
									+ html
								+ '</div>'
							+ '</td>'
						+ '</tr>'
					+ '</tbody>'
				+ '</table>'
			+ '</div>'
			;
			
		return html;
	},
	
	/**
	 * Highlights the code and returns complete HTML.
	 * @param {String} code     Code to highlight.
	 * @return {Element}        Returns container DIV element with all markup.
	 */
	getDiv: function(code)
	{
		if (code === null) 
			code = '';
		
		this.code = code;

		var div = this.create('div');

		// create main HTML
		div.innerHTML = this.getHtml(code);
		
		// set up click handlers
		if (this.getParam('toolbar'))
			attachEvent(findElement(div, '.toolbar'), 'click', sh.toolbar.handler);
		
		if (this.getParam('quick-code'))
			attachEvent(findElement(div, '.code'), 'dblclick', quickCodeHandler);
		
		return div;
	},
	
	/**
	 * Initializes the highlighter/brush.
	 *
	 * Constructor isn't used for initialization so that nothing executes during necessary
	 * `new SyntaxHighlighter.Highlighter()` call when setting up brush inheritence.
	 *
	 * @param {Hash} params Highlighter parameters.
	 */
	init: function(params)
	{
		this.id = guid();
		
		// register this instance in the highlighters list
		storeHighlighter(this);
		
		// local params take precedence over defaults
		this.params = merge(sh.defaults, params || {})
		
		// process light mode
		if (this.getParam('light') == true)
			this.params.toolbar = this.params.gutter = false;
	},
	
	/**
	 * Converts space separated list of keywords into a regular expression string.
	 * @param {String} str    Space separated keywords.
	 * @return {String}       Returns regular expression string.
	 */
	getKeywords: function(str)
	{
		str = str
			.replace(/^\s+|\s+$/g, '')
			.replace(/\s+/g, '|')
			;
		
		return '\\b(?:' + str + ')\\b';
	},
	
	/**
	 * Makes a brush compatible with the `html-script` functionality.
	 * @param {Object} regexGroup Object containing `left` and `right` regular expressions.
	 */
	forHtmlScript: function(regexGroup)
	{
		this.htmlScript = {
			left : { regex: regexGroup.left, css: 'script' },
			right : { regex: regexGroup.right, css: 'script' },
			code : new XRegExp(
				"(?<left>" + regexGroup.left.source + ")" +
				"(?<code>.*?)" +
				"(?<right>" + regexGroup.right.source + ")",
				"sgi"
				)
		};
	}
}; // end of Highlighter

return sh;
}(); // end of anonymous function

// CommonJS
typeof(exports) != 'undefined' ? exports['SyntaxHighlighter'] = SyntaxHighlighter : null;
</script><script type="text/javascript">// (inc clojure-brush) ;; an improved SyntaxHighlighter brush for clojure
//
// Copyright (C) 2011 Andrew Brehaut
//
// Distributed under the Eclipse Public License, the same as Clojure.
//
// https://github.com/brehaut/inc-clojure-brush
//
// Written by Andrew Brehaut
// V0.9.1, November 2011

if (typeof net == "undefined") net = {};
if (!(net.brehaut)) net.brehaut = {};

net.brehaut.ClojureTools = (function (SH) {
  "use strict";
  // utiliies
  if (!Object.create) Object.create = function object(o) {
    function F() {};
    F.prototype = o;  
    return new F();
  };
        
  // data
  
  function Token(value, index, tag, length) {
    this.value = value;
    this.index = index;
    this.length = length || value.length;
    this.tag = tag;
    this.secondary_tags = {};
  }
  
  // null_token exists so that LispNodes that have not had a closing tag attached
  // can have a dummy token to simplify annotation
  var null_token = new Token("", -1, "null", -1);
  
  /* LispNodes are aggregate nodes for sexpressions. 
   *
   */
  function LispNode(tag, children, opening) {
    this.tag = tag;            // current metadata for syntax inference
    this.parent = null;        // the parent expression
    this.list = children;      // all the child forms in order
    this.opening = opening;    // the token that opens this form.
    this.closing = null_token; // the token that closes this form.
    this.meta = null;          // metadata nodes will be attached here if they are found
  }

  var null_lispnode = new LispNode("null", [], null_token);

  
  function PrefixNode(tag, token, attached_node) {
    this.tag = tag;
    this.token = token;
    this.attached_node = attached_node;
    this.parent = null;
  }

  
  
  // tokenize

  function tokenize(code) {
    var tokens = [];
    var tn = 0;
    
    var zero = "0".charCodeAt(0);
    var nine = "9".charCodeAt(0); 
    var lower_a = "a".charCodeAt(0);
    var lower_f = "f".charCodeAt(0);    
    var upper_a = "A".charCodeAt(0);
    var upper_f = "F".charCodeAt(0);
    
    var dispatch = false; // have we just seen a # character?
    
    // i tracks the start of the current window
    // extent is the window for slicing
    
    for (var i = 0, 
             extent = i, 
             j = code.length; 
             i < j && extent <= j;) {          
                
      var c = code[i];
      
      // we care about capturing the whole token when dispatch is used, so back up the
      // starting index by 1
      if (dispatch) i--; 
      
      switch (c) {
        // dispatch alters the value of the next thing read
        case "#":
          dispatch = true;
          i++;
          extent++;
          continue;
          
        case " ":    // ignore whitespace
        case "\t":
        case "\n":
        case "\r":
        case ",":   
          extent++
          break; 
          
        // simple terms
        case "^":
        case "`":
        case ")":
        case "[":
        case "]":
        case "}":
        case "@":
          tokens[tn++] = new Token(c, i, c, ++extent - i);
          break;
        
        case "'":
          tokens[tn++] = new Token(code.slice(i, ++extent), i, dispatch ? "#'" : "'", extent - i);
          break
        
        case "(":
          tokens[tn++] = new Token(code.slice(i, ++extent), i, "(", extent - i);
          break;          
          
        case "{":
          tokens[tn++] = new Token(code.slice(i, ++extent), i, dispatch ? "#{" : "{", extent - i);
          break;  
        
        case "\\":
          if (code.slice(i + 1, i + 8) === "newline") {
            tokens[tn++] = new Token("\\newline", i, "value", 8);
            extent = i + 9; 
          }
          else if (code.slice(i + 1, i + 6) === "space") {
            tokens[tn++] = new Token("\\space", i, "value", 6);
            extent = i + 6;
          }
          else if (code.slice(i + 1, i + 4) === "tab") {
            tokens[tn++] = new Token("\\tab", i, "value", 4);
            extent = i + 5;
          } // work around fun bug with &,>,< in character literals
          else if (code.slice(i + 1, i + 6) === "&amp;") {
            tokens[tn++] = new Token("\\&amp;", i, "value", 6);
            extent = i + 6; 
          }
          else if (code.slice(i + 1, i + 5) === "&lt;") {
            tokens[tn++] = new Token("\\&lt;", i, "value", 5);
            extent = i + 5;
          }
          else if (code.slice(i + 1, i + 5) === "&gt;") {
            tokens[tn++] = new Token("\\&gt;", i, "value", 5);
            extent = i + 5;
          }
          
          else {
            extent += 2;
            tokens[tn++] = new Token(code.slice(i, extent), i, "value", 2);
          }
          break;
        
        case "~": // slice
          if (code[i + 1] === "@") {
            extent += 2;
            tokens[tn++] = new Token(code.slice(i, extent), i, "splice", 2);
          }
          else {
            tokens[tn++] = new Token(code.slice(i, ++extent), i, "unquote", 2);
          }
          break;
        
        // complicated terms
        case "\"": // strings and regexps
          for (extent++; extent <= j; extent++) {
            if (code[extent] === "\\") extent++;
            else if (code[extent] === "\"") break;
          }
          tokens[tn++] = new Token(code.slice(i, ++extent), i, dispatch ? "regexp" : "string", extent - i);       
          break;
          
        case ";":
          for (; extent <= j && code[extent] !== "\n" && code[extent] !== "\r"; extent++);
          tokens[tn++] = new Token(code.slice(i, ++extent), i, "comments", extent - i);   
          break;
        
        case "+": // numbers; fall through to symbol for + and - not prefixing a number
        case "-":
        case "0":
        case "1":
        case "2":
        case "3":
        case "4":
        case "5":
        case "6":
        case "7":
        case "8":
        case "9":
        // todo: exponents, hex
        // http://my.safaribooksonline.com/9781449310387/14?reader=pf&readerfullscreen=&readerleftmenu=1
          var c2 = code.charCodeAt(i + 1);
          if (((c === "+" || c === "-") && (c2 >= zero && c2 <= nine)) // prefixes
              || (c !== "+" && c !== "-")) {
            if (c === "+" || c === "-") extent++; 
            for (; extent <= j; extent++) {
              var charCode = code.charCodeAt(extent);
              if (charCode < zero || charCode > nine) break;
            }
            
            c = code[extent];
            c2 = code.charCodeAt(extent + 1);
            if ((c === "r" || c === "R" || c === "/" || c === ".") // interstitial characters
                && (c2 >= zero && c2 <= nine)) {
              for (extent++; extent <= j; extent++) {
                var charCode = code.charCodeAt(extent);
                if (charCode < zero || charCode > nine) break;
              }
            }
            
            c = code[extent];
            c2 = code.charCodeAt(extent + 1);
            if ((c === "x" || c === "X") && 
                ((c2 >= zero && c2 <= nine) 
                 || (c2 >= lower_a && c2 <= lower_f)
                 || (c2 >= upper_a && c2 <= upper_f))) {
              for (extent++; extent <= j; extent++) {
                var charCode = code.charCodeAt(extent);
                if (((charCode >= zero && charCode <= nine) 
                    || (charCode >= lower_a && charCode <= lower_f)
                    || (charCode >= upper_a && charCode <= upper_f))) continue;
                break;
              }
            }
            
            c = code[extent];
            c2 = code.charCodeAt(extent + 1);
            if ((c === "e" || c === "E") 
                && (c2 >= zero && c2 <= nine)) {
              for (extent++; extent <= j; extent++) {
                var charCode = code.charCodeAt(extent);
                if (charCode < zero || charCode > nine) break;
              }
            }
            
            c = code[extent];
            if (c === "N" || c === "M") extent++;

            tokens[tn++] = new Token(code.slice(i, extent), i, "value", extent - i);
            break;
          }

        case "_":
          if (dispatch && c === "_") {
            tokens[tn++] = new Token(code.slice(i, ++extent), i, "skip", extent - i);
            break;
          } // if not a skip, fall through to symbols
        
        // Allow just about any other symbol as a symbol. This is far more permissive than 
        // clojure actually allows, but should catch any weirdo crap that accidentally gets
        // into the code.
        default: 
          for (extent++; extent <= j; extent++) {
            switch (code[extent]) {
              case " ":
              case "\t":
              case "\n":
              case "\r":
              case "\\":
              case ",":
              case "{":
              case "}":
              case "(":
              case ")":
              case "[":
              case "]":
              case "^":
              case "`":
              case "@":   
                break;
              case ";":   
                // theres a weird bug via syntax highligher that gives us escaped entities.
                // need to watch out for these
                if (code.slice(extent-3, extent+1) === "&lt;"
                    ||code.slice(extent-3, extent+1) === "&gt;"
                    ||code.slice(extent-4, extent+1) === "&amp;") {
                  continue;
                }
                break;
              default:
                continue;
            }
            break;
          }
          
          var value = code.slice(i, extent);
          var tag = "symbol";
          if (value[0] == ":") {
            tag = "keyword";
          }
          else if (value === "true" || value === "false" || value === "nil") {
            tag = "value";
          }
          tokens[tn++] = new Token(value, i, tag, extent - i);
      }
      
      dispatch = false;
      i = extent;
    } 

    return tokens;
  }


  function build_tree(tokens) {
    var toplevel = {
      list: [], 
      tag: "toplevel", 
      parent: null, 
      opening: null,
      closing: null,
      depth: -1
    };
    
    // loop variables hoisted out as semi globals to track position in token stream
    var i = -1;
    var j = tokens.length;
    
    function parse_one(t) {
      // ignore special tokens and forms that dont belong in the tree
      for (; t && (t.tag === "comments" || t.tag === "invalid" || t.tag == "skip") && i < j; ) {
        if (t.tag === "skip") {
          t.tag = "preprocessor";
          annotate_comment(parse_one(tokens[++i]));
        }
        t = tokens[++i];
      }
      
      if (!t) return {}; // hackity hack
      
      switch (t.tag) {
        case "{":
          return build_aggregate(new LispNode("map", [], t), "}");
        case "(":
          return build_aggregate(new LispNode("list", [], t), ")");
        case "#{":
          return build_aggregate(new LispNode("set", [], t), "}");
        case "[":
          return build_aggregate(new LispNode("vector", [], t), "]");
        case "'":
          return new PrefixNode("quote", t, parse_one(tokens[++i]));
        case "#'":
          return new PrefixNode("varquote", t, parse_one(tokens[++i]));  
        case "@":
          return new PrefixNode("deref", t, parse_one(tokens[++i]));  
        case "`":
          return new PrefixNode("quasiquote", t, parse_one(tokens[++i]));  
        case "unquote":
          return new PrefixNode("unquote", t, parse_one(tokens[++i]));
        case "splice":
          return new PrefixNode("splice", t, parse_one(tokens[++i]));  
        case "^":
          t.tag = "meta";
          var meta = parse_one(tokens[++i]);
          var next = parse_one(tokens[++i]);
          next.meta = meta;
          return next;
      }
      
      return t;
    }
    
    // build_aggregate collects to ether sub forms for one aggregate for. 
    function build_aggregate(current, expected_closing) {
      for (i++; i < j; i++) {
        var t = tokens[i];

        if (t.tag === "}" || t.tag === ")" || t.tag === "]") {
          if (t.tag !== expected_closing) t.tag = "invalid";
          current.closing = t;
          if (expected_closing) return current;
        }
        var node = parse_one(t);

        node.parent = current;
        current.list[current.list.length] = node;
      }
      
      return current;
    }
    
    build_aggregate(toplevel, null);
    
    return toplevel;
  }

  // annotation rules to apply to a form based on its head

  var show_locals = true;  // HACK. would rather not use a (semi)-global.

  /* annotate_comment is a special case annotation. 
   * in addition to its role in styling specific forms, it is called by parse_one to
   * ignore any forms skipped with #_
   */ 
  function annotate_comment(exp) {
    exp.tag = "comments";

    if (exp.list) {
      exp.opening.tag = "comments";
      exp.closing.tag = "comments";
    
      for (var i = 0; i < exp.list.length; i++) {
        var child = exp.list[i];
        if (child.list) {
          annotate_comment(child);
        }
        if (child.attached_node) {
          annotate_comment(child.attached_node);
        }
        else {
          child.tag = "comments";
        }
      }
    }
  }

  /* custom annotation rules are stored here */
  var annotation_rules = {};
  
  // this function is exposed to allow ad hoc extension of the customisation rules
  function register_annotation_rule(names, rule) {
    for (var i = 0; i < names.length; i++) {
      annotation_rules[names[i]] = rule;
    }
  }


  function annotate_destructuring (exp, scope) {
    if (exp.list) {
      if (exp.tag === "vector") {
        for (var i = 0; i < exp.list.length; i++) {
          annotate_destructuring(exp.list[i], scope);
        }
      } 
      else if (exp.tag === "map") {
        for (var i = 0; i < exp.list.length; i += 2) {
          var key = exp.list[i];
          var val = exp.list[i + 1];
          
          if (key.tag === "keyword" && val.tag === "vector") {
            for (var ii = 0, jj = val.list.length; ii < jj; ii++) {
              if (val.list[ii].tag !== "symbol") continue;
              val.list[ii].tag = "variable";
              scope[val.list[ii].value] = true;
            }
          }
          else {
            annotate_destructuring(key, scope);
            annotate_expressions(val, scope);
          }
        } 
      }
    } 
    else if (exp.tag === "symbol" && (exp.value !== "&" && exp.value !== "&amp;")){
      exp.tag = "variable";
      scope[exp.value] = true;
    }
  }

  function _annotate_binding_vector (exp, scope) {
    if (exp.tag !== "vector") return;
  
    var bindings = exp.list;

    if (bindings.length % 2 === 1) return;
    
    for (var i = 0; i < bindings.length; i += 2) {
      annotate_destructuring(bindings[i], scope);
      annotate_expressions(bindings[i + 1], scope);
    }    
  }

  function annotate_binding (exp, scope) {
    var bindings = exp.list[1];
    if (!show_locals) return; // HACK

    if (bindings) {
      scope = Object.create(scope);
      _annotate_binding_vector(bindings, scope);
    }
    for (var i = 2; i < exp.list.length; i++) {
      annotate_expressions(exp.list[i], scope);
    }
  }
  
  function _annotate_function_body (exp, scope, start_idx) {
    var argvec = exp.list[start_idx];
    if (argvec.tag !== "vector") return;

    scope = Object.create(scope);

    for (var i = 0, j = argvec.list.length; i < j; i++) {
      annotate_destructuring(argvec.list[i], scope);
    }
    
    for (var i = start_idx, j = exp.list.length; i < j; i++) {
      annotate_expressions(exp.list[i], scope);
    }
  }
  
  function annotate_function (exp, scope) {
    for (var i = 1, j = exp.list.length; i < j; i++) {
      var child = exp.list[i];
      
      if (child.tag === "vector") {
        _annotate_function_body (exp, scope, i);
        return;
      }
      else if (child.tag === "list") {
        _annotate_function_body(child, scope, 0)
      }
    }
  }
  
  function annotate_letfn (exp, scope) {
    scope = Object.create(scope);
    var bindings = exp.list[1];
    
    var fn;
    for (var i = 0, j = bindings.list.length; i < j; i++) {
      fn = bindings.list[i];
      if (!fn.list[0]) continue;
      fn.list[0].tag = "variable";
      scope[fn.list[0].value] = true;
    }
    
    for (i = 0, j = bindings.list.length; i < j; i++) {
      var fn = bindings.list[i];
      annotate_function(fn, scope);
    }
    
    for (i = 2, j = exp.list.length; i < j; i++) {
      annotate_expressions(exp.list[i], scope);
    }
  }

  register_annotation_rule(
    ["comment"],
    annotate_comment
  );
  
  register_annotation_rule(
    ["let", "when-let", "if-let", "binding", "doseq", "for", "dotimes", "let*"],
    annotate_binding
  );
  
  register_annotation_rule(
    ["defn", "defn-", "fn", "bound-fn", "defmacro", "fn*", "defmethod"],
    annotate_function
  );
  
  register_annotation_rule(
    ["letfn"],
    annotate_letfn
  );

  // standard annotations

  function _annotate_metadata_recursive(meta, scope) {
    if (!meta) return;

    if (meta.list !== undefined && meta.list !== null) {
      for (var i = 0, j = meta.list.length; i < j; i++) {
        meta.opening.secondary_tags.meta = true
        meta.closing.secondary_tags.meta = true
        _annotate_metadata_recursive(meta.list[i], scope);
      }
    }
    else if (meta.attached_node) {
      meta.token.secondary_tags.meta = true;
      _annotate_metadata_recursive(meta.attached_node, scope);
    }
    else {
      meta.secondary_tags.meta = true;
    }
  }
  
  function annotate_metadata(exp) {
    if (!(exp && exp.meta)) return;
    var meta = exp.meta;
    
     annotate_expressions(meta, {});    
    _annotate_metadata_recursive(meta, {});
  }


  function annotate_quoted(exp, scope) {
    if (!exp) return;

    if (exp.list !== undefined && exp.list !== null) {
      for (var i = 0, j = exp.list.length; i < j; i++) {
        exp.opening.secondary_tags.quoted = true
        exp.closing.secondary_tags.quoted = true
        annotate_quoted(exp.list[i], scope);
      }
    }
    else if (exp.attached_node) {
      if (exp.tag === "unquote" || exp.tag === "splice") return;
      exp.token.secondary_tags.quoted = true;
      annotate_quoted(exp.attached_node, scope);
    }
    else {
      exp.secondary_tags.quoted = true;
    }
  }


  function annotate_expressions(exp, scope) {
    annotate_metadata(exp);
    
    switch (exp.tag) {
      case "toplevel": 
        for (var i = 0; i < exp.list.length; i++) {
          annotate_expressions(exp.list[i], scope);
        }
        break;
      
      case "list": // functions, macros, special forms, comments
        var head = exp.list[0];
      
        if (head) {
          if (head.tag === "list" || head.tag === "vector" 
           || head.tag === "map" || head.tag === "set") {
            annotate_expressions(head, scope);
          }
          else if (head.attached_node) {
            annotate_expressions(head.attached_node, scope);
          }
          else {
            head.tag = (head.value.match(/(^\.)|(\.$)|[A-Z].*\//)
                        ? "method"
                        : "function");
          }

          // apply specific rules
          if (annotation_rules.hasOwnProperty(head.value)) {
            annotation_rules[head.value](exp, scope);
          } 
          else {
            for (var i = 1; i < exp.list.length; i++) {
              annotate_expressions(exp.list[i], scope);
            }
          } 
        }
        else { // empty list
          exp.opening.tag = "value";
          exp.closing.tag = "value";
        }
      
        break;
      
      case "vector": // data
      case "map":
      case "set":
        for (var i = 0; i < exp.list.length; i++) {
          annotate_expressions(exp.list[i], scope);
        }
        break;
      
      case "symbol":
        if (exp.value.match(/[A-Z].*\/[A-Z_]+/)) {
          exp.tag = "constant";
        }
        else if (show_locals && scope[exp.value]) {
          exp.tag = "variable";
        }
        else if (exp.tag === "symbol" && exp.value.match(/([A-Z].*\/)?[A-Z_]+/)) {
          exp.tag = "type";
        }
        break;
      
      case "quote":
      case "quasiquote":
        annotate_quoted(exp.attached_node, scope);
        
      default:
        if (exp.attached_node) annotate_expressions(exp.attached_node, scope);
    }
  }

  // translation of tag to css:
  var css_translation = {
    "constant":     "constants",
    "keyword":      "constants",
    "method":       "color1",
    "type":         "color3", 
    "function":     "functions",
    "string":       "string",
    "regexp":       "string",
    "value":        "value",
    "comments":     "comments",
    "symbol":       "symbol",
    "variable":     "variable",
    "splice":       "preprocessor", 
    "unquote":      "preprocessor",     
    "preprocessor": "preprocessor",
    "meta":         "preprocessor", 
    "'":            "preprocessor", 
    "#'":           "preprocessor",    
    "(":            "plain",
    ")":            "plain",
    "{":            "keyword",
    "}":            "keyword",
    "#{":           "keyword",   
    "[":            "keyword",
    "]":            "keyword",
    "invalid":      "invalid",
    "@":            "plain" 
  };
  
  function translate_tags_to_css(tokens) {
    for (var i = 0, j = tokens.length; i < j; i++) {
      var token = tokens[i];
      token.css = css_translation[token.tag];
      for (var k in token.secondary_tags) if (token.secondary_tags.hasOwnProperty(k))
        token.css += " " + k ;
    };
  }
  
  
  // create the new brush

  SH.brushes.Clojure = function () {};
  SH.brushes.Clojure.prototype = new SyntaxHighlighter.Highlighter();
  
  SH.brushes.Clojure.prototype.findMatches = function find_matches (regexpList, code) {
    // this is a nasty global hack. need to resolve this
    if (this.params && this.params.locals) {
      show_locals = this.params.locals === true || this.params.locals === "true"; 
    }
    else {
      show_locals = true;
    }
    
    var tokens = tokenize(code);
    annotate_expressions(build_tree(tokens), {});
    translate_tags_to_css(tokens);

    return tokens;
  };
  
  SH.brushes.Clojure.aliases = ['clojure', 'Clojure', 'clj'];
  SH.brushes.Clojure.register_annotation_rule = register_annotation_rule;

  return {
    tokenize: tokenize,
    build_tree: build_tree
  };
})(SyntaxHighlighter);
</script><title>bcbio.variation -- Marginalia</title></head><body><table><tr><td class="docs"><div class="header"><h1 class="project-name">bcbio.variation</h1><h2 class="project-version">0.0.1-SNAPSHOT</h2><br /><p>Clojure API for variation data, built on GATK</p>
</div><div class="dependencies"><h3>dependencies</h3><table><tr><td class="dep-name">org.clojure/clojure</td><td class="dotted"><hr /></td><td class="dep-version">1.3.0</td></tr><tr><td class="dep-name">org.clojure/math.combinatorics</td><td class="dotted"><hr /></td><td class="dep-version">0.0.2</td></tr><tr><td class="dep-name">org.clojure/data.csv</td><td class="dotted"><hr /></td><td class="dep-version">0.1.2</td></tr><tr><td class="dep-name">org.clojars.chapmanb/gatk</td><td class="dotted"><hr /></td><td class="dep-version">1.5.2</td></tr><tr><td class="dep-name">org.clojars.chapmanb/picard</td><td class="dotted"><hr /></td><td class="dep-version">1.64</td></tr><tr><td class="dep-name">incanter/incanter-core</td><td class="dotted"><hr /></td><td class="dep-version">1.3.0-SNAPSHOT</td></tr><tr><td class="dep-name">incanter/incanter-charts</td><td class="dotted"><hr /></td><td class="dep-version">1.3.0-SNAPSHOT</td></tr><tr><td class="dep-name">com.leadtune/clj-ml</td><td class="dotted"><hr /></td><td class="dep-version">0.2.0</td></tr><tr><td class="dep-name">fs</td><td class="dotted"><hr /></td><td class="dep-version">1.1.2</td></tr><tr><td class="dep-name">clj-yaml</td><td class="dotted"><hr /></td><td class="dep-version">0.3.1</td></tr><tr><td class="dep-name">doric</td><td class="dotted"><hr /></td><td class="dep-version">0.7.0-SNAPSHOT</td></tr><tr><td class="dep-name">ordered</td><td class="dotted"><hr /></td><td class="dep-version">1.0.0</td></tr><tr><td class="dep-name">compojure</td><td class="dotted"><hr /></td><td class="dep-version">1.0.1</td></tr><tr><td class="dep-name">ring</td><td class="dotted"><hr /></td><td class="dep-version">1.0.2</td></tr><tr><td class="dep-name">enlive</td><td class="dotted"><hr /></td><td class="dep-version">1.0.0</td></tr></table></div><div class="dependencies"><h3>dev dependencies</h3><table><tr><td class="dep-name">midje</td><td class="dotted"><hr /></td><td class="dep-version">1.3.0</td></tr><tr><td class="dep-name">lein-midje</td><td class="dotted"><hr /></td><td class="dep-version">1.0.8</td></tr></table></div></td><td class="codes" style="text-align: center; vertical-align: middle;color: #666;padding-right:20px"><br /><br /><br />(this space intentionally left almost blank)</td></tr><tr><td class="docs"><div class="toc"><a name="toc"><h3>namespaces</h3></a><ul><li><a href="#bcbio.align.ref">bcbio.align.ref</a></li><li><a href="#bcbio.align.reorder">bcbio.align.reorder</a></li><li><a href="#bcbio.run.broad">bcbio.run.broad</a></li><li><a href="#bcbio.run.itx">bcbio.run.itx</a></li><li><a href="#bcbio.variation.annotate.nbq">bcbio.variation.annotate.nbq</a></li><li><a href="#bcbio.variation.annotation">bcbio.variation.annotation</a></li><li><a href="#bcbio.variation.callable">bcbio.variation.callable</a></li><li><a href="#bcbio.variation.combine">bcbio.variation.combine</a></li><li><a href="#bcbio.variation.compare">bcbio.variation.compare</a></li><li><a href="#bcbio.variation.complex">bcbio.variation.complex</a></li><li><a href="#bcbio.variation.core">bcbio.variation.core</a></li><li><a href="#bcbio.variation.filter">bcbio.variation.filter</a></li><li><a href="#bcbio.variation.metrics">bcbio.variation.metrics</a></li><li><a href="#bcbio.variation.multiple">bcbio.variation.multiple</a></li><li><a href="#bcbio.variation.normalize">bcbio.variation.normalize</a></li><li><a href="#bcbio.variation.phasing">bcbio.variation.phasing</a></li><li><a href="#bcbio.variation.report">bcbio.variation.report</a></li><li><a href="#bcbio.variation.structural">bcbio.variation.structural</a></li><li><a href="#bcbio.variation.utils.background">bcbio.variation.utils.background</a></li><li><a href="#bcbio.variation.utils.cgmetrics">bcbio.variation.utils.cgmetrics</a></li><li><a href="#bcbio.variation.utils.popfreq">bcbio.variation.utils.popfreq</a></li><li><a href="#bcbio.variation.validate">bcbio.variation.validate</a></li><li><a href="#bcbio.variation.variantcontext">bcbio.variation.variantcontext</a></li><li><a href="#bcbio.variation.vcfwalker">bcbio.variation.vcfwalker</a></li><li><a href="#bcbio.variation.web.process">bcbio.variation.web.process</a></li><li><a href="#bcbio.variation.web.server">bcbio.variation.web.server</a></li><li><a href="#bcbio.variation.score">bcbio.variation.score</a></li></ul></div></td><td class="codes">&nbsp;</td></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.align.ref" name="bcbio.align.ref"><h1 class="project-name">bcbio.align.ref</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Deal with reference sequences for alignment and variant calling.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.align.ref
  (:import [org.broadinstitute.sting.gatk.datasources.reference ReferenceDataSource]
           [net.sf.picard.reference ReferenceSequenceFileFactory])
  (:use [clojure.java.io]))</pre></td></tr><tr><td class="docs"><p>Retrieve Picard sequence dictionary from FASTA reference file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-seq-dict
  [ref-file]
  (ReferenceDataSource. (file ref-file))
  (-&gt; ref-file
      file
      ReferenceSequenceFileFactory/getReferenceSequenceFile
      .getSequenceDictionary))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.align.reorder" name="bcbio.align.reorder"><h1 class="project-name">bcbio.align.reorder</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Reorder BAM alignment files to a reference dictionary, potentially swapping naming.
  Handles Human hg19 to GRCh37 naming conversions.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.align.reorder
  (:import [net.sf.samtools SAMFileReader SAMFileWriterFactory SAMReadGroupRecord
            SAMTag SAMFileReader$ValidationStringency])
  (:use [clojure.java.io]
        [bcbio.align.ref :only [get-seq-dict]]
        [bcbio.run.broad :only [index-bam]]
        [bcbio.variation.normalize :only [hg19-map]])
  (:require [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><p>Add updated sequence dictionary and run group information to header.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- updated-bam-header
  [in-bam ref-file call exp]
  (letfn [(update-rgs [rgs]
            (if-not (empty? rgs) rgs
                    [(doto (SAMReadGroupRecord. &quot;1&quot;)
                       (.setLibrary (:sample exp))
                       (.setPlatform (get call :platform &quot;illumina&quot;))
                       (.setSample (:sample exp))
                       (.setPlatformUnit (:sample exp)))]))]
    (let [read-groups (update-rgs (-&gt; in-bam .getFileHeader .getReadGroups))]
      (doto (-&gt; in-bam .getFileHeader .clone)
        (.setSequenceDictionary (-&gt; ref-file get-seq-dict))
        (.setReadGroups read-groups)))))</pre></td></tr><tr><td class="docs"><p>Retrieve order of chromosomes to fetch and mapping to new index.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-new-chr-order
  [bam-names ref-names]
  (letfn [(get-bam-name-map [bam-names orig-ref-names]
            (let [ref-names (set orig-ref-names)]
              (reduce (fn [coll x]
                        (assoc coll (cond
                                     (contains? ref-names x) x
                                     (contains? hg19-map x) (get hg19-map x)
                                     :else (throw (Exception. (str &quot;Could not map &quot; x))))
                               x))
                      {} bam-names)))
          (get-index-map [name-map]
            (let [bam-name-map (reduce (fn [coll [x y]] (assoc coll y x))
                                       {} name-map)]
              (reduce (fn [coll [i x]]
                        (assoc coll i (.indexOf ref-names (get bam-name-map x))))
                      {} (map-indexed vector bam-names))))]
    (when-not (every? #(apply = %) (partition 2 (interleave ref-names bam-names)))
      (let [name-map (get-bam-name-map bam-names ref-names)]
        {:names (remove nil? (map #(get name-map %) ref-names))
         :indexes (get-index-map name-map)}))))</pre></td></tr><tr><td class="docs"><p>Lazy sequence for BAM reads from a Picard iterator.</p>
</td><td class="codes"><pre class="brush: clojure">(defn bam-read-seq
  [iter]
  (lazy-seq
   (when (.hasNext iter)
     (cons (.next iter) (bam-read-seq iter)))))</pre></td></tr><tr><td class="docs"><p>Write reordered BAM file in specified chromosome order.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- write-reorder-bam
  [in-bam out-bam chr-order header]
  (let [default-rg-id (-&gt; header .getReadGroups first .getId)]
    (letfn [(update-read [read]
              (let [new-rg-id (if-let [x (.getAttribute read (.name SAMTag/RG))] x
                                      default-rg-id)]
                (doto read
                  (.setHeader header)
                  (.setReferenceIndex (get (:indexes chr-order)
                                           (.getReferenceIndex read) -1))
                  (.setMateReferenceIndex (get (:indexes chr-order)
                                               (.getMateReferenceIndex read) -1))
                  (.setAttribute (.name SAMTag/RG) new-rg-id))))]
      (doseq [cur-chr (:names chr-order)]
        (with-open [iter (.query in-bam cur-chr 0 0 false)]
          (doseq [read (bam-read-seq iter)]
            (.addAlignment out-bam (update-read read)))))
      (with-open [iter (.queryUnmapped in-bam)]
        (doseq [read (bam-read-seq iter)]
          (.addAlignment out-bam (update-read read)))))))</pre></td></tr><tr><td class="docs"><p>Reorder and remap BAM file to match supplied reference file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn reorder-bam
  [bam-file ref-file call exp &amp; {:keys [out-dir]}]
  (let [out-file (itx/add-file-part bam-file &quot;reorder&quot; out-dir)]
    (when (itx/needs-run? out-file)
      (index-bam bam-file)
      (SAMFileReader/setDefaultValidationStringency SAMFileReader$ValidationStringency/LENIENT)
      (with-open [in-bam (SAMFileReader. (file bam-file))]
        (let [ref-names (map #(.getSequenceName %) (-&gt; ref-file get-seq-dict .getSequences))
              bam-names (map #(.getSequenceName %) (-&gt; in-bam .getFileHeader .getSequenceDictionary
                                                       .getSequences))
              header (updated-bam-header in-bam ref-file call exp)]
          (if-let [chr-order (get-new-chr-order bam-names ref-names)]
            (do
              (with-open [out-bam (.makeSAMOrBAMWriter (SAMFileWriterFactory.)
                                                       header true (file out-file))]
                (write-reorder-bam in-bam out-bam chr-order header))
              out-file)
            bam-file))))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main [bam-file ref-file sample-name]
  (reorder-bam bam-file ref-file {} {:sample sample-name}))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.run.broad" name="bcbio.run.broad"><h1 class="project-name">bcbio.run.broad</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>High level functions to run software from Broad: GATK, Picard</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.run.broad
  (:import [org.broadinstitute.sting.gatk CommandLineGATK]
           [net.sf.samtools SAMFileReader SAMFileReader$ValidationStringency]
           [net.sf.picard.sam BuildBamIndex])
  (:use [clojure.java.io])
  (:require [fs.core :as fs]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><p>Run a GATK commandline in an idempotent file-safe transaction.</p>
</td><td class="codes"><pre class="brush: clojure">(defn run-gatk
  [program args file-info map-info]
  (if (itx/needs-run? (map #(% file-info) (get map-info :out [])))
    (let [std-args [&quot;-T&quot; program]]
      (itx/with-tx-files [tx-file-info file-info (get map-info :out [])]
        (CommandLineGATK/start (CommandLineGATK.)
                               (into-array (map str (itx/subs-kw-files
                                                     (concat std-args args)
                                                     tx-file-info))))))))</pre></td></tr><tr><td class="docs"><p>Generate BAM index, skipping if already present.</p>
</td><td class="codes"><pre class="brush: clojure">(defn index-bam
  [in-bam]
  (let [index-file (str in-bam &quot;.bai&quot;)]
    (if (itx/needs-run? index-file)
      (do
        (SAMFileReader/setDefaultValidationStringency SAMFileReader$ValidationStringency/LENIENT)
        (BuildBamIndex/createIndex (SAMFileReader. (file in-bam)) (file index-file))))
    index-file))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.run.itx" name="bcbio.run.itx"><h1 class="project-name">bcbio.run.itx</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Functionality for running idempotent, transactional processes.
   Provides an API for long running processes in computational
   pipelines. Avoids re-running a process if it has produced the
   output file on a previous run, and leaving partially finished
   files in the case of premature termination.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.run.itx
  (:import (java.io File))
  (:use [clojure.java.io])
  (:require [fs.core :as fs]))</pre></td></tr><tr><td class="docs"><h2>Idempotent processing</h2>

<p>avoid re-running when output files exist</p>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Check if an output files need a run: any do not exist or empty file</p>
</td><td class="codes"><pre class="brush: clojure">(defn needs-run?
  [&amp; fnames]
  (letfn [(file-non-empty? [f]
            (and (fs/exists? f)
                 (&gt; (fs/size f) 0)))]
    (not-every? true?
                (map file-non-empty? (flatten fnames)))))</pre></td></tr><tr><td class="docs"><p>Substitute any keywords in the arguments from file information map.</p>
</td><td class="codes"><pre class="brush: clojure">(defn subs-kw-files
  [args file-info]
  (letfn [(maybe-sub-kw [x]
            (if (and (keyword? x)
                     (contains? file-info x))
              (get file-info x)
              x))]
    (map maybe-sub-kw args)))</pre></td></tr><tr><td class="docs"><h2>Transactions</h2>

<p>Handle output files in a separate transaction directory to avoid
partially finished output files if long-running processes fail.</p>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn temp-dir-w-prefix [root prefix]
  (let [dir (File/createTempFile prefix  (file root))]
    (fs/delete dir)
    (fs/mkdir dir)
    dir))</pre></td></tr><tr><td class="docs"><p>Provide a temporary directory, removed when exiting the body.</p>
</td><td class="codes"><pre class="brush: clojure">(defmacro with-temp-dir
  [[tmp-dir base-dir] &amp; body]
  `(let [~tmp-dir (temp-dir-w-prefix ~base-dir &quot;tmp&quot;)]
     (try
       ~@body
       (finally
        (fs/delete-dir ~tmp-dir)))))</pre></td></tr><tr><td class="docs"><p>Update file-info with need-tx files in a safe transaction directory.</p>
</td><td class="codes"><pre class="brush: clojure">(defn safe-tx-files
  [file-info need-tx]
  (let [tx-files (map #(get file-info %) need-tx)
        tx-dir (temp-dir-w-prefix (fs/parent (first tx-files)) &quot;txtmp&quot;)]
    (reduce (fn [m [k v]]
              (assoc m k v))
            file-info
            (zipmap need-tx
                    (map #(str (fs/file tx-dir (fs/base-name %))) tx-files)))))</pre></td></tr><tr><td class="docs"><p>Perform action with files, keeping need-tx files in a transaction.</p>
</td><td class="codes"><pre class="brush: clojure">(defmacro with-tx-files
  [[tx-file-info file-info need-tx] &amp; body]
  (if (= (count need-tx) 0)
    `(do ~@body)
    `(let [~tx-file-info (safe-tx-files ~file-info ~need-tx)]
       (try
         ~@body
         (doseq [tx-key# ~need-tx]
           (fs/rename (get ~tx-file-info tx-key#) (get ~file-info tx-key#)))
         (finally
          (fs/delete-dir (fs/parent (get ~tx-file-info (first ~need-tx)))))))))</pre></td></tr><tr><td class="docs"><h2>Naming</h2>

<p>Generate new file names from existing ones</p>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Retrieve file name without extension: /path/to/fname.txt -> /path/to/fname</p>
</td><td class="codes"><pre class="brush: clojure">(defn file-root
  [fname]
  (let [i (.lastIndexOf fname &quot;.&quot;)]
    (if (pos? i)
      (subs fname 0 i)
      fname)))</pre></td></tr><tr><td class="docs"><p>Add file extender: base.txt -> base-part.txt</p>
</td><td class="codes"><pre class="brush: clojure">(defn add-file-part
  ([fname part]
     (add-file-part fname part nil))
  ([fname part out-dir]
     (let [out-fname (format &quot;%s-%s%s&quot; (file-root fname) part (fs/extension fname))]
       (if-not (nil? out-dir)
         (str (fs/file out-dir (fs/base-name out-fname)))
         out-fname))))</pre></td></tr><tr><td class="docs"><p>Remove any zip extensions from the input filename</p>
</td><td class="codes"><pre class="brush: clojure">(defn remove-zip-ext
  [fname]
  (letfn [(maybe-remove-ext [fname ext]
            (if (.endsWith fname ext)
              (subs fname 0 (- (.length fname) (.length ext)))
              fname))]
    (let [exts [&quot;.tar.gz&quot; &quot;tar.bz2&quot; &quot;.gz&quot; &quot;.bz2&quot; &quot;.zip&quot;]]
      (reduce maybe-remove-ext fname exts))))</pre></td></tr><tr><td class="docs"><h2>File and directory manipulation</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Remove file or directory only if it exists.</p>
</td><td class="codes"><pre class="brush: clojure">(defn remove-path
  [x]
  (if (fs/exists? x)
    (if (fs/directory? x)
      (fs/delete-dir x)
      (fs/delete x))))</pre></td></tr><tr><td class="docs"><h2>Utility macros</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Emulate with-open using bindings supplied as a map.</p>
</td><td class="codes"><pre class="brush: clojure">(defmacro with-open-map
  [binding-map &amp; body]
  `(try
     ~@body
     (finally
      (vec (map #(.close %) (vals ~binding-map))))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.annotate.nbq" name="bcbio.variation.annotate.nbq"><h1 class="project-name">bcbio.variation.annotate.nbq</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>GATK annotator that calculates Mean Neighboring Base Quality (NBQ) for variants.</p>

<p>  The motivation for this annotation is that regional base quality influences whether
  a call is correct. The Atlas2 paper describes the metric in more detail:</p>

<p>  http://www.biomedcentral.com/1471-2105/13/8/abstract</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.annotate.nbq
  (:import [org.broadinstitute.sting.gatk.walkers.annotator.interfaces.InfoFieldAnnotation]
           [org.broadinstitute.sting.utils.codecs.vcf VCFInfoHeaderLine VCFHeaderLineType])
  (:require [incanter.stats :as istats])
  (:gen-class
   :name bcbio.variation.annotate.nbq.MeanNeighboringBaseQuality
   :extends org.broadinstitute.sting.gatk.walkers.annotator.interfaces.InfoFieldAnnotation))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(def flank-bp 5)</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -getKeyNames
  [_]
  [&quot;NBQ&quot;])</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -getDescriptions
  [_]
  [(VCFInfoHeaderLine. &quot;NBQ&quot; 1 VCFHeaderLineType/Float
                       (format &quot;Mean Neighboring Base Quality, includes %sbp on both sides&quot;
                               flank-bp))])</pre></td></tr><tr><td class="docs"><p>Provide Mean Neighboring Base Quality calculations at a position.</p>

<pre><code>- Get a pileup for each sample context.
- Use pileup to retrieve reads and current offsets.
- Get quality from reads and pull out qualities in surrounding region
- Calculate mean and return.
</code></pre>
</td><td class="codes"><pre class="brush: clojure">(defn -annotate
  [_ _ _ _ contexts _]
  (letfn [(get-pileup [context]
            (if (.hasExtendedEventPileup context)
              (.getExtendedEventPileup context)
              (.getBasePileup context)))
          (neighbor-qualities [[offset read]]
            (let [quals (-&gt; read .getBaseQualities vec)]
              (map #(nth quals % nil) (range (- offset flank-bp) (+ offset flank-bp)))))
          (pileup-qualities [pileup]
            (map neighbor-qualities (map vector (.getOffsets pileup) (.getReads pileup))))]
    {&quot;NBQ&quot; (-&gt;&gt; contexts
                vals
                (map get-pileup)
                (map pileup-qualities)
                flatten
                (remove nil?)
                istats/mean
                (format &quot;%.2f&quot;))}))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.annotation" name="bcbio.variation.annotation"><h1 class="project-name">bcbio.variation.annotation</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Annotate variant calls with metrics for assessing false positives
  http://www.broadinstitute.org/gsa/wiki/index.php/VariantAnnotator</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.annotation
  (:use [bcbio.variation.utils.cgmetrics :only [add-cgmetrics]])
  (:require [fs.core :as fs]
            [bcbio.run.itx :as itx]
            [bcbio.run.broad :as broad]))</pre></td></tr><tr><td class="docs"><p>Add GATK annotation metrics to variant calls.</p>
</td><td class="codes"><pre class="brush: clojure">(defn add-gatk-annotations
  [in-vcf align-bam ref &amp; {:keys [out-dir]}]
  {:pre [(not (nil? align-bam))]}
  (let [file-info {:out-vcf (itx/add-file-part in-vcf &quot;annotated&quot; out-dir)}
        annotations [&quot;AlleleBalance&quot; &quot;BaseQualityRankSumTest&quot; &quot;DepthOfCoverage&quot;
                     &quot;FisherStrand&quot; &quot;GCContent&quot; &quot;HaplotypeScore&quot; &quot;HomopolymerRun&quot;
                     &quot;MappingQualityRankSumTest&quot; &quot;MappingQualityZero&quot;
                     &quot;MeanNeighboringBaseQuality&quot; &quot;QualByDepth&quot;
                     &quot;ReadPosRankSumTest&quot; &quot;RMSMappingQuality&quot;]
        args (concat [&quot;-R&quot; ref
                      &quot;-I&quot; align-bam
                      &quot;--variant&quot; in-vcf
                      &quot;-o&quot; :out-vcf]
                     (reduce #(concat %1 [&quot;-A&quot; %2]) [] annotations))]
    (broad/index-bam align-bam)
    (broad/run-gatk &quot;VariantAnnotator&quot; args file-info {:out [:out-vcf]})
    (:out-vcf file-info)))</pre></td></tr><tr><td class="docs"><p>Flexible addition of additions to a variant file.
  Handles GATK annotations and Complete Genomics metrics.</p>
</td><td class="codes"><pre class="brush: clojure">(defn add-variant-annotations
  [vcf-file bam-file ref-file call &amp; {:keys [out-dir]}]
  (let [x (get call :annotate &quot;&quot;)
        ann (if (true? x) &quot;gatk&quot; x)]
    (cond
     (and (= ann &quot;gatk&quot;) (not (nil? bam-file)))
     (add-gatk-annotations vcf-file bam-file ref-file :out-dir out-dir)
     (.contains ann &quot;masterVar&quot;)
     (add-cgmetrics vcf-file ann ref-file :out-dir out-dir)
     :else vcf-file)))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.callable" name="bcbio.variation.callable"><h1 class="project-name">bcbio.variation.callable</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Identify callable bases from a BAM alignment file.
  Help differentiate positions where we can not assess variation</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.callable
  (:import [org.broad.tribble.bed BEDCodec]
           [org.broad.tribble.index IndexFactory]
           [org.broad.tribble.source BasicFeatureSource])
  (:use [clojure.java.io])
  (:require [fs.core :as fs]
            [bcbio.run.itx :as itx]
            [bcbio.run.broad :as broad]))</pre></td></tr><tr><td class="docs"><p>Identify callable bases from the provided alignment file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn identify-callable
  [align-bam ref &amp; {:keys [out-dir] :or {out-dir nil}}]
  (let [base-dir (if (nil? out-dir) (fs/parent align-bam) out-dir)
        base-fname (str (file base-dir (-&gt; align-bam fs/base-name itx/file-root)))
        file-info {:out-bed (format &quot;%s-callable.bed&quot; base-fname)
                   :out-summary (format &quot;%s-callable-summary.txt&quot; base-fname)}
        args [&quot;-R&quot; ref
              &quot;-I&quot; align-bam
              &quot;--out&quot; :out-bed
              &quot;--summary&quot; :out-summary]]
    (if-not (fs/exists? base-dir)
      (fs/mkdirs base-dir))
    (broad/index-bam align-bam)
    (broad/run-gatk &quot;CallableLoci&quot; args file-info {:out [:out-bed :out-summary]})
    (:out-bed file-info)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn features-in-region [source space start end]
  (for [f (.query source space start end)]
    {:chr (.getChr f)
     :start (.getStart f)
     :end (.getEnd f)
     :name (.getName f)
     :score (.getScore f)
     :strand (.getStrand f)}))</pre></td></tr><tr><td class="docs"><p>Provide tribble feature source for a BED formatted file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-bed-source
  [bed-file]
  (let [batch-size 500
        idx (IndexFactory/createIntervalIndex (file bed-file) (BEDCodec.) batch-size)]
    (BasicFeatureSource. bed-file idx (BEDCodec.))))</pre></td></tr><tr><td class="docs"><p>Provide function to check if a region (chromsome start end) is callable.
  Calculates based on reads in input BAM file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn callable-checker
  [align-bam ref &amp; {:keys [out-dir] :or {out-dir nil}}]
  (if (nil? align-bam) [(fn [&amp; _] true) (java.io.StringReader. &quot;&quot;)]
      (let [source (get-bed-source (identify-callable align-bam ref :out-dir out-dir))]
        (letfn [(is-callable? [space start end]
                  (&gt; (count (filter #(= (:name %) &quot;CALLABLE&quot;)
                                    (features-in-region source space start end)))
                     0))]
          [is-callable? source]))))</pre></td></tr><tr><td class="docs"><p>Create BED file of callable regions from the BAM alignment file.
  Pass the callable BED to GATK for subsetting based on callable intervals.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-callable-bed
  [align-bam ref &amp; {:keys [out-dir]}]
  (let [orig-bed-file (identify-callable align-bam ref :out-dir out-dir)
        out-file (itx/add-file-part orig-bed-file &quot;intervals&quot;)]
    (with-open [source (get-bed-source orig-bed-file)
                wtr (writer out-file)]
      (doseq [f (.iterator source)]
        (when (= (.getName f) &quot;CALLABLE&quot;)
          (.write wtr (format &quot;%s\t%s\t%s\n&quot; (.getChr f)
                              (dec (.getStart f)) (inc (.getEnd f)))))))
    out-file))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.combine" name="bcbio.variation.combine"><h1 class="project-name">bcbio.variation.combine</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Combine variant files, handling no-calls versus reference calls</p>

<ol>
<li>Combine the variants to create a merged set of positions to call at</li>
<li>For each variant file:
  a. Generate callability at each position
  b. Combine original calls with merged positions
  c. Walk through each no-call and set as reference if callable</li>
</ol>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.combine
  (:import [org.broadinstitute.sting.utils.variantcontext
            Genotype VariantContextBuilder GenotypesContext])
  (:use [bcbio.variation.variantcontext :only [parse-vcf write-vcf-w-template get-vcf-source
                                               get-vcf-header]]
        [bcbio.variation.callable :only [callable-checker]]
        [bcbio.variation.complex :only [normalize-variants]]
        [bcbio.variation.normalize :only [prep-vcf clean-problem-vcf]])
  (:require [fs.core :as fs]
            [clojure.string :as string]
            [bcbio.run.itx :as itx]
            [bcbio.run.broad :as broad]))</pre></td></tr><tr><td class="docs"><p>Supply GATK commandline arguments for interval files, merging via intersection.</p>
</td><td class="codes"><pre class="brush: clojure">(defn gatk-cl-intersect-intervals
  [intervals]
  (cond
   (nil? intervals) []
   (coll? intervals) (concat (flatten (map #(list &quot;-L&quot; %) intervals))
                             [&quot;--interval_set_rule&quot; &quot;INTERSECTION&quot;])
   :else [&quot;-L&quot;, intervals]))</pre></td></tr><tr><td class="docs"><p>Combine multiple variant files with GATK CombineVariants.</p>
</td><td class="codes"><pre class="brush: clojure">(defn combine-variants
  [vcfs ref &amp; {:keys [merge-type out-dir intervals unsafe name-map base-ext]
               :or {merge-type :unique unsafe false name-map {}}}]
  (letfn [(unique-name [f]
            (get name-map f
                 (-&gt; f fs/base-name itx/file-root)))]
    (let [base-dir (if (nil? out-dir) (fs/parent (first vcfs)) out-dir)
          full-base-name (-&gt; vcfs first fs/base-name itx/remove-zip-ext)
          base-name (if (nil? base-ext) full-base-name
                        (format &quot;%s-%s.vcf&quot; (first (string/split full-base-name #&quot;-&quot;))
                                base-ext))
          file-info {:out-vcf (str (fs/file base-dir
                                            (itx/add-file-part base-name
                                                               (case merge-type
                                                                     :minimal &quot;mincombine&quot;
                                                                     :full &quot;fullcombine&quot;
                                                                     &quot;combine&quot;))))}
          args (concat [&quot;-R&quot; ref
                        &quot;-o&quot; :out-vcf
                        &quot;--rod_priority_list&quot; (string/join &quot;,&quot; (map unique-name vcfs))]
                       (if unsafe [&quot;--unsafe&quot; &quot;ALLOW_SEQ_DICT_INCOMPATIBILITY&quot;] [])
                       (flatten (map #(list (str &quot;--variant:&quot; (unique-name %)) %) vcfs))
                       (gatk-cl-intersect-intervals intervals)
                       (case merge-type
                             :full [&quot;--genotypemergeoption&quot; &quot;PRIORITIZE&quot;]
                             :unique [&quot;--genotypemergeoption&quot; &quot;UNIQUIFY&quot;]
                             :minimal [&quot;--sites_only&quot; &quot;--minimalVCF&quot;]))]
      (if-not (fs/exists? base-dir)
        (fs/mkdirs base-dir))
      (broad/run-gatk &quot;CombineVariants&quot; args file-info {:out [:out-vcf]})
      (:out-vcf file-info))))</pre></td></tr><tr><td class="docs"><p>Convert no-calls into callable reference and real no-calls.</p>
</td><td class="codes"><pre class="brush: clojure">(defn convert-no-calls
  [in-vcf align-bam ref &amp; {:keys [out-dir] :or {out-dir nil}}]
  (let [out-file (itx/add-file-part in-vcf &quot;wrefs&quot;)
        [is-callable? call-source] (callable-checker align-bam ref :out-dir out-dir)]
    (letfn [(ref-genotype [g vc]
              (doto (-&gt; vc :vc .getGenotypes GenotypesContext/copy)
                (.replace
                 (Genotype/modifyAlleles (:genotype g)
                                         (repeat (count (:alleles g))
                                                 (:ref-allele vc))))))
            (maybe-callable-vc [vc]
              {:pre (= 1 (count (:genotypes vc)))}
              (let [g (-&gt; vc :genotypes first)]
                (if (.isNoCall (-&gt; g :alleles first))
                  (if (is-callable? (:chr vc) (:start vc) (:end vc))
                    (-&gt; (VariantContextBuilder. (:vc vc))
                        (.genotypes (ref-genotype g vc))
                        (.make))
                    (-&gt; (VariantContextBuilder. (:vc vc))
                        (.filters #{&quot;NotCallable&quot;})
                        (.make)))
                  (:vc vc))))
            (convert-vcs [vcf-source]
              (for [vc (parse-vcf vcf-source)]
                [:out (maybe-callable-vc vc)]))]
      (if (itx/needs-run? out-file)
        (with-open [in-vcf-s (get-vcf-source in-vcf ref)
                    _ call-source]
          (write-vcf-w-template in-vcf {:out out-file} (convert-vcs in-vcf-s) ref)))
      out-file)))</pre></td></tr><tr><td class="docs"><p>Check if the input VCF file has multiple genotyped samples.</p>
</td><td class="codes"><pre class="brush: clojure">(defn multiple-samples?
  [in-file &amp; {:keys [sample]}]
  (let [samples (-&gt; in-file get-vcf-header .getGenotypeSamples)]
    (or (&gt; (count samples) 1)
        (and (not (nil? sample))
             (not (contains? (set samples) sample))))))</pre></td></tr><tr><td class="docs"><p>Retrieve the sample name in a provided VCF file, allowing for partial matches.</p>
</td><td class="codes"><pre class="brush: clojure">(defn vcf-sample-name
  [sample in-vcf ref-file]
  (letfn [(sample-match [x choices]
            (let [do-match (filter #(when (.contains % x) %) choices)]
              (when (= 1 (count do-match))
                (first do-match))))]
    (let [vcf-samples (with-open [vcf-source (get-vcf-source in-vcf ref-file)]
                        (-&gt; vcf-source .getHeader .getGenotypeSamples set))]
      (if (contains? vcf-samples sample)
        sample
        (sample-match sample vcf-samples)))))</pre></td></tr><tr><td class="docs"><p>Select only the sample of interest from input VCF files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn select-by-sample
  [sample in-file name ref &amp; {:keys [out-dir intervals remove-refcalls]
                              :or {remove-refcalls false}}]
  (let [base-dir (if (nil? out-dir) (fs/parent in-file) out-dir)
        file-info {:out-vcf (str (fs/file base-dir
                                          (format &quot;%s-%s.vcf&quot; sample name)))}
        args (concat [&quot;-R&quot; ref
                      &quot;--sample_name&quot; (vcf-sample-name sample in-file ref)
                      &quot;--variant&quot; in-file
                      &quot;--unsafe&quot; &quot;ALLOW_SEQ_DICT_INCOMPATIBILITY&quot;
                      &quot;--out&quot; :out-vcf]
                     (if remove-refcalls [&quot;--excludeNonVariants&quot; &quot;--excludeFiltered&quot;] [])
                     (if-not (nil? intervals) [&quot;-L&quot; intervals] []))]
    (if-not (fs/exists? base-dir)
      (fs/mkdirs base-dir))
    (broad/run-gatk &quot;SelectVariants&quot; args file-info {:out [:out-vcf]})
    (:out-vcf file-info)))</pre></td></tr><tr><td class="docs"><p>Create merged VCF files with no-call/ref-calls for each of the inputs.</p>
</td><td class="codes"><pre class="brush: clojure">(defn create-merged
  [vcfs align-bams do-merges ref &amp; {:keys [out-dir intervals]
                                    :or {out-dir nil intervals nil}}]
  (letfn [(merge-vcf [vcf all-vcf align-bam ref]
            (let [ready-vcf (combine-variants [vcf all-vcf] ref
                                              :merge-type :full :intervals intervals
                                              :out-dir out-dir)]
              (convert-no-calls ready-vcf align-bam ref :out-dir out-dir)))]
    (let [merged (combine-variants vcfs ref :merge-type :minimal :intervals intervals
                                   :out-dir out-dir)]
      (map (fn [[v b merge?]] (if merge? (merge-vcf v merged b ref) v))
           (map vector vcfs align-bams do-merges)))))</pre></td></tr><tr><td class="docs"><p>Prepare input file for comparisons based on configuration:
    - Selecting a single sample from multi-sample files
    - Resorting and fixing chromosome naming
    - Removing reference call genotypes
   This organizes the logic which get convoluted for different cases.
   The approach is to select a single sample and remove refcalls if we have
   a multiple sample file, so the sample name will be correct.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- dirty-prep-work
  [in-file call exp out-dir out-fname]
  (letfn [(run-sample-select [in-file]
            (select-by-sample (:sample exp) in-file (:name call)
                              (get call :ref (:ref exp))
                              :out-dir out-dir
                              :remove-refcalls (get call :remove-refcalls false)))]
    (let [sample-file (if (multiple-samples? in-file)
                        (run-sample-select in-file)
                        in-file)
          prep-file (if (true? (:prep call))
                      (prep-vcf sample-file (:ref exp) (:sample exp) :out-dir out-dir
                                :out-fname out-fname :orig-ref-file (:ref call))
                      sample-file)
          noref-file (if (and (not (multiple-samples? in-file)) (:remove-refcalls call))
                       (run-sample-select prep-file)
                       prep-file)]
      noref-file)))</pre></td></tr><tr><td class="docs"><p>Prepare call information for VCF comparisons by normalizing through GATK.
  Handles:</p>

<ol>
<li>Combining multiple input files</li>
<li>Fixing reference and sample information.</li>
<li>Splitting combined MNPs into phased SNPs</li>
</ol>
</td><td class="codes"><pre class="brush: clojure">(defn gatk-normalize
  [call exp out-dir]
  (if-not (fs/exists? out-dir)
    (fs/mkdirs out-dir))
  (letfn [(merge-call-files [call in-files]
            (combine-variants in-files (get call :ref (:ref exp))
                              :merge-type :full :out-dir out-dir
                              :unsafe true))]
    (let [out-fname (format &quot;%s-%s.vcf&quot; (:sample exp) (:name call))
          in-files (if (coll? (:file call)) (:file call) [(:file call)])
          clean-files (map #(if-not (:preclean call) %
                                    (clean-problem-vcf % :out-dir out-dir))
                           in-files)
          merge-file (if (&gt; (count clean-files) 1)
                       (merge-call-files call clean-files)
                       (first clean-files))
          prep-file (dirty-prep-work merge-file call exp out-dir out-fname)]
      (assoc call :file (if (true? (get call :normalize true))
                          (normalize-variants prep-file (:ref exp) out-dir
                                              :out-fname out-fname)
                          prep-file)))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.compare" name="bcbio.variation.compare"><h1 class="project-name">bcbio.variation.compare</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Generate comparisons between two sets of variant calls.
   Utilizes GATK walkers to generate detailed and summary statistics
   about two sets of calls:</p>

<ul>
<li>Identify non-callable regions with CallableLociWalker</li>
<li>Combine variants from two samples</li>
<li>Use VariantEval to calculate overall concordance statistics</li>
<li>Provide output for concordant and discordant regions for
 detailed investigation</li>
</ul>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.compare
  (:use [bcbio.variation.variantcontext :only [parse-vcf write-vcf-w-template
                                               get-vcf-source]]
        [bcbio.variation.metrics :only [vcf-stats write-summary-table]]
        [bcbio.variation.report :only [concordance-report-metrics
                                       write-concordance-metrics
                                       write-scoring-table
                                       top-level-metrics
                                       write-classification-metrics]]
        [bcbio.variation.combine :only [combine-variants create-merged
                                        gatk-normalize gatk-cl-intersect-intervals]]
        [bcbio.variation.annotation :only [add-variant-annotations]]
        [bcbio.variation.filter :only [variant-filter pipeline-recalibration]]
        [bcbio.variation.phasing :only [is-haploid? compare-two-vcf-phased]]
        [bcbio.variation.callable :only [get-callable-bed]]
        [bcbio.variation.multiple :only [prep-cmp-name-lookup pipeline-compare-multiple]]
        [bcbio.variation.validate :only [pipeline-validate]]
        [bcbio.align.reorder :only [reorder-bam]]
        [ordered.map :only [ordered-map]]
        [clojure.math.combinatorics :only [combinations]]
        [clojure.java.io])
  (:require [clojure.string :as string]
            [clojure.data.csv :as csv]
            [fs.core :as fs]
            [clj-yaml.core :as yaml]
            [bcbio.run.itx :as itx]
            [bcbio.run.broad :as broad]))</pre></td></tr><tr><td class="docs"><h2>Variance assessment</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Compare two variant files with GenotypeConcordance in VariantEval</p>
</td><td class="codes"><pre class="brush: clojure">(defn calc-variant-eval-metrics
  [sample vcf1 vcf2 ref &amp; {:keys [out-base intervals]}]
  (let [file-info {:out-eval (str (itx/file-root (if (nil? out-base) vcf1 out-base)) &quot;.eval&quot;)}
        args (concat
              [&quot;-R&quot; ref
               &quot;--out&quot; :out-eval
               &quot;--eval&quot; vcf1
               &quot;--comp&quot; vcf2
               &quot;--sample&quot; sample
               &quot;--doNotUseAllStandardModules&quot;
               &quot;--evalModule&quot; &quot;CompOverlap&quot;
               &quot;--evalModule&quot; &quot;CountVariants&quot;
               &quot;--evalModule&quot; &quot;GenotypeConcordance&quot;
               &quot;--evalModule&quot; &quot;TiTvVariantEvaluator&quot;
               &quot;--evalModule&quot; &quot;ValidationReport&quot;
               &quot;--stratificationModule&quot; &quot;Sample&quot;
               &quot;--stratificationModule&quot; &quot;Filter&quot;]
              (gatk-cl-intersect-intervals intervals))]
    (broad/run-gatk &quot;VariantEval&quot; args file-info {:out [:out-eval]})
    (:out-eval file-info)))</pre></td></tr><tr><td class="docs"><p>Variant comparison producing 3 files: concordant and both directions discordant</p>
</td><td class="codes"><pre class="brush: clojure">(defn select-by-concordance
  [sample call1 call2 ref &amp; {:keys [out-dir interval-file]}]
  (let [base-dir (if (nil? out-dir) (fs/parent (:file call1)) out-dir)]
    (if-not (fs/exists? base-dir)
      (fs/mkdirs base-dir))
    (doall
     (for [[c1 c2 cmp-type] [[call1 call2 &quot;concordance&quot;]
                             [call1 call2 &quot;discordance&quot;]
                             [call2 call1 &quot;discordance&quot;]]]
       (let [file-info {:out-vcf (str (fs/file base-dir
                                               (format &quot;%s-%s-%s-%s.vcf&quot;
                                                       sample (:name c1) (:name c2) cmp-type)))}
             args (concat
                   [&quot;-R&quot; ref
                    &quot;--sample_name&quot; sample
                    &quot;--variant&quot; (:file c1)
                    (str &quot;--&quot; cmp-type) (:file c2)
                    &quot;--out&quot; :out-vcf]
                   (if-not (nil? interval-file) [&quot;-L:bed&quot; interval-file] []))]
         (broad/run-gatk &quot;SelectVariants&quot; args file-info {:out [:out-vcf]})
         (:out-vcf file-info))))))</pre></td></tr><tr><td class="docs"><h2>Custom parsing and combinations</h2>

<p>Utilizes GATK VariantContexts</p>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Lazy stream of VariantContexts categorized by concordant/discordant matching.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- vc-by-match-category
  [vcf-source]
  (letfn [(genotype-alleles [g]
            (vec (map #(.toString %) (:alleles g))))
          (is-concordant? [vc]
            (= (-&gt; (map genotype-alleles (:genotypes vc))
                   set
                   count)
               1))]
    (for [vc (parse-vcf vcf-source)]
      [(if (is-concordant? vc) :concordant :discordant)
       (:vc vc)])))</pre></td></tr><tr><td class="docs"><p>Provide concordant and discordant variants for two variant files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn split-variants-by-match
  [vcf1 vcf2 ref]
  (let [combo-file (combine-variants [vcf1 vcf2] ref)
        out-map {:concordant (itx/add-file-part combo-file &quot;concordant&quot;)
                 :discordant (itx/add-file-part combo-file &quot;discordant&quot;)}]
    (if-not (fs/exists? (:concordant out-map))
      (with-open [combo-vcf-s (get-vcf-source combo-file ref)]
        (write-vcf-w-template combo-file out-map (vc-by-match-category combo-vcf-s)
                              ref)))
    out-map))</pre></td></tr><tr><td class="docs"><h2>Top-level</h2>

<p>Process a directory of variant calls from multiple
sources, generating a summary of concordance plus detailed metrics
differences for tweaking filters.</p>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- get-summary-writer [config config-file ext]
  (if-not (nil? (get-in config [:dir :out]))
    (do
      (if-not (fs/exists? (get-in config [:dir :out]))
        (fs/mkdirs (get-in config :dir :out)))
      (writer (str (fs/file (get-in config [:dir :out])
                            (format &quot;%s-%s&quot;
                                    (itx/file-root (fs/base-name config-file)) ext)))))
    (writer System/out)))</pre></td></tr><tr><td class="docs"><p>Retrieve BAM files associated with alignments, normalizing if needed.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- prepare-input-bams
  [exp out-dir]
  (let [call-bams (map (fn [c] [(get c :align (:align exp)) c]) (:calls exp))]
    (map (fn [[b c]] (when-not (nil? b)
                     (reorder-bam b (:ref exp) c exp :out-dir out-dir)))
         call-bams)))</pre></td></tr><tr><td class="docs"><p>Prepare merged and annotated VCF files for an experiment.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- prepare-vcf-calls
  [exp config]
  (let [out-dir (get-in config [:dir :prep] (get-in config [:dir :out]))
        align-bams (prepare-input-bams exp out-dir)
        start-vcfs (map #(gatk-normalize % exp out-dir) (:calls exp))
        all-intervals (remove nil? (map :intervals (cons exp (:calls exp))))
        merged-vcfs (create-merged (map :file start-vcfs)
                                   align-bams
                                   (map #(get % :refcalls false) (:calls exp))
                                   (:ref exp) :out-dir out-dir
                                   :intervals all-intervals)
        ann-vcfs (map (fn [[v b c]]
                        (add-variant-annotations v b (:ref exp) c :out-dir out-dir))
                      (map vector merged-vcfs align-bams (:calls exp)))
        filter-vcfs (map (fn [[v c]] (if-not (nil? (:filters c))
                                       (variant-filter v (:filters c) (:ref exp))
                                       v))
                         (map vector ann-vcfs (:calls exp)))]
    (map (fn [[c v b]] (-&gt; c
                           (assoc :file v)
                           (assoc :align b)))
         (map vector (:calls exp) filter-vcfs align-bams))))</pre></td></tr><tr><td class="docs"><p>Compare two standard VCF files based on the supplied configuration.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- compare-two-vcf-standard
  [c1 c2 exp config]
  (letfn [(callable-intervals [exp c1 c2]
            (let [out-dir (get-in config [:dir :prep] (get-in config [:dir :out]))]
              (remove nil? (cons (:intervals exp)
                                 (map #(when-not (nil? (:align %))
                                         (get-callable-bed (:align %) (:ref exp)
                                                           :out-dir out-dir))
                                      [c1 c2])))))
          (discordant-name [x]
            (format &quot;%s-discordant&quot; (:name x)))
          (zipmap-ordered [xs1 xs2]
            (apply ordered-map (interleave xs1 xs2)))]
    (let [c-files (select-by-concordance (:sample exp) c1 c2 (:ref exp)
                                         :out-dir (get-in config [:dir :out])
                                         :interval-file (:intervals exp))
          eval (calc-variant-eval-metrics (:sample exp) (:file c1) (:file c2) (:ref exp)
                                          :out-base (first c-files)
                                          :intervals (:intervals exp))
          c-eval (calc-variant-eval-metrics (:sample exp) (:file c1) (:file c2) (:ref exp)
                                            :out-base (itx/add-file-part (first c-files) &quot;callable&quot;)
                                            :intervals (callable-intervals exp c1 c2))]
      {:c-files (zipmap-ordered [&quot;concordant&quot; (discordant-name c1) (discordant-name c2)]
                                c-files)
       :c1 c1 :c2 c2 :exp exp :dir (config :dir)
       :metrics (first (concordance-report-metrics (:sample exp) eval))
       :callable-metrics (first (concordance-report-metrics (:sample exp) c-eval))})))</pre></td></tr><tr><td class="docs"><p>Compare two VCF files, handling standard and haploid specific comparisons.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- compare-two-vcf
  [c1 c2 exp config]
  (let [phased-vcfs (group-by #(-&gt; % :file (is-haploid? (:ref exp))) [c1 c2])]
    (if (get phased-vcfs true)
      (compare-two-vcf-phased (first (get phased-vcfs false))
                              (first (get phased-vcfs true))
                              exp config)
      (compare-two-vcf-standard c1 c2 exp config))))</pre></td></tr><tr><td class="docs"><h2>Customizable finalizer comparisons</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Run a post-pairwise comparison function, returning updated comparison details,</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti run-finalizer
  (fn [cmps finalizer exp config] (-&gt; finalizer :method keyword)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod run-finalizer :recal-filter
  [&amp; args]
  (apply pipeline-recalibration args))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod run-finalizer :multiple
  [&amp; args]
  (apply pipeline-compare-multiple args))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod run-finalizer :validate
  [&amp; args]
  (apply pipeline-validate args))</pre></td></tr><tr><td class="docs"><p>Finalize all comparisons with finished initial pass data.</p>
</td><td class="codes"><pre class="brush: clojure">(defn finalize-comparisons
  [cmps exp config]
  (letfn [(add-summary [x]
            (-&gt; x
                (assoc :exp exp)
                (#(assoc % :summary (top-level-metrics %)))))
          (update-w-finalizer [cur-cmps finalizer]
            &quot;Update the current comparisons with a defined finalizer.&quot;
            (let [updated-cmp (run-finalizer cur-cmps finalizer exp config)]
              (assoc cur-cmps (map #(get-in updated-cmp [% :name]) [:c1 :c2])
                     (if-not (:re-compare updated-cmp) updated-cmp
                             (compare-two-vcf (:c1 updated-cmp) (:c2 updated-cmp) exp config)))))]
    (-&gt;&gt; (reduce update-w-finalizer
                 (prep-cmp-name-lookup cmps) (:finalize exp))
         vals
         (map add-summary))))</pre></td></tr><tr><td class="docs"><h2>Top-level</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Load configuration file, handling conversion of relative to absolute paths.</p>
</td><td class="codes"><pre class="brush: clojure">(defn load-config
  [config-file]
  (let [config (-&gt; config-file slurp yaml/parse-string)
        base-dir (fs/file (get-in config [:dir :base] &quot;.&quot;))
        to-process #{[:dir :out] [:dir :prep]
                     [:experiments :ref] [:experiments :intervals]
                     [:experiments :align] [:experiments :calls :file]
                     [:experiments :calls :align] [:experiments :calls :annotate]}]
    (letfn [(make-absolute [x]
              (if (.isAbsolute (file x))
                x
                (str (fs/file base-dir x))))
            (maybe-process [val path]
              (if (contains? to-process path)
                (cond
                 (seq? val) (map make-absolute val)
                 (string? val) (make-absolute val)
                 :else val)
                val))
            (update-tree [config path]
              (cond (map? config)
                    (reduce (fn [item [k v]]
                              (assoc item k (cond
                                             (map? v) (update-tree v (conj path k))
                                             (seq? v) (map #(update-tree % (conj path k)) v)
                                             :else (maybe-process v (conj path k)))))
                            config
                            (vec config))
                    (contains? to-process path) (maybe-process config path)
                    :else config))]
      (update-tree config []))))</pre></td></tr><tr><td class="docs"><p>Perform comparison between variant calls using inputs from YAML config.</p>
</td><td class="codes"><pre class="brush: clojure">(defn variant-comparison-from-config
  [config-file]
  (let [config (load-config config-file)
        comparisons (flatten
                     (for [exp (:experiments config)]
                       (let [cmps (for [[c1 c2] (combinations (prepare-vcf-calls exp config) 2)]
                                    (compare-two-vcf c1 c2 exp config))]
                         (finalize-comparisons cmps exp config))))]
    (with-open [w (get-summary-writer config config-file &quot;summary.txt&quot;)
                w2 (get-summary-writer config config-file &quot;files.csv&quot;)]
      (csv/write-csv w2 [[&quot;call1&quot; &quot;call2&quot; &quot;type&quot; &quot;fname&quot;]])
      (doseq [x comparisons]
        (.write w (format &quot;* %s : %s vs %s\n&quot; (-&gt; x :exp :sample)
                          (-&gt; x :c1 :name) (-&gt; x :c2 :name)))
        (write-scoring-table (:metrics x) w)
        (write-concordance-metrics (:summary x) w)
        (when (get-in x [:c1 :mod])
          (write-classification-metrics x w))
        (doseq [[k f] (:c-files x)]
          (.write w (format &quot;** %s\n&quot; (name k)))
          (csv/write-csv w2 [[(get-in x [:c1 :name]) (get-in x [:c2 :name]) (name k)
                              (string/replace-first f (str (get-in config [:dir :out]) &quot;/&quot;) &quot;&quot;)]])
          (write-summary-table (vcf-stats f (get-in x [:exp :ref])) :wrtr w))))
    (with-open [w (get-summary-writer config config-file &quot;summary.csv&quot;)]
      (doseq [[i x] (map-indexed vector (map :summary comparisons))]
        (when (= i 0)
          (.write w (format &quot;%s\n&quot; (string/join &quot;,&quot; (map name (keys x))))))
        (.write w (format &quot;%s\n&quot; (string/join &quot;,&quot; (for [v (vals x)]
                                                    (if (map? v) (:total v) v)))))))
    comparisons))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main [config-file]
  (variant-comparison-from-config config-file)
  nil)</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.complex" name="bcbio.variation.complex"><h1 class="project-name">bcbio.variation.complex</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Handle complex variations representations: multi-nucleotide
   polymorphisms and indels.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.complex
  (:import [org.broadinstitute.sting.utils.variantcontext Allele
            VariantContextBuilder GenotypesContext Genotype
            VariantContextUtils])
  (:use [bcbio.variation.variantcontext :only [parse-vcf write-vcf-w-template
                                               get-vcf-source]])
  (:require [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><h2>Multi-nucleotide polymorphisms (MNPs)</h2>

<p>Split into single variant primitives.</p>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Do a set of alleles have any variants at a position.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- has-variant-base?
  [alleles i]
  (&gt; (count (set (map #(nth % i nil) alleles)))
     1))</pre></td></tr><tr><td class="docs"><p>Detect single call SNP variants within a MNP genotype.
  Handles reference no-variant padding bases on the 5' end of
  the sequence, writing only variants at the adjusted positions.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- split-alleles
  [vc genotype]
  (letfn [(mnp-ref-padding [ref-allele vc]
            {:post [(&gt;= % 0)]}
            (- (inc (- (:end vc) (:start vc)))
               (count ref-allele)))
          (extract-variants [alleles i ref-pad]
            (let [ref-allele (nth (first alleles) i)
                  cur-alleles (map #(Allele/create (str (nth % i))
                                                   (= ref-allele (nth % i)))
                                   alleles)]
              {:offset (+ i ref-pad)
               :ref-allele (first cur-alleles)
               :alleles (rest cur-alleles)}))]
    (let [orig-alleles (map #(.getBaseString %) (cons (:ref-allele vc) (:alleles genotype)))
          ref-pad (mnp-ref-padding (first orig-alleles) vc)]
      (remove nil?
              (for [i (-&gt; orig-alleles first count range)]
                (if (has-variant-base? orig-alleles i)
                  (extract-variants orig-alleles i ref-pad)))))))</pre></td></tr><tr><td class="docs"><p>Retrieve a new genotype with the given alleles.
   Creates a single genotype from the VariantContext, copying the existing
   genotype and substituting in the provided alleles and phasing information.</p>
</td><td class="codes"><pre class="brush: clojure">(defn genotype-w-alleles
  [vc alleles is-phased]
  (let [genotype (first (.getGenotypes vc))]
    (doto (-&gt; vc .getGenotypes GenotypesContext/copy)
      (.replace
       (Genotype. (.getSampleName genotype)
                  alleles
                  (.getLog10PError genotype)
                  (if (.filtersWereApplied genotype) (.getFilters genotype) nil)
                  (.getAttributes genotype)
                  is-phased)))))</pre></td></tr><tr><td class="docs"><p>Create a new VariantContext as a subset of an existing variant.
   <code>allele-info</code> specifies the location size and alleles for the new variant:
   <code>{:offset :size :ref-allele :alleles}</code></p>
</td><td class="codes"><pre class="brush: clojure">(defn- new-split-vc
  [vc i allele-info]
  (let [pos (+ (:offset allele-info) (.getStart vc))]
    (-&gt; (VariantContextBuilder. vc)
        (.start pos)
        (.stop (+ pos (get allele-info :size 0)))
        (.genotypes (genotype-w-alleles vc (:alleles allele-info) (&gt; i 0)))
        (.alleles (set (cons (:ref-allele allele-info) (:alleles allele-info))))
        (.make))))</pre></td></tr><tr><td class="docs"><p>Split a MNP into individual alleles</p>
</td><td class="codes"><pre class="brush: clojure">(defn- split-mnp
  [vc]
  {:pre [(= 1 (count (:genotypes vc)))]}
  (let [alleles (split-alleles vc (-&gt; vc :genotypes first))]
    (map (fn [[i x]] (new-split-vc (:vc vc) i x)) (map-indexed vector alleles))))</pre></td></tr><tr><td class="docs"><h2>Indels</h2>

<p>Create a normalized representation for comparison.</p>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Remove extra variant bases, if necessary, from 5' end of indels.
  Checks both called alleles and potential alleles for extra 5' padding
  removing this if not needed to distinguish any potential alleles.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- maybe-strip-indel
  [vc]
  {:pre [(= 1 (count (:genotypes vc)))]}
  (letfn [(strip-indel [vc i alleles]
            (let [start-pos (- i 1)
                  ref-allele (subs (first alleles) start-pos)
                  cur-alleles (map #(Allele/create (subs % start-pos)
                                                   (= ref-allele (subs % start-pos)))
                                   alleles)]
              (new-split-vc vc 0 {:offset i
                                  :size (- (count ref-allele) 1)
                                  :ref-allele (first cur-alleles)
                                  :alleles (rest cur-alleles)})))
          (variant-allele-pos [input-alleles]
            (let [str-alleles (map #(.getBaseString %) input-alleles)
                  first-var-i (first (filter #(has-variant-base? str-alleles %)
                                     (range (apply max (map count str-alleles)))))]
              [str-alleles first-var-i]))]
    (let [[orig-alleles first-var-i] (variant-allele-pos (cons (:ref-allele vc)
                                                               (-&gt; vc :genotypes first :alleles)))
          [_ nocall-i] (variant-allele-pos (cons (:ref-allele vc) (:alt-alleles vc)))]
      (if (or (nil? first-var-i) (= first-var-i 0)
              (nil? nocall-i) (= nocall-i 0))
        (:vc vc)
        (strip-indel (:vc vc) first-var-i orig-alleles)))))</pre></td></tr><tr><td class="docs"><h2>VCF file conversion</h2>

<p>Process entire files, normalizing complex variations</p>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Provide lazy stream of variants, avoiding MNP overlaps with single variants.
  Variant representations can have a MNP and also a single SNP representing
  the same information. In this case we ignore SNPs overlapping a MNP region
  and rely on MNP splitting to resolve the SNPs.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- vcs-no-mnp-overlaps
  [vc-iter]
  (letfn [(mnp-end [x]
            (if (= &quot;MNP&quot; (:type x))
              (:end x)
              (:start x)))
          (mnp-overlap? [cur prev]
            (cond
             (nil? prev) false
             (and (= (:chr prev) (:chr cur))
                  (&gt; (mnp-end prev) (:start cur))) true
                  :else false))]
    (let [num-prev 5]
      (remove nil?
              (for [[prev cur] (map (juxt butlast last)
                                    (partition num-prev 1 (concat (repeat (dec num-prev) nil)
                                                                  vc-iter)))]
                (if (not-any? (partial mnp-overlap? cur) prev)
                  cur))))))</pre></td></tr><tr><td class="docs"><p>Lazy list of variant context with MNPs split into single genotypes and indels stripped.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-normalized-vcs
  [vcf-source]
  (map (fn [x] [:out x])
   (flatten
    (for [vc (vcs-no-mnp-overlaps (parse-vcf vcf-source))]
      (condp = (:type vc)
        &quot;MNP&quot; (split-mnp vc)
        &quot;INDEL&quot; (maybe-strip-indel vc)
        (:vc vc))))))</pre></td></tr><tr><td class="docs"><p>Convert MNPs and indels into normalized representation.</p>
</td><td class="codes"><pre class="brush: clojure">(defn normalize-variants
  ([in-file ref]
     (normalize-variants in-file ref nil))
  ([in-file ref out-dir &amp; {:keys [out-fname]}]
     (let [base-name (if (nil? out-fname) (itx/remove-zip-ext in-file) out-fname)
           out-file (itx/add-file-part base-name &quot;nomnp&quot; out-dir)]
       (if (itx/needs-run? [out-file])
         (with-open [vcf-source (get-vcf-source in-file ref)]
           (write-vcf-w-template in-file {:out out-file} (get-normalized-vcs vcf-source) ref)))
       out-file)))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.core" name="bcbio.variation.core"><h1 class="project-name">bcbio.variation.core</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.core
  (:import [org.broadinstitute.sting.gatk CommandLineGATK])
  (:gen-class))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main [&amp; args]
  (CommandLineGATK/main (into-array (if-not (nil? args) args [&quot;-h&quot;]))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.filter" name="bcbio.variation.filter"><h1 class="project-name">bcbio.variation.filter</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Filter variant calls according to supplied criteria.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.filter
  (:import [org.broadinstitute.sting.utils.variantcontext
            VariantContextBuilder])
  (:use [clojure.string :only [split]]
        [bcbio.variation.multiple :only [multiple-overlap-analysis]]
        [bcbio.variation.variantcontext :only [parse-vcf write-vcf-w-template
                                               get-vcf-source]])
  (:require [bcbio.run.broad :as broad]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn jexl-from-config [jexl-filters]
  &quot;Retrieve GATK JEXL commandline expressions from filters.&quot;
  (letfn [(jexl-args [x]
            [&quot;--filterName&quot; (str (first (split x #&quot;\s+&quot;)) &quot;Filter&quot;)
             &quot;--filterExpression&quot; x])]
    (flatten (map jexl-args jexl-filters))))</pre></td></tr><tr><td class="docs"><p>Perform hard variant filtering with supplied JEXL expression criteria.</p>
</td><td class="codes"><pre class="brush: clojure">(defn variant-filter
  [in-vcf jexl-filters ref]
  (let [file-info {:out-vcf (itx/add-file-part in-vcf &quot;filter&quot;)}
        args (concat [&quot;-R&quot; ref
                      &quot;--variant&quot; in-vcf
                      &quot;-o&quot; :out-vcf
                      &quot;-l&quot; &quot;ERROR&quot;]
                      (jexl-from-config jexl-filters))]
    (broad/run-gatk &quot;VariantFiltration&quot; args file-info {:out [:out-vcf]})
    (:out-vcf file-info)))</pre></td></tr><tr><td class="docs"><p>Perform the variant recalibration step with input training VCF files.
  training-vcfs is a list of <code>{:file vcf-file :name name-to-use :prior probability}</code></p>
</td><td class="codes"><pre class="brush: clojure">(defn- variant-recalibration
  [in-vcf training-vcfs annotations ref]
  (let [base-out (itx/file-root in-vcf)
        file-info {:out-recal (str base-out &quot;.recal&quot;)
                   :out-tranch (str base-out &quot;.tranches&quot;)
                   :out-r (str base-out &quot;-recalplots.R&quot;)}
        args (concat [&quot;-R&quot; ref
                      &quot;-input&quot; in-vcf
                      &quot;-recalFile&quot; :out-recal
                      &quot;-tranchesFile&quot; :out-tranch
                      &quot;-rscriptFile&quot; :out-r
                      &quot;--percentBadVariants&quot; &quot;0.03&quot;
                      &quot;--maxGaussians&quot; &quot;10&quot;
                      &quot;--mode&quot; &quot;BOTH&quot;]
                     (flatten (map (fn [x] [&quot;-an&quot; x]) annotations))
                     (flatten (map (fn [x] [(str &quot;-resource:&quot; (:name x)
                                                 &quot;,known=true&quot;
                                                 &quot;,training=true&quot;
                                                 &quot;,truth=&quot; (:truth x)
                                                 &quot;,prior=&quot; (:prior x)
                                                 &quot;,bad=&quot; (:bad x))
                                            (:file x)])
                                   training-vcfs)))]
    (broad/run-gatk &quot;VariantRecalibrator&quot; args file-info {:out [:out-recal :out-tranch]})
    file-info))</pre></td></tr><tr><td class="docs"><p>Apply variant recalibration to input VCF.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- apply-recalibration
  [in-vcf recal-files ref]
  (let [file-info {:out-vcf (itx/add-file-part in-vcf &quot;recalfilter&quot;)}
        args [&quot;-R&quot; ref
              &quot;-input&quot; in-vcf
              &quot;--ts_filter_level&quot; &quot;99.0&quot;
              &quot;--mode&quot; &quot;BOTH&quot;
              &quot;-tranchesFile&quot; (:out-tranch recal-files)
              &quot;-recalFile&quot; (:out-recal recal-files)
              &quot;-o&quot; :out-vcf]]
    (broad/run-gatk &quot;ApplyRecalibration&quot; args file-info {:out [:out-vcf]})
    (:out-vcf file-info)))</pre></td></tr><tr><td class="docs"><p>Perform filtration using variant recalibration based on known variations.
  Training-vcfs is a list of true training sites along with associated
  probability and name.</p>
</td><td class="codes"><pre class="brush: clojure">(defn variant-recal-filter
  [in-vcf training-vcfs annotations ref]
  (let [recal-files (variant-recalibration in-vcf training-vcfs annotations ref)]
    (apply-recalibration in-vcf recal-files ref)))</pre></td></tr><tr><td class="docs"><p>Remove any filter information in the supplied file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn remove-cur-filters
  [in-vcf ref]
  (letfn [(remove-vc-filter [vc]
            [:out (-&gt; (VariantContextBuilder. (:vc vc))
                      (.passFilters)
                      (.make))])]
    (let [out-file (itx/add-file-part in-vcf &quot;nofilter&quot;)]
      (with-open [vcf-source (get-vcf-source in-vcf ref)]
        (write-vcf-w-template in-vcf {:out out-file}
                              (map remove-vc-filter (parse-vcf vcf-source))
                              ref))
      out-file)))</pre></td></tr><tr><td class="docs"><p>Retrieve training information for GATK recalibration:
   - No support specified: use the target comparison
   - Support specified and a specific comparison pair
   - Support specified as a single target: use target versus all comparison</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-train-info
  [cmps-by-name support config]
  (let [support-vcfs (if (coll? support)
                       (take 2 (-&gt; cmps-by-name (get support) :c-files vals))
                       (let [x (multiple-overlap-analysis cmps-by-name config support)]
                         [(:true-positives x) (:false-positives x)]))]
      [{:file (first support-vcfs)
        :name &quot;concordant&quot;
        :truth &quot;true&quot;
        :bad &quot;false&quot;
        :prior 10.0}
       {:file (second support-vcfs)
        :name &quot;discordant&quot;
        :truth &quot;false&quot;
        :bad &quot;true&quot;
        :prior 10.0}]))</pre></td></tr><tr><td class="docs"><p>Perform variant recalibration and filtration as part of processing pipeline.</p>
</td><td class="codes"><pre class="brush: clojure">(defn pipeline-recalibration
  [cmps-by-name finalizer exp config]
  (let [init-target (get cmps-by-name (:target finalizer))
        all-params (let [x (:params finalizer)] (if (map? x) [x] x))]
    (reduce (fn [target [params fkey]]
              (let [in-vcf (remove-cur-filters (-&gt; target fkey :file) (:ref exp))
                    hard-filters (:filters params)
                    anns (:annotations params)
                    train-info (get-train-info cmps-by-name
                                               (get params :support (:target finalizer))
                                               config)]
                (-&gt; target
                    (assoc-in [fkey :file] (-&gt; in-vcf
                                               (#(if-not anns %
                                                         (variant-recal-filter % train-info
                                                                               anns (:ref exp))))
                                               (#(if-not hard-filters %
                                                         (variant-filter % hard-filters
                                                                         (:ref exp))))))
                    (#(assoc-in % [fkey :name] (format &quot;%s-%s&quot; (get-in % [fkey :name]) &quot;recal&quot;)))
                    (assoc-in [fkey :mod] &quot;recal&quot;)
                    (assoc :re-compare true))))
            init-target (map vector all-params [:c1 :c2]))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.metrics" name="bcbio.variation.metrics"><h1 class="project-name">bcbio.variation.metrics</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Accumulate and analyze metrics associated with each variant.
   This provides summaries intended to identify characteristic
   metrics to use for filtering.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.metrics
  (:use [clojure.java.io]
        [clojure.set]
        [bcbio.variation.variantcontext :only [parse-vcf get-vcf-source]]
        [clojure.string :only [split-lines]]
        [clj-ml.data :only [make-dataset]]
        [clj-ml.classifiers :only [make-classifier classifier-train]]
        [ordered.set :only [ordered-set]])
  (:require [incanter.stats :as istats]
            [doric.core :as doric]))</pre></td></tr><tr><td class="docs"><h2>Convenience functions</h2>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- to-float [x]
  (if (number? x)
    x
    (try
      (Float/parseFloat x)
      (catch Exception e nil))))</pre></td></tr><tr><td class="docs"><p>Check if a VariantContext is not filtered.</p>
</td><td class="codes"><pre class="brush: clojure">(defn passes-filter?
  [vc]
  (= (count (:filters vc)) 0))</pre></td></tr><tr><td class="docs"><p>Check if a variant context is not filter and is not a reference call.</p>
</td><td class="codes"><pre class="brush: clojure">(defn nonref-passes-filter?
  [vc]
  (and (passes-filter? vc)
       (every? #(contains? #{&quot;HET&quot; &quot;HOM_VAR&quot;} (:type %)) (:genotypes vc))))</pre></td></tr><tr><td class="docs"><p>Retrieve numeric metrics associated with VariantContext.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-vc-metrics
  [vc]
  (reduce (fn [coll [k v]]
            (if-let [num-v (to-float v)]
              (assoc coll k num-v)
              coll))
   {}
   (assoc (:attributes vc) &quot;QUAL&quot; (-&gt; vc :genotypes first :qual))))</pre></td></tr><tr><td class="docs"><h2>Summary metrics</h2>

<p>Provide a summary-style presentation of distribution of metrics values.</p>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(def header [{:name :metric}
             {:name :count}
             {:name :min :format #(format &quot;%.2f&quot; %)}
             {:name :pct25 :format #(format &quot;%.2f&quot; %)}
             {:name :median :format #(format &quot;%.2f&quot; %)}
             {:name :pct75 :format #(format &quot;%.2f&quot; %)}
             {:name :max :format #(format &quot;%.2f&quot; %)}])</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn summary-stats [key vals]
  &quot;Provide summary statistics on a list of values.&quot;
  (zipmap (map :name header)
          (concat [key (count vals)]
                  (istats/quantile vals))))</pre></td></tr><tr><td class="docs"><p>Accumulate raw statistics associated with variant calls from input VCF.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- raw-vcf-stats
  [vcf-file ref-file]
  (letfn [(collect-attributes [collect [k v]]
            (if-not (nil? (to-float v))
              (assoc collect k (cons (to-float v) (get collect k [])))
              collect))
          (collect-vc [collect vc]
            (assoc (reduce collect-attributes collect (:attributes vc))
              &quot;QUAL&quot; (cons (-&gt; vc :genotypes first :qual)
                           (get collect &quot;QUAL&quot; []))))]
    (with-open [vcf-source (get-vcf-source vcf-file ref-file)]
      (reduce collect-vc {} (filter passes-filter? (parse-vcf vcf-source))))))</pre></td></tr><tr><td class="docs"><p>Collect summary statistics associated with variant calls.</p>
</td><td class="codes"><pre class="brush: clojure">(defn vcf-stats
  [vcf-file ref-file]
  (let [raw-stats (raw-vcf-stats vcf-file ref-file)]
    (map #(apply summary-stats %) (sort-by first raw-stats))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn write-summary-table [stats &amp; {:keys [wrtr]
                                    :or {wrtr (writer System/out)}}]
  (.write wrtr (str (doric/table header stats) &quot;\n&quot;)))</pre></td></tr><tr><td class="docs"><h2>Classify</h2>

<p>Provide metrics for files in preparation for automated
classification.</p>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Collect classification metrics from a single VCF file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-file-metrics
  [ref-file vcf-file]
  (letfn [(has-nil-names [metrics all-metrics all-names]
            (let [test-names (union (-&gt; metrics keys set) all-names)]
              (apply union
                     (map (fn [xs] (set (keep #(when (nil? (get xs %)) %) test-names)))
                          (cons metrics (take-last 10 all-metrics))))))
          (classifier-metrics [coll vc]
            (let [cur-metrics (get-vc-metrics vc)]
              (-&gt; coll
                  (assoc :rows (cons cur-metrics (:rows coll)))
                  (assoc :names (union (-&gt; cur-metrics keys set) (:names coll)))
                  (assoc :nil-names (union (has-nil-names cur-metrics (:rows coll) (:names coll))
                                           (:nil-names coll))))))
          (prep-table [{rows :rows names :names nil-names :nil-names}]
            (let [sort-names (sort (vec names))]
              {:cols sort-names
               :with-nil-cols nil-names
               :rows (map (fn [x]
                            (map #(get x %) sort-names))
                          rows)}))]
    (with-open [vcf-source (get-vcf-source vcf-file ref-file)]
      (prep-table
       (reduce classifier-metrics {:rows [] :names #{} :nil-names #{}}
               (filter passes-filter? (parse-vcf vcf-source)))))))</pre></td></tr><tr><td class="docs"><p>Collect metrics from multiple vcf files into tables suitable for
  classification algorithms.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-vcf-classifier-metrics
  [ref-file vcf-files &amp; {:keys [remove-nil-cols]
                         :or {remove-nil-cols true}}]
  (letfn [(get-shared-cols [xs]
            (-&gt; (apply intersection (map #(set (:cols %)) xs))
                sort
                vec))
          (filter-by-cols [orig-cols want-cols]
            (let [check-cols (set want-cols)
                  want (set (keep-indexed #(if (contains? check-cols %2) %1) orig-cols))]
              (fn [xs]
                (keep-indexed #(when (contains? want %1) %2) xs))))
          (subset-file-metrics [shared-cols nil-cols {cols :cols rows :rows}]
            (let [ready-cols (if-not remove-nil-cols shared-cols
                                     (remove #(contains? nil-cols %) shared-cols))
                  row-filter (filter-by-cols cols ready-cols)]
              {:cols ready-cols
               :rows (remove #(not= (count %) (count ready-cols)) (map row-filter rows))}))]
    (let [file-metrics (map (partial get-file-metrics ref-file) vcf-files)
          shared-cols (get-shared-cols file-metrics)
          nil-cols (apply union (map #(set (:with-nil-cols %)) file-metrics))]
      (map (partial subset-file-metrics shared-cols nil-cols) file-metrics))))</pre></td></tr><tr><td class="docs"><p>Retrieve classification metrics from a tree based classifier.
  Metric ordering is relative to the usefulness in classifying.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- parse-classifier-nodes
  [classifier metrics]
  (-&gt;&gt; classifier
       .graph
       split-lines
       (map #(re-find #&quot;label=\&quot;(\w+)\&quot;&quot; %))
       (map second)
       flatten
       (remove nil?)
       (filter #(contains? (set metrics) %))
       (apply ordered-set)))</pre></td></tr><tr><td class="docs"><p>Classify VCF files with INFO metrics using a decision tree classifier.</p>
</td><td class="codes"><pre class="brush: clojure">(defn classify-decision-tree
  [metrics]
  (letfn [(prep-one-dataset [rows i]
            (map #(conj (vec %) (str i)) rows))
          (prep-dataset [metrics]
            (make-dataset &quot;ds&quot; (conj (-&gt; metrics first :cols vec)
                                     {:c (map str (range (count metrics)))})
                          (apply concat (map-indexed #(prep-one-dataset (:rows %2) %1) metrics))
                          {:class :c}))]
    (let [ds (prep-dataset metrics)
          c (-&gt; (make-classifier :decision-tree :c45)
                (classifier-train ds))]
      (vec (parse-classifier-nodes c (-&gt; metrics first :cols))))))</pre></td></tr><tr><td class="docs"><p>Merge multiple classification approaches into a set of final metrics.
  <code>in-metrics</code> contains ordered best metric classifiers from the different
  approaches. Returns interleaved metrics ranked by present in these
  classifiers. </p>
</td><td class="codes"><pre class="brush: clojure">(defn merge-classified-metrics
  [in-metrics]
  (loop [cur in-metrics
         final (ordered-set)]
    (if (every? empty? cur)
      {:top-metrics (vec final)}
      (recur (map rest cur)
             (reduce #(conj %1 %2) final (remove nil? (map first cur)))))))</pre></td></tr><tr><td class="docs"><p>Apply machine learning/classification approaches to distinguish useful
  metrics distinguishing VCF files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn ml-on-vcf-metrics
  [ref-file vcf-files]
  (letfn [(run-classifier [remove-nil-cols]
            (-&gt; (get-vcf-classifier-metrics ref-file vcf-files :remove-nil-cols remove-nil-cols)
                classify-decision-tree))]
    (merge-classified-metrics (map run-classifier [true false]))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.multiple" name="bcbio.variation.multiple"><h1 class="project-name">bcbio.variation.multiple</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Handle useful comparisons from multiple variation calling approaches.
  High level API to consolidate pairwise variant comparisons.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.multiple
  (:use [ordered.map :only [ordered-map]]
        [bcbio.variation.annotation :only [add-variant-annotations]]
        [bcbio.variation.combine :only [combine-variants]]
        [bcbio.variation.metrics :only [nonref-passes-filter?]]
        [bcbio.variation.variantcontext :only [parse-vcf get-vcf-retriever
                                               get-vcf-source write-vcf-w-template]])
  (:require [clojure.string :as string]
            [fs.core :as fs]
            [bcbio.run.itx :as itx]
            [bcbio.run.broad :as broad]))</pre></td></tr><tr><td class="docs"><h2>Utility functions</h2>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- remove-mod-name [x &amp; {:keys [mods] :or {mods [&quot;recal&quot;]}}]
  &quot;Removes modification names from an approach name.&quot;
  (reduce (fn [final mod]
            (string/replace final (str &quot;-&quot; mod) ))
          x mods))</pre></td></tr><tr><td class="docs"><p>Lookup map of comparisons by method names.
   - ignore: a list of method names to ignore when creating the lookup map.
   - remove-mods?: Flag to remove naming modifications. This
                   will replace original comparisons with recalibrated.</p>
</td><td class="codes"><pre class="brush: clojure">(defn prep-cmp-name-lookup
  [cmps &amp; {:keys [ignore remove-mods?] :or {ignore #{}}}]
  (reduce (fn [m x]
            (let [cmps [:c1 :c2]
                  names (map #(let [n (get-in x [% :name])]
                                (if-not remove-mods? n
                                        (remove-mod-name n :mods [(get-in x [% :mod])])))
                             cmps)]
              (if (some #(contains? ignore %) names) m
                  (assoc m names x))))
          (ordered-map)
          cmps))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- not-target? [target-name xs]
  (not (contains? (set (map remove-mod-name xs)) target-name)))</pre></td></tr><tr><td class="docs"><h2>Prepare multi-overlap sets</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Select samples based on name of a 'set' from CombineVariants.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- select-variant-by-set
  [vcf-in ref set-name &amp; {:keys [out-dir]}]
  (let [file-info {:out-vcf (itx/add-file-part vcf-in set-name out-dir)}
        args [&quot;-R&quot; ref
              &quot;-o&quot; :out-vcf
              &quot;--variant&quot; vcf-in
              &quot;-select&quot; (format &quot;set == '%s'&quot; set-name)]]
    (broad/run-gatk &quot;SelectVariants&quot; args file-info {:out [:out-vcf]})
    (:out-vcf file-info)))</pre></td></tr><tr><td class="docs"><p>Create VCF of the intersection of all concordant calls.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- gen-all-concordant
  [cmps-by-name out-dir config &amp; {:keys [do-include? base-ext]
                                  :or {base-ext &quot;multiall&quot;}}]
  (let [concordant-map (reduce (fn [m [k v]]
                                 (if (or (nil? do-include?) (do-include? k))
                                   (assoc m (-&gt; v :c-files (get &quot;concordant&quot;)) (string/join &quot;-&quot; k))
                                   m))
                               (ordered-map) cmps-by-name)
        ref (-&gt; cmps-by-name vals first :exp :ref)
        union-vcf (combine-variants (keys concordant-map) ref :merge-type :full :out-dir out-dir
                                    :name-map concordant-map :base-ext base-ext)]
    {:union union-vcf
     :intersection (select-variant-by-set union-vcf ref &quot;Intersection&quot;)}))</pre></td></tr><tr><td class="docs"><p>Generate false positives: discordant calls also called in other samples.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- gen-target-fps
  [target-cmps target-name other-conc-vcf ref out-dir]
  (letfn [(check-shared [fetch]
            (fn [x]
              (and (not (empty? (fetch (:chr x) (:start x) (:end x))))
                   (nonref-passes-filter? x))))
          (get-shared-discordant [xs fetch]
            (let [pass-and-shared? (check-shared fetch)]
              (map :vc (filter pass-and-shared? xs))))]
    (let [disc-vcfs (remove nil? (map (fn [v]
                                        (get (:c-files v) (format &quot;%s-discordant&quot; target-name)))
                                      (vals target-cmps)))
          disc-vcf (-&gt; (combine-variants disc-vcfs ref :merge-type :full :out-dir out-dir
                                         :base-ext (format &quot;dis%s&quot; target-name))
                       (select-variant-by-set ref &quot;Intersection&quot;))
          out-file (itx/add-file-part disc-vcf &quot;shared&quot;)]
      (with-open [disc-source (get-vcf-source disc-vcf ref)
                  other-source (get-vcf-source other-conc-vcf ref)]
        (let [vrn-fetch (get-vcf-retriever other-source)]
          (write-vcf-w-template disc-vcf {:out out-file}
                                (get-shared-discordant (parse-vcf disc-source) vrn-fetch)
                                ref)))
      out-file)))</pre></td></tr><tr><td class="docs"><p>Create files of false negatives and positives from target-name.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- gen-target-problems
  [target-name target-call cmps-by-name true-p-vcf ref out-dir config]
  (let [notarget-concordant (gen-all-concordant cmps-by-name out-dir config
                                                :do-include? (partial not-target? target-name)
                                                :base-ext (format &quot;multino%s&quot; target-name))]
    {:false-negatives
     (-&gt; (combine-variants [true-p-vcf (:intersection notarget-concordant)]
                           ref :merge-type :full :out-dir out-dir
                           :name-map {true-p-vcf &quot;truep&quot;
                                      (:intersection notarget-concordant) target-name}
                           :base-ext (format &quot;multiall-no%s&quot; target-name))
         (select-variant-by-set ref target-name)
         (add-variant-annotations (:align target-call) ref target-call :out-dir out-dir))
     :false-positives (gen-target-fps (remove #(not-target? target-name (first %))
                                              cmps-by-name)
                                      target-name (:union notarget-concordant)
                                      ref out-dir)}))</pre></td></tr><tr><td class="docs"><p>Provide high level concordance overlap comparisons for multiple call approaches.
  Organizes relative to the given target name generating:
   - VCF of calls concordant in all methods: intersection of all concordant calls.
     These are true positives.
   - VCF of calls discordant in the target method, but concordant in the remainder:
     the intersection of all concordant pairs not including target-name minus the
     overall intersection of concordants. These are false negatives.
   - VCF of non-ref calls discordant in the target method and called in any of the other
     methods. We restrict to shared calls to avoid penalizing unique calls.
     These are false positives.</p>
</td><td class="codes"><pre class="brush: clojure">(defn multiple-overlap-analysis
  [cmps config target-name &amp; {:keys [dirname] :or {dirname &quot;multiple&quot;}}]
  (let [cmps-by-name (if (map? cmps) cmps
                         (prep-cmp-name-lookup cmps :ignore #{&quot;all&quot; &quot;validate&quot;}))
        out-dir (str (fs/file (get-in config [:dir :prep] (get-in config [:dir :out]))
                              dirname))
        ref (-&gt; cmps-by-name vals first :exp :ref)
        target-call (-&gt;&gt; cmps-by-name
                         (remove #(not-target? target-name (first %)))
                         first
                         second
                         ((juxt :c1 :c2))
                         (filter #(= (remove-mod-name (:name %)) target-name))
                         first)]
    (when-not (fs/exists? out-dir)
      (fs/mkdirs out-dir))
    (let [true-p-vcf (-&gt; (gen-all-concordant cmps-by-name out-dir config)
                         :intersection
                         (add-variant-annotations (:align target-call) ref target-call
                                                  :out-dir out-dir))
          target-problems (gen-target-problems target-name target-call cmps-by-name
                                               true-p-vcf ref out-dir config)]
      (ordered-map :true-positives true-p-vcf
                   :false-negatives (:false-negatives target-problems)
                   :false-positives (:false-positives target-problems)))))</pre></td></tr><tr><td class="docs"><p>Perform high level pipeline comparison of a target with multiple experiments.</p>
</td><td class="codes"><pre class="brush: clojure">(defn pipeline-compare-multiple
  [cmps finalizer exp config]
  (let [analysis (multiple-overlap-analysis cmps config (:target finalizer))]
    {:c-files analysis
     :c1 {:name (:target finalizer)}
     :c2 {:name &quot;all&quot;}
     :exp exp :dir (config :dir)}))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.normalize" name="bcbio.variation.normalize"><h1 class="project-name">bcbio.variation.normalize</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Prepare a VCF file for comparison by normalizing chromosome names,
  sort order, sample name, and genotype representation.
  This handles the work of making slightly different representations
  match, enabling VCF comparisons.
  Currently implemented for human only, with hooks to generalize for other
  organisms.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.normalize
  (:import [org.broadinstitute.sting.utils.variantcontext VariantContextBuilder Genotype]
           [org.broadinstitute.sting.utils.codecs.vcf VCFHeader]
           [org.broad.tribble.readers AsciiLineReader])
  (:use [clojure.java.io]
        [bcbio.variation.variantcontext :only [write-vcf-w-template
                                               get-vcf-source
                                               get-vcf-retriever
                                               get-vcf-line-parser]]
        [bcbio.align.ref :only [get-seq-dict]]
        [bcbio.variation.structural :only [nochange-alt?]]
        [ordered.map :only (ordered-map)]
        [ordered.set :only (ordered-set)])
  (:require [clojure.string :as string]
            [bcbio.run.itx :as itx]
            [fs.core :as fs]))</pre></td></tr><tr><td class="docs"><h2>Chromosome name remapping</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Provide mapping from variant chromosome names to reference
keyed on the organism name. Currently only a human GRCh37 remap.</p>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmulti chr-name-remap (fn [type &amp; args] type))</pre></td></tr><tr><td class="docs"><p>Function to retrieve hg19 information. Requires korma and
  mysql connector.</p>
</td><td class="codes"><pre class="brush: clojure">(comment
(defn- get-hg19-map
  []
  (defdb db (mysql {:db &quot;hg19&quot;
                    :user &quot;genome&quot;
                    :host &quot;genome-mysql.cse.ucsc.edu&quot;}))
  (defentity ucscToEnsembl)
  (-&gt;&gt; (select ucscToEnsembl)
       (map (juxt :ucsc :ensembl))
       (into {}))))</pre></td></tr><tr><td class="docs"><p>Cached version of hg19 map to avoid having to make database connections</p>
</td><td class="codes"><pre class="brush: clojure">(def hg19-map
  {&quot;chrM&quot; &quot;MT&quot;, &quot;chrUn_gl000211&quot; &quot;GL000211&quot;, &quot;chrUn_gl000222&quot; &quot;GL000222&quot;,
   &quot;chrUn_gl000233&quot; &quot;GL000233&quot;, &quot;chrUn_gl000244&quot; &quot;GL000244&quot;, &quot;chrUn_gl000212&quot; &quot;GL000212&quot;,
   &quot;chrUn_gl000223&quot; &quot;GL000223&quot;, &quot;chrUn_gl000234&quot; &quot;GL000234&quot;, &quot;chrUn_gl000245&quot; &quot;GL000245&quot;,
   &quot;chrUn_gl000213&quot; &quot;GL000213&quot;, &quot;chrUn_gl000224&quot; &quot;GL000224&quot;, &quot;chrUn_gl000235&quot; &quot;GL000235&quot;,
   &quot;chrUn_gl000246&quot; &quot;GL000246&quot;, &quot;chr6_mcf_hap5&quot; &quot;HSCHR6_MHC_MCF&quot;, &quot;chrUn_gl000214&quot; &quot;GL000214&quot;,
   &quot;chrUn_gl000225&quot; &quot;GL000225&quot;, &quot;chrUn_gl000236&quot; &quot;GL000236&quot;, &quot;chrUn_gl000247&quot; &quot;GL000247&quot;,
   &quot;chr1&quot; &quot;1&quot;, &quot;chr6_cox_hap2&quot; &quot;HSCHR6_MHC_COX&quot;, &quot;chrUn_gl000215&quot; &quot;GL000215&quot;,
   &quot;chrUn_gl000226&quot; &quot;GL000226&quot;, &quot;chrUn_gl000237&quot; &quot;GL000237&quot;, &quot;chrUn_gl000248&quot; &quot;GL000248&quot;,
   &quot;chr2&quot; &quot;2&quot;, &quot;chrUn_gl000216&quot; &quot;GL000216&quot;, &quot;chrUn_gl000227&quot; &quot;GL000227&quot;,
   &quot;chrUn_gl000238&quot; &quot;GL000238&quot;, &quot;chrUn_gl000249&quot; &quot;GL000249&quot;, &quot;chr3&quot; &quot;3&quot;,
   &quot;chrUn_gl000217&quot; &quot;GL000217&quot;, &quot;chrUn_gl000228&quot; &quot;GL000228&quot;, &quot;chrUn_gl000239&quot; &quot;GL000239&quot;,
   &quot;chr9_gl000201_random&quot; &quot;GL000201&quot;, &quot;chr4&quot; &quot;4&quot;, &quot;chr11_gl000202_random&quot; &quot;GL000202&quot;,
   &quot;chrUn_gl000218&quot; &quot;GL000218&quot;, &quot;chrUn_gl000229&quot; &quot;GL000229&quot;, &quot;chr9_gl000200_random&quot; &quot;GL000200&quot;,
   &quot;chr19_gl000209_random&quot; &quot;GL000209&quot;, &quot;chr5&quot; &quot;5&quot;, &quot;chrUn_gl000219&quot; &quot;GL000219&quot;,
   &quot;chr1_gl000192_random&quot; &quot;GL000192&quot;, &quot;chr18_gl000207_random&quot; &quot;GL000207&quot;, &quot;chr6&quot; &quot;6&quot;,
   &quot;chr21_gl000210_random&quot; &quot;GL000210&quot;, &quot;chr17_gl000206_random&quot; &quot;GL000206&quot;,
   &quot;chr9_gl000199_random&quot; &quot;GL000199&quot;, &quot;chr1_gl000191_random&quot; &quot;GL000191&quot;,
   &quot;chr4_gl000194_random&quot; &quot;GL000194&quot;, &quot;chr19_gl000208_random&quot; &quot;GL000208&quot;,
   &quot;chr17_gl000205_random&quot; &quot;GL000205&quot;, &quot;chr7&quot; &quot;7&quot;, &quot;chr9_gl000198_random&quot; &quot;GL000198&quot;,
   &quot;chr8_gl000197_random&quot; &quot;GL000197&quot;, &quot;chr4_gl000193_random&quot; &quot;GL000193&quot;,
   &quot;chr17_gl000204_random&quot; &quot;GL000204&quot;, &quot;chr8&quot; &quot;8&quot;, &quot;chrX&quot; &quot;X&quot;, &quot;chr8_gl000196_random&quot; &quot;GL000196&quot;,
   &quot;chr7_gl000195_random&quot; &quot;GL000195&quot;, &quot;chr20&quot; &quot;20&quot;, &quot;chr9&quot; &quot;9&quot;, &quot;chrY&quot; &quot;Y&quot;,
   &quot;chr17_gl000203_random&quot; &quot;GL000203&quot;, &quot;chr10&quot; &quot;10&quot;, &quot;chr21&quot; &quot;21&quot;, &quot;chr6_dbb_hap3&quot; &quot;HSCHR6_MHC_DBB&quot;,
   &quot;chr11&quot; &quot;11&quot;, &quot;chr22&quot; &quot;22&quot;, &quot;chr6_ssto_hap7&quot; &quot;HSCHR6_MHC_SSTO&quot;, &quot;chr17_ctg5_hap1&quot; &quot;HSCHR17_1&quot;,
   &quot;chr12&quot; &quot;12&quot;, &quot;chr13&quot; &quot;13&quot;, &quot;chr14&quot; &quot;14&quot;, &quot;chr15&quot; &quot;15&quot;, &quot;chr16&quot; &quot;16&quot;,
   &quot;chr6_mann_hap4&quot; &quot;HSCHR6_MHC_MANN&quot;, &quot;chr17&quot; &quot;17&quot;, &quot;chr18&quot; &quot;18&quot;, &quot;chr19&quot; &quot;19&quot;,
   &quot;chr6_qbl_hap6&quot; &quot;HSCHR6_MHC_QBL&quot;, &quot;chr6_apd_hap1&quot; &quot;HSCHR6_MHC_APD&quot;,
   &quot;chrUn_gl000240&quot; &quot;GL000240&quot;, &quot;chrUn_gl000230&quot; &quot;GL000230&quot;, &quot;chrUn_gl000241&quot; &quot;GL000241&quot;,
   &quot;chr4_ctg9_hap1&quot; &quot;HSCHR4_1&quot;, &quot;chrUn_gl000220&quot; &quot;GL000220&quot;, &quot;chrUn_gl000231&quot; &quot;GL000231&quot;,
   &quot;chrUn_gl000242&quot; &quot;GL000242&quot;, &quot;chrUn_gl000221&quot; &quot;GL000221&quot;, &quot;chrUn_gl000232&quot; &quot;GL000232&quot;,
   &quot;chrUn_gl000243&quot; &quot;GL000243&quot;})</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod chr-name-remap :GRCh37
  [_ ref-chrs vcf-chrs]
  (letfn [(maybe-remap-name [x]
            {:post [(contains? ref-chrs %)]}
            (if (contains? ref-chrs x)
              x
              (get hg19-map x)))]
    (zipmap vcf-chrs
            (map maybe-remap-name vcf-chrs))))</pre></td></tr><tr><td class="docs"><h2>Resort and normalize variants</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Build a new variant context with updated sample name and normalized alleles.
  Based on :allele-count in the configuration updates haploid allele calls. This
  normalizes the representation in Mitochondrial and Y chromosomes which are
  haploid but are often represented as diploid with a single call.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- fix-vc
  [sample config orig]
  (letfn [(update-genotype-sample [vc]
            (if (= 1 (count (.getGenotypes vc)))
              (let [g (first (.getGenotypes vc))]
                [(Genotype/modifyName g sample)])
              (.getGenotypes vc)))
          (normalize-allele-calls [g]
            {:pre [(contains? #{1 (:allele-count config)} (count (.getAlleles g)))]}
            (if (= (count (.getAlleles g)) (:allele-count config)) g
                (Genotype/modifyAlleles g (repeat (:allele-count config)
                                                  (first (.getAlleles g))))))]
    (-&gt; orig
        (assoc :vc
          (-&gt; (VariantContextBuilder. (:vc orig))
              (.genotypes (map normalize-allele-calls (update-genotype-sample (:vc orig))))
              .make)))))</pre></td></tr><tr><td class="docs"><p>Check if a variant has a non-informative no-call genotype.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- no-call-genotype?
  [vc]
  (if-not (= 1 (count (:genotypes vc))) false
          (contains? #{&quot;NO_CALL&quot; &quot;MIXED&quot; &quot;HOM_REF&quot;}
                     (-&gt; vc :genotypes first :type))))</pre></td></tr><tr><td class="docs"><p>Sort stream of line inputs by position.
  Requires loading the entire file into memory during the sort-by phase
  so will not work on massive files. Should be feasible with files
  split by chromosome.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- sort-by-position
  [line-seq]
  (letfn [(add-position [line]
            (let [[chrom start] (take 2 (string/split line #&quot;\t&quot;))]
              [[chrom (Integer/parseInt start)] line]))]
    (-&gt;&gt; line-seq
         (map add-position)
         (sort-by first)
         (map second))))</pre></td></tr><tr><td class="docs"><p>Provide VariantContexts ordered by chromosome and normalized.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- ordered-vc-iter
  [rdr vcf-decoder sample config]
  (-&gt;&gt; rdr
       line-seq
       (#(if (:sort-pos config) (sort-by-position %) %))
       (remove nochange-alt?)
       (map vcf-decoder)
       (remove no-call-genotype?)
       (map (partial fix-vc sample config))
       (map :vc)))</pre></td></tr><tr><td class="docs"><p>Provide fixes to VCF input lines that do not require VariantContext parsing.
  Fixes:
    - INFO lines with empty attributes (starting with ';'), found in
      Complete Genomics VCF files
    - Chromosome renaming.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- fix-vcf-line
  [line ref-info config]
  (letfn [(empty-attribute-info [info]
            (if (.startsWith info &quot;;&quot;)
              (subs info 1)
              info))
          (fix-info [xs]
            (assoc xs 7 (-&gt; (nth xs 7)
                            empty-attribute-info)))
          (fix-chrom [new xs]
            (assoc xs 0 new))]
    (let [parts (string/split line #&quot;\t&quot;)
          cur-chrom (first (vals
                            (chr-name-remap (:org config) ref-info [(first parts)])))]
      {:chrom cur-chrom
       :line (-&gt;&gt; parts
                  (fix-chrom cur-chrom)
                  fix-info
                  (string/join &quot;\t&quot;))})))</pre></td></tr><tr><td class="docs"><p>Split input VCF into separate files by chromosome, returning a map of file names.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- vcf-by-chrom
  [vcf-file ref-file tmp-dir config]
  (letfn [(ref-chr-files [ref-file]
            (into (ordered-map)
                  (map (fn [x] [(.getSequenceName x)
                                (str (fs/file tmp-dir (str &quot;prep&quot; (.getSequenceName x) &quot;.vcf&quot;)))])
                       (-&gt; ref-file get-seq-dict .getSequences))))
          (write-by-chrom [ref-wrtrs line]
            (let [line-info (fix-vcf-line line ref-wrtrs config)]
              (.write (get ref-wrtrs (:chrom line-info))
                      (str (:line line-info) &quot;\n&quot;))))]
    (let [ref-chrs (ref-chr-files ref-file)
          ref-wrtrs (zipmap (keys ref-chrs) (map writer (vals ref-chrs)))]
      (with-open [rdr (reader vcf-file)]
        (itx/with-open-map ref-wrtrs
          (-&gt;&gt; rdr
               line-seq
               (drop-while #(.startsWith % &quot;#&quot;))
               (map (partial write-by-chrom ref-wrtrs))
               doall))
        ref-chrs))))</pre></td></tr><tr><td class="docs"><h2>Top level functionality to manage inputs and writing.</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Update header information, removing contig and adding sample names.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- update-header
  [sample]
  (fn [header]
    (case (count (.getGenotypeSamples header))
     1 (VCFHeader. (apply ordered-set (remove #(= &quot;contig&quot; (.getKey %)) (.getMetaData header)))
                   (ordered-set sample))
     0 (VCFHeader. (apply ordered-set (remove #(= &quot;contig&quot; (.getKey %)) (.getMetaData header))) #{})
     header)))</pre></td></tr><tr><td class="docs"><p>Write VCF file with correctly ordered and cleaned variants.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- write-prepped-vcf
  [vcf-file out-info ref-file sample config]
  (itx/with-temp-dir [tmp-dir (fs/parent (:out out-info))]
    (let [reader-by-chr (into (ordered-map) (map (fn [[k v]] [k (reader v)])
                                                 (vcf-by-chrom vcf-file ref-file tmp-dir config)))]
      (itx/with-open-map reader-by-chr
        (with-open [vcf-reader (AsciiLineReader. (input-stream vcf-file))]
          (let [vcf-decoder (get-vcf-line-parser vcf-reader)]
            (write-vcf-w-template vcf-file out-info
                                  (flatten
                                   (for [rdr (vals reader-by-chr)]
                                     (ordered-vc-iter rdr vcf-decoder sample config)))
                                  ref-file
                                  :header-update-fn (update-header sample))))))))</pre></td></tr><tr><td class="docs"><p>Prepare VCF for comparison by normalizing high level attributes
  Assumes by position sorting of variants in the input VCF. Chromosomes do
  not require a specific order, but positions internal to a chromosome do.
  Currently configured for human preparation.</p>
</td><td class="codes"><pre class="brush: clojure">(defn prep-vcf
  [in-vcf-file ref-file sample &amp; {:keys [out-dir out-fname sort-pos]
                                  :or {sort-pos false}}]
  (let [config {:org :GRCh37 :allele-count 2 :sort-pos sort-pos}
        base-name (if (nil? out-fname) (itx/remove-zip-ext in-vcf-file) out-fname)
        out-file (itx/add-file-part base-name &quot;prep&quot; out-dir)]
    (when (itx/needs-run? out-file)
      (write-prepped-vcf in-vcf-file {:out out-file} ref-file sample config))
    out-file))</pre></td></tr><tr><td class="docs"><h2>Remove problem characters</h2>

<p>Handle cleanup for VCF files before feeding to any verifying parser.</p>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Clean VCF file which GATK parsers cannot handle due to illegal characters.
  Fixes:
    - Gap characters (-) found in REF or ALT indels.
    - Filter out call with extra N padding on 5' side of indels.</p>
</td><td class="codes"><pre class="brush: clojure">(defn clean-problem-vcf
  [in-vcf-file &amp; {:keys [out-dir]}]
  (letfn [(remove-gap [n xs]
            (assoc xs n
                   (string/replace (nth xs n) &quot;-&quot; &quot;&quot;)))
          (is-5pad-n? [xs]
            (let [ref (nth xs 3)
                  alt (nth xs 4)]
              (and (= ref &quot;N&quot;) (.startsWith alt &quot;N&quot;) (&gt; (count alt) 1))))
          (remove-5pad-n [xs]
            (if (is-5pad-n? xs) [] xs))
          (clean-line [line]
            (if (.startsWith line &quot;#&quot;) line
                (-&gt;&gt; (string/split line #&quot;\t&quot;)
                     (remove-gap 3)
                     (remove-gap 4)
                     (remove-5pad-n)
                     (string/join &quot;\t&quot;))))]
    (let [out-file (itx/add-file-part in-vcf-file &quot;preclean&quot; out-dir)]
      (when (itx/needs-run? out-file)
        (with-open [rdr (reader in-vcf-file)
                    wtr (writer out-file)]
          (doall
           (map #(.write wtr (str % &quot;\n&quot;))
                (remove empty? (map clean-line (line-seq rdr)))))))
      out-file)))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.phasing" name="bcbio.variation.phasing"><h1 class="project-name">bcbio.variation.phasing</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Support phased haplotype comparisons between variant calls.
   Compares a phased set of calls versus haploid reference calls.</p>

<p>   The comparison logic is:</p>

<ul>
<li>Group calls into regions based on phasing</li>
<li>For each phase region:
<ul><li>Determine which set of haploid alleles to compare with the reference</li>
<li>With each position in this haploid:
<ul><li>Compare to reference allele</li>
<li>If mismatch and alternate allele matches reference, then phasing error</li>
<li>If mismatch and neither allele matches, then calling error</li></ul></li></ul></li>
</ul>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.phasing
  (:import [org.broadinstitute.sting.utils.interval IntervalUtils IntervalSetRule]
           [org.broadinstitute.sting.utils GenomeLocParser GenomeLoc])
  (:use [bcbio.variation.variantcontext :only [parse-vcf get-vcf-retriever get-vcf-source
                                               write-vcf-w-template]]
        [bcbio.align.ref :only [get-seq-dict]]
        [bcbio.variation.callable :only [get-bed-source]]
        [ordered.map :only [ordered-map]])
  (:require [fs.core :as fs]))</pre></td></tr><tr><td class="docs"><h2>Find phased haplotypes in VCF</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Check for phasing on a single genotype variant context.</p>
</td><td class="codes"><pre class="brush: clojure">(defn is-phased?
  [vc]
  {:pre [(= 1 (count (:genotypes vc)))]}
  (-&gt; vc :genotypes first :genotype .isPhased))</pre></td></tr><tr><td class="docs"><p>Separate phased haplotypes provided in diploid input genome.
   3 conditions:</p>

<ol>
<li>Out of variants; add the current one to the list and done</li>
<li>No current haplotype variants or phased with the previous variant:
  add to the current haplotype</li>
<li>A new haplotype: add existing haplotype to list and create new</li>
</ol>
</td><td class="codes"><pre class="brush: clojure">(defn parse-phased-haplotypes
  [vcf-source]
  (lazy-seq
   (loop [vcs (parse-vcf vcf-source)
          cur-hap []
          all-haps []]
     (cond
      (nil? (first vcs)) (if (empty? cur-hap) all-haps (conj all-haps cur-hap))
      (or (empty? cur-hap)
          (is-phased? (first vcs))) (recur (rest vcs) (conj cur-hap (first vcs)) all-haps)
          :else (recur (rest vcs) [(first vcs)] (conj all-haps cur-hap))))))</pre></td></tr><tr><td class="docs"><h2>Compare phased variants</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Retrieve the item with the highest count in the supplied list.
  We break ties by sorting by the actual list items</p>
</td><td class="codes"><pre class="brush: clojure">(defn highest-count
  [xs]
  (-&gt;&gt; (frequencies xs)
       (sort-by val &gt;)
       (partition-by second)
       first
       (sort-by first)
       ffirst))</pre></td></tr><tr><td class="docs"><p>Convenience function to get alleles for a single genotype variant context.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-alleles
  [vc]
  {:pre [(= 1 (count (:genotypes vc)))]}
  (-&gt; vc :genotypes first :alleles))</pre></td></tr><tr><td class="docs"><p>Determine allele index where the variant context matches haploid reference.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- matching-allele
  [vc ref-vcs]
  {:pre [(every? #(= 1 (count (-&gt; % :genotypes first :alleles))) ref-vcs)
         (= 1 (count (:genotypes vc)))]}
  (if (empty? ref-vcs)
    (.indexOf (get-alleles vc) (:ref-allele vc))
    (highest-count
     (map #(.indexOf (get-alleles vc) (-&gt; % get-alleles first)) ref-vcs))))</pre></td></tr><tr><td class="docs"><p>Compare the haploid allele of a variant against the reference call.</p>
</td><td class="codes"><pre class="brush: clojure">(defn cmp-allele-to-ref
  [vc ref-vcs i]
  {:pre [(= 2 (count (get-alleles vc)))]}
  (letfn [(is-ref-allele? [x]
            (= (.getBaseString x) (-&gt; vc :ref-allele .getBaseString)))]
    (let [ref-alleles (set (map #(-&gt; % get-alleles first) ref-vcs))
          call-hap (nth (get-alleles vc) i)]
      (cond
       (and (empty? ref-alleles) (is-ref-allele? call-hap)) :ref-concordant
       (empty? ref-alleles) :discordant
       (contains? ref-alleles call-hap) :concordant
       (some (partial contains? ref-alleles) (get-alleles vc)) :phasing-error
       :else :discordant))))</pre></td></tr><tr><td class="docs"><p>Retrieve the type of a set of variants involved in a comparison.</p>

<ul>
<li><code>:indel</code> -- insertions or deletions of more than 1bp</li>
<li><code>:snp</code> -- Single nucleotide changes or single basepair changes</li>
<li><code>:unknown</code> -- Other classs of variations (structural)</li>
</ul>
</td><td class="codes"><pre class="brush: clojure">(defn get-variant-type
  [vcs]
  (letfn [(is-indel? [x]
            (= &quot;INDEL&quot; (:type x)))
          (is-multi-indel? [x]
            (and (is-indel? x)
                 (not-every? #(contains? #{0 1} %)
                             (map #(-&gt; % .getBaseString count) (get-alleles x)))))
          (is-snp? [x]
            (= &quot;SNP&quot; (:type x)))]
    (cond
     (some is-multi-indel? vcs) :indel
     (some is-indel? vcs) :snp
     (every? is-snp? vcs) :snp
     :else :unknown)))</pre></td></tr><tr><td class="docs"><p>Determine if the variant has a non-matching heterozygous alternative allele.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- nomatch-het-alt?
  [vc ref-vcs]
  (let [match-allele-i (matching-allele vc ref-vcs)
        no-match-alleles (remove nil? (map-indexed
                                       (fn [i x] (if-not (= i match-allele-i) x))
                                       (get-alleles vc)))]
    (and (= &quot;HET&quot; (-&gt; vc :genotypes first :type))
         (not-every? #(.isReference %) no-match-alleles))))</pre></td></tr><tr><td class="docs"><p>Provide metrics for comparison of haploid allele to reference calls.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- comparison-metrics
  [vc ref-vcs i]
  {:comparison (cmp-allele-to-ref vc ref-vcs i)
   :variant-type (get-variant-type (cons vc ref-vcs))
   :nomatch-het-alt (nomatch-het-alt? vc ref-vcs)
   :vc (:vc vc)})</pre></td></tr><tr><td class="docs"><p>Provide scoring metrics for a phased region against a haplotype reference.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- score-phased-region
  [vcs ref-fetch]
  (letfn [(ref-alleles [x]
            (ref-fetch (:chr x) (:start x) (:end x)))
          (ref-match-allele [x]
            (matching-allele x (ref-alleles x)))]
    (let [cmp-allele-i (highest-count (map ref-match-allele vcs))]
      (map #(comparison-metrics % (ref-alleles %) cmp-allele-i) vcs))))</pre></td></tr><tr><td class="docs"><p>Score a called VCF against reference based on phased regions.</p>
</td><td class="codes"><pre class="brush: clojure">(defn score-phased-calls
  [call-vcf-s ref-vcf-s]
  (let [ref-fetch (get-vcf-retriever ref-vcf-s)]
    (map #(score-phased-region % ref-fetch)
         (parse-phased-haplotypes call-vcf-s))))</pre></td></tr><tr><td class="docs"><h2>Summarize phased comparisons</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Write concordant and discordant variants to VCF output files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- write-concordance-output
  [vc-info sample-name base-info out-dir ref]
  (let [base-dir (if (nil? out-dir) (fs/parent (:file base-info)) out-dir)
        gen-file-name (fn [x] (str (fs/file base-dir (format &quot;%s-%s-%s.vcf&quot; sample-name
                                                             (:name base-info) (name x)))))
        out-files (apply ordered-map (flatten (map (juxt identity gen-file-name)
                                                   [:concordant :discordant :phasing-error])))]
    (if-not (fs/exists? base-dir)
      (fs/mkdirs base-dir))
    (write-vcf-w-template (:file base-info) out-files
                          (map (juxt :comparison :vc)
                               (remove #(= :ref-concordant (:comparison %)) (flatten vc-info)))
                          ref)
    out-files))</pre></td></tr><tr><td class="docs"><p>Provide counts for comparison: entire region plus user specified regions</p>
</td><td class="codes"><pre class="brush: clojure">(defn count-comparison-bases
  [total-bed call-bed ref-file]
  (letfn [(feature-size [x]
            (cond
             (instance? GenomeLoc x) (- (.getStop x) (.getStart x))
             :else (- (.getEnd x) (.getStart x))))
          (count-bases [xs]
            (apply + (map feature-size xs)))
          (genome-loc-list [x]
            (let [parser (GenomeLocParser. (get-seq-dict ref-file))]
              (with-open [bed-source (get-bed-source x)]
                (-&gt;&gt; bed-source
                     .iterator
                     (map #(.createGenomeLoc parser %))
                     doall))))
          (merge-intervals [x y]
            (IntervalUtils/mergeListsBySetOperator (genome-loc-list x)
                                                   (genome-loc-list y)
                                                   IntervalSetRule/INTERSECTION))]
    (with-open [bed-source (get-bed-source total-bed)]
      (let [total (count-bases (.iterator bed-source))
            compared (if (nil? call-bed) total
                         (count-bases (merge-intervals total-bed call-bed)))]
        {:percent (* 100.0 (/ compared total))
         :compared compared
         :total total}))))</pre></td></tr><tr><td class="docs"><p>Collect summary metrics for concordant/discordant and phasing calls</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-phasing-metrics
  [vc-info exp-interval-file call-interval-file ref-file]
  (letfn [(count-nomatch-het-alt [xs]
            (count (filter #(and (contains? #{:concordant :ref-concordant} (:comparison %))
                                 (:nomatch-het-alt %))
                           (flatten vc-info))))
          (blank-count-dict []
            {:snp 0 :indel 0})
          (add-current-count [coll x]
            (let [cur-val (map x [:comparison :variant-type])]
              (assoc-in coll cur-val (inc (get-in coll cur-val)))))]
    (reduce add-current-count
            {:haplotype-blocks (count vc-info)
             :total-bases (count-comparison-bases exp-interval-file call-interval-file ref-file)
             :nonmatch-het-alt (count-nomatch-het-alt vc-info)
             :concordant (blank-count-dict)
             :ref-concordant (blank-count-dict)
             :discordant (blank-count-dict)
             :phasing-error (blank-count-dict)}
            (flatten vc-info))))</pre></td></tr><tr><td class="docs"><p>Compare two VCF files including phasing with a haplotype reference.</p>
</td><td class="codes"><pre class="brush: clojure">(defn compare-two-vcf-phased
  [call ref exp config]
  (with-open [ref-vcf-s (get-vcf-source (:file ref) (:ref exp))
              call-vcf-s (get-vcf-source (:file call) (:ref exp))]
    (let [compared-calls (score-phased-calls call-vcf-s ref-vcf-s)]
      {:c-files (write-concordance-output compared-calls (:sample exp) call
                                          (get-in config [:dir :out]) (:ref exp))
       :metrics (get-phasing-metrics compared-calls (:intervals exp) (:intervals call) (:ref exp)) 
       :c1 call :c2 ref :sample (:sample exp)})))</pre></td></tr><tr><td class="docs"><h2>Utility functions</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Is the provided VCF file a haploid genome (one genotype or all homozygous)</p>
</td><td class="codes"><pre class="brush: clojure">(defn is-haploid?
  [vcf-file ref-file]
  (letfn [(is-vc-haploid? [vc]
            (or (= 1 (apply max (map #(count (:alleles %)) (:genotypes vc))))
                (contains? #{&quot;HOM_REF&quot; &quot;HOM_VAR&quot;} (:type vc))))]
    (with-open [vcf-source (get-vcf-source vcf-file ref-file)]
      (every? is-vc-haploid? (parse-vcf vcf-source)))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.report" name="bcbio.variation.report"><h1 class="project-name">bcbio.variation.report</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Parse and provide detailed information from GATKReport outputs.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.report
  (:import [org.broadinstitute.sting.gatk.report GATKReport])
  (:use [ordered.map :only [ordered-map]]
        [clojure.math.combinatorics :only [cartesian-product]]
        [bcbio.variation.variantcontext :only [parse-vcf get-vcf-retriever
                                               get-vcf-source]]
        [bcbio.variation.callable :only [callable-checker]]
        [bcbio.variation.metrics :only [ml-on-vcf-metrics passes-filter? nonref-passes-filter?]])
  (:require [doric.core :as doric]
            [clojure.string :as string]))</pre></td></tr><tr><td class="docs"><p>Retrieve high level concordance metrics from GATK VariantEval report.</p>
</td><td class="codes"><pre class="brush: clojure">(defn concordance-report-metrics
  [sample in-file]
  (letfn [(sample-in-row? [x]
            (and (= (:row x) sample)
                 (= (:Sample x) sample)
                 (= (:Novelty x) &quot;all&quot;)
                 (= (:Filter x) &quot;called&quot;)))]
    (let [table (-&gt; (GATKReport. in-file) (.getTable &quot;GenotypeConcordance.simplifiedStats&quot;))
          cols (rest (.getColumns table))
          headers (map #(-&gt; % (.getColumnName) keyword) cols)]
      (filter sample-in-row?
              (for [i (range (count (.values (first cols))))]
                (zipmap headers
                        (map #(nth (vec (.values %)) i) cols)))))))</pre></td></tr><tr><td class="docs"><p>Count variants that pass an optional checker function.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- count-variants
  [f ref-file check?]
  (with-open [vcf-source (get-vcf-source f ref-file)]
    (count (filter check? (parse-vcf vcf-source)))))</pre></td></tr><tr><td class="docs"><p>Provide metrics to distinguish types of discordance in a comparison.
  These identify variants which differ due to being missing in one variant
  call versus calls present in both with different genotypes.</p>
</td><td class="codes"><pre class="brush: clojure">(defn discordance-metrics
  [file1 file2 ref-file]
  (with-open [file2-source (get-vcf-source file2 ref-file)
              file1-source (get-vcf-source file1 ref-file)]
    (let [vrn-fetch (get-vcf-retriever file2-source)]
      (reduce (fn [coll vc]
                (let [other-vcs (vrn-fetch (:chr vc) (:start vc) (:end vc))
                      vc-type (if-not (empty? other-vcs) :total :unique)]
                  (assoc coll vc-type (inc (get coll vc-type)))))
              {:total 0 :unique 0}
              (parse-vcf file1-source)))))</pre></td></tr><tr><td class="docs"><p>Calculate count of variant in input file without coverage in the comparison.</p>
</td><td class="codes"><pre class="brush: clojure">(defn nocoverage-count
  [in-vcf ref-file compare-kw compared]
  (let [align-file (get-in compared [compare-kw :align]
                           (get-in compared [:exp :align]))]
    (if (nil? align-file)
      &quot;&quot;
      (let [out-dir (get-in compared [:dir :prep] (get-in compared [:dir :out]))
            [callable? call-source] (callable-checker align-file (-&gt; compared :exp :ref)
                                                      :out-dir out-dir)
            vc-callable? (fn [vc]
                           (callable? (:chr vc) (:start vc) (:end vc)))]
        (with-open [_ call-source]
          (count-variants in-vcf ref-file vc-callable?))))))</pre></td></tr><tr><td class="docs"><p>Retrieve expected summary level from configuration</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-summary-level
  [config]
  (letfn [(level-from-string [x]
            (case (when-not (nil? x) (string/lower-case x))
              &quot;quick&quot; :quick
              &quot;full&quot; :full
              :standard))
          (get-string-level [config to-try]
            (loop [cur-try to-try]
              (if (empty? cur-try) nil
                  (let [cur-level (get-in config (first cur-try))]
                    (if-not (nil? cur-level) cur-level
                            (recur (rest cur-try)))))))]
    (let [to-check (cartesian-product [:exp :c1 :c2 :call] [:summary-level])]
      (level-from-string (get-string-level config to-check)))))</pre></td></tr><tr><td class="docs"><p>Provide one-line summary of similarity metrics for a VCF comparison.</p>
</td><td class="codes"><pre class="brush: clojure">(defn top-level-metrics
  [compared]
  (let [sum-level (get-summary-level compared)
        ref-file (get-in compared [:exp :ref])]
    (letfn [(vrn-type-passes-filter [vrn-type]
              (fn [vc]
                (and (passes-filter? vc)
                     (contains? vrn-type (:type vc)))))
            (all-vrn-counts [fname cmp-kw compared]
              (let [base {:total (count-variants fname ref-file passes-filter?)}]
                (if (= sum-level :quick) base
                    (assoc base
                      :nocoverage (nocoverage-count fname ref-file cmp-kw compared)
                      :snp (count-variants fname ref-file
                                                (vrn-type-passes-filter #{&quot;SNP&quot;}))
                      :indel (count-variants fname ref-file
                                             (vrn-type-passes-filter #{&quot;INDEL&quot;}))))))]
      (let [c-files (-&gt; compared :c-files vals)
            base
            (ordered-map
             :sample (-&gt; compared :exp :sample)
             :call1 (-&gt; compared :c1 :name)
             :call2 (-&gt; compared :c2 :name)
             :genotype_concordance (-&gt; compared :metrics :percent_overall_genotype_concordance)
             :callable_concordance (-&gt; compared :callable-metrics
                                       :percent_overall_genotype_concordance)
             :nonref_discrepency (-&gt; compared :metrics :percent_non_reference_discrepancy_rate)
             :nonref_sensitivity (-&gt; compared :metrics :percent_non_reference_sensitivity)
             :concordant (all-vrn-counts (first c-files) nil compared)
             :nonref_concordant (count-variants (first c-files) ref-file
                                                nonref-passes-filter?)
             :discordant1 (all-vrn-counts (second c-files) :c2 compared)
             :discordant2 (when (&gt; (count c-files) 2) (all-vrn-counts (nth c-files 2) :c1 compared))
             :discordant_both (when (&gt; (count c-files) 2)
                                (apply discordance-metrics (conj (vec (rest c-files))
                                                                 ref-file))))]
        (if-not (= sum-level :full) base
            (assoc base
              :ml_metrics (ml-on-vcf-metrics ref-file (take 2 c-files))))))))</pre></td></tr><tr><td class="docs"><p>Calculate an overall accuracy score from input metrics.
  The accuracy logic is:
  (#correctly aligned bases / (#correctly aligned bases +
                               1*(simple substitutions and indels) +
                               2*(larger errors))).</p>
</td><td class="codes"><pre class="brush: clojure">(defn calc-accuracy
  [metrics]
  (letfn [(get-penalty [[error-type call-type]]
            (case call-type
              :snp 1
              :indel 2))]
    (let [error-items (cartesian-product [:discordant :phasing-error] [:snp :indel])
          error-score (apply + (map #(* (get-in metrics % 0) (get-penalty %)) error-items))
          total-bases (get-in metrics [:total-bases :compared] 1)]
      (float
       (* 100.0 (/ total-bases (+ total-bases error-score)))))))</pre></td></tr><tr><td class="docs"><p>Summary table of high level variables and scoring metrics for comparison.</p>
</td><td class="codes"><pre class="brush: clojure">(defn prep-scoring-table
  [metrics]
  (let [to-write (ordered-map :accuracy &quot;Overall accuracy score&quot;
                              [:total-bases :percent] &quot;Percentage of bases compared&quot;
                              [:total-bases :compared] &quot;Total bases compared&quot;
                              [:total-bases :total] &quot;Possible evaluation bases&quot;
                              [:discordant :snp] &quot;Discordant SNPs&quot;
                              [:discordant :indel] &quot;Discordant indels&quot;
                              [:phasing-error :snp] &quot;Phasing Error SNPs&quot;
                              [:phasing-error :indel] &quot;Phasing Error indels&quot;
                              :haplotype-blocks &quot;Phased haplotype blocks&quot;
                              :nonmatch-het-alt &quot;Non-matching heterozygous alternative alleles&quot;)
        s-metrics (assoc metrics :accuracy (calc-accuracy metrics))
        need-percent #{:accuracy [:total-bases :percent]}]
    (letfn [(prep-row [[k x]]
              (let [val (if (coll? k) (get-in s-metrics k) (get s-metrics k))]
                {:metric x
                 :value (if (contains? need-percent k) (format &quot;%.2f&quot; val) val)}))]
      (map prep-row to-write))))</pre></td></tr><tr><td class="docs"><p>Write high level metrics table in readable format.</p>
</td><td class="codes"><pre class="brush: clojure">(defn write-scoring-table
  [metrics wrtr]
  (when-not (nil? metrics)
    (.write wrtr (str (doric/table [:metric :value] (prep-scoring-table metrics))
                      &quot;\n&quot;))))</pre></td></tr><tr><td class="docs"><p>Summary table of metrics for assessing the score of a variant comparison.</p>
</td><td class="codes"><pre class="brush: clojure">(defn write-concordance-metrics
  [metrics wrtr]
  (let [to-write (ordered-map :genotype_concordance &quot;Overall genotype concordance&quot;
                              :callable_concordance &quot;Callable genotype concordance&quot;
                              :nonref_discrepency &quot;Non-reference discrepancy rate&quot;
                              :nonref_sensitivity &quot;Non-reference sensitivity&quot;
                              [:concordant :total] &quot;Total concordant&quot;
                              :nonref_concordant &quot;Non-reference concordant count&quot;
                              [:discordant_both :total] &quot;Shared discordant&quot;
                              [:concordant :snp] &quot;Concordant SNPs&quot;
                              [:concordant :indel] &quot;Concordant indels&quot;
                              [:discordant1 :total] (str &quot;Discordant total: &quot; (:call1 metrics))
                              [:discordant1 :nocoverage]  (str &quot;Discordant unique: &quot;
                                                               (:call1 metrics))
                              [:discordant1 :snp] (str &quot;Discordant SNPs: &quot; (:call1 metrics))
                              [:discordant1 :indel] (str &quot;Discordant indels: &quot; (:call1 metrics))
                              [:discordant2 :total] (str &quot;Discordant total: &quot; (:call2 metrics))
                              [:discordant2 :nocoverage]  (str &quot;Discordant unique: &quot;
                                                               (:call2 metrics))
                              [:discordant2 :snp] (str &quot;Discordant SNPs: &quot; (:call2 metrics))
                              [:discordant2 :indel] (str &quot;Discordant indels: &quot; (:call2 metrics))
                              [:ml_metrics :top-metrics] &quot;Classification metrics&quot;)]
    (letfn [(get-value [[k metric]]
              (let [val (if (coll? k) (get-in metrics k) (get metrics k))]
                {:metric metric :value val}))]
      (.write wrtr (str (doric/table [:metric :value] (map get-value to-write))
                        &quot;\n&quot;)))))</pre></td></tr><tr><td class="docs"><h2>Classification metrics</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Summary table of classification metrics from GATK variant recalibration.</p>
</td><td class="codes"><pre class="brush: clojure">(defn write-classification-metrics
  [cmp-info wrtr]
  (letfn [(get-metric-counts [in-vcf]
            (with-open [vcf-source (get-vcf-source in-vcf (get-in cmp-info [:exp :ref]))]
              (reduce (fn [coll vc]
                        (let [culprit (get-in vc [:attributes &quot;culprit&quot;])]
                          (if (or (nil? culprit) (= (count (:filters vc)) 0)) coll
                              (assoc coll culprit (inc (get coll culprit 0))))))
                      {} (parse-vcf vcf-source))))
          (get-recal-metrics [in-vcf]
            (sort-by :count &gt;
                     (map (fn [[m c]] {:metric m :count c}) (get-metric-counts in-vcf))))]
    (.write wrtr &quot;** GATK recalibration filter metrics\n&quot;)
    (doseq [call (map (partial get cmp-info) [:c1 :c2])]
      (when (= (:mod call) &quot;recal&quot;)
        (.write wrtr (str (doric/table [:metric :count]
                                       (get-recal-metrics (:file call)))
                          &quot;\n&quot;))))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.structural" name="bcbio.variation.structural"><h1 class="project-name">bcbio.variation.structural</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Handle structural variations for larger insertions, deletions and
  genome rearrangements.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.structural
  (:import [org.broadinstitute.sting.utils.codecs.vcf VCFCodec]
           [org.broadinstitute.sting.utils.variantcontext VariantContextBuilder
            Allele]
           [java.io StringReader]
           [net.sf.picard.util IntervalTree])
  (:use [bcbio.variation.variantcontext :only [get-vcf-source parse-vcf
                                               from-vc write-vcf-w-template]]
        [bcbio.variation.callable :only [get-bed-source]])
  (:require [clojure.string :as string]
            [fs.core :as fs]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><p>Determine the type of a structural variant. Expected types are:</p>

<pre><code>- DEL: Deletion
- INS: Insertion
- DUP: Duplication
- INV: Inversion
- BND: Breakpoint end; paired with second variant
- CNV: Copy number variation
- nil: Not a structural variant.
</code></pre>
</td><td class="codes"><pre class="brush: clojure">(defn get-sv-type
  [vc]
  (let [min-indel 100]
    (letfn [(max-allele-size [vc]
              (apply max (map #(.length %) (cons (:ref-allele vc) (:alt-alleles vc)))))
            (indel-type [vc]
              (if (&gt; (.length (:ref-allele vc)) 0) :DEL :INS))
            (sv-type-from-symbol [allele]
              (-&gt;&gt; allele
                   (re-find #&quot;^&lt;(\w+)(:|&gt;)&quot; )
                   second
                   keyword))
            (alt-sv-type [vc]
              (let [allele (-&gt; vc :alt-alleles first .getDisplayString)]
                (cond
                 (.startsWith allele &quot;&lt;&quot;) (sv-type-from-symbol allele)
                 (or (.contains allele &quot;[&quot;)
                     (.contains allele &quot;]&quot;)) :BND)))]
      (cond
       (and (= &quot;INDEL&quot; (:type vc))
            (&gt; (max-allele-size vc) min-indel)) (indel-type vc)
       (= &quot;SYMBOLIC&quot; (:type vc)) (alt-sv-type vc)
       :else nil))))</pre></td></tr><tr><td class="docs"><p>Check a VCF input line for identical REF and ALT calls</p>
</td><td class="codes"><pre class="brush: clojure">(defn nochange-alt?
  [line]
  (let [parts (string/split line #&quot;\t&quot;)]
    (= (nth parts 3) (nth parts 4))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn structural-vcfcodec []
  &quot;Provide VCFCodec decoder that returns structural variants.
  Check SV inputs for validity, fixing or filtering where possible.
  Fixes:
    - identical ref/alt calls: an apparent SV no-call&quot;
  (letfn [(check-sv-line [line]
            (cond
             (.startsWith line &quot;#&quot;) line
             (nochange-alt? line) nil
             :else line))]
    (proxy [VCFCodec] []
      (decode [line]
        (when-let [work-line (check-sv-line line)]
          (when-let [vc (proxy-super decode work-line)]
            vc)))
      (decodeLoc [line]
        (when-let [work-line (check-sv-line line)]
          (when-let [vc (proxy-super decode work-line)]
            vc))))))</pre></td></tr><tr><td class="docs"><p>Retrieve normalized integer values from an attribute.</p>
</td><td class="codes"><pre class="brush: clojure">(defn value-from-attr
  ([vc attr-name]
     (value-from-attr vc attr-name 0))
  ([vc attr-name attr-index]
      (-&gt; vc
          :attributes
          (get attr-name (repeat (inc attr-index) &quot;0&quot;))
          (#(if (string? %) [%] %))
          (nth attr-index)
          (Integer/parseInt)
          Math/abs)))</pre></td></tr><tr><td class="docs"><p>Parse VCF file returning structural variants with confidence intervals.
  The :out-format keyword specifies how to return the parsed structural variants:
   - :itree -- Interval tree for variant lookup by chromosome and start/end.
   - default -- List of variants (non-lazy).</p>
</td><td class="codes"><pre class="brush: clojure">(defn parse-vcf-sv
  [vcf-file ref-file &amp; {:keys [out-format interval-file]}]
  (letfn [(start-adjust [vc]
            (value-from-attr vc &quot;CIPOS&quot; 0))
          (end-adjust [vc]
            (value-from-attr vc &quot;CIEND&quot; 1))
          (updated-sv-vc [cur-vc]
            (when-let [sv-type (get-sv-type cur-vc)]
              (-&gt; cur-vc
                  (assoc :start-ci (- (:start cur-vc) (start-adjust cur-vc)))
                  (assoc :end-ci (+ (:end cur-vc) (end-adjust cur-vc)))
                  (assoc :sv-type sv-type))))
          (prep-itree [vc-iter]
            (reduce (fn [coll vc]
                      (assoc coll (:chr vc)
                             (doto (get coll (:chr vc) (IntervalTree.))
                               (.put (:start-ci vc) (inc (:end-ci vc)) vc))))
                    {} vc-iter))
          (in-intervals? [bed-source vc]
            (or (instance? StringReader bed-source)
                (not (nil? (first (.query bed-source (:chr vc) (:start-ci vc) (:end-ci vc)))))))]
    (with-open [vcf-source (get-vcf-source vcf-file ref-file :codec (structural-vcfcodec))
                bed-source (if-not (nil? interval-file) (get-bed-source interval-file)
                                   (StringReader. &quot;&quot;))]
      (let [vs-iter (filter (partial in-intervals? bed-source)
                            (keep updated-sv-vc (parse-vcf vcf-source)))]
        (case out-format
          :itree (prep-itree vs-iter)
          (vec vs-iter))))))</pre></td></tr><tr><td class="docs"><h2>Concordance checking</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Retrieve start and end with confidence intervals for a variation.
  length-fn returns the length of the item or a string for well-known items.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-ci-start-end
  [vc length-fn]
  (letfn [(get-ci-range [orig attr]
            [(- orig (value-from-attr vc attr 0))
             (+ orig (value-from-attr vc attr 1))])]
    (let [start (:start vc)
          length (length-fn vc)
          end (if (string? length) length
                  (max (+ start length) (:end vc)))]
      [(get-ci-range start &quot;CIPOS&quot;)
       (if (string? end) end
           (get-ci-range end &quot;CIEND&quot;))])))</pre></td></tr><tr><td class="docs"><p>Check if coordinates from two structural variants overlap.
  Considered an overlap if the two confidence intervals
  have shared bases.</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti sv-ends-overlap?
  (fn [[end1 end2]] (type end1)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod sv-ends-overlap? clojure.lang.PersistentVector
  [[[s1 e1] [s2 e2]]]
  (or (and (&gt;= s2 s1) (&lt;= s2 e1))
      (and (&gt;= e2 s1) (&lt;= e2 e1))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod sv-ends-overlap? java.lang.String
  [[end1 end2]]
  (= end1 end2))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- length-from-svlen [x] (value-from-attr x &quot;SVLEN&quot;))</pre></td></tr><tr><td class="docs"><p>Length of insertion variation, handling ALT allele, INSEQ
  and well-known named insertions.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- insertion-length
  [x]
  (letfn [(get-insseq [x]
            (-&gt; x :attributes (get &quot;INSSEQ&quot;)))
          (length-by-insert-name [alt-allele]
            (cond
             (.startsWith alt-allele &quot;&lt;INS:ME:&quot;) (-&gt; alt-allele
                                                     (subs 1 (dec (count alt-allele)))
                                                     (string/split #&quot;:&quot;)
                                                     last)
             :else (throw (Exception. (str &quot;Unknown insert allele&quot; alt-allele)))))
          (get-allele-insert [x]
            (let [alt-allele (-&gt; x :alt-alleles first .getDisplayString)]
              (if (.startsWith alt-allele &quot;&lt;&quot;)
                (length-by-insert-name alt-allele)
                (dec (count alt-allele)))))]
    (if-let [seq (get-insseq x)]
      (count seq)
      (get-allele-insert x))))</pre></td></tr><tr><td class="docs"><p>Length of duplication variation, handling SVLEN and END.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- duplication-length
  [x]
  (max (length-from-svlen x)
       (- (value-from-attr x &quot;END&quot;) (:start x))))</pre></td></tr><tr><td class="docs"><p>Check for concordance of variants based on reported length:
  handles deletions, inversions. insertions and duplications.
  length-fn is a custom function to retrieve the variation length.</p>
</td><td class="codes"><pre class="brush: clojure">(defn sv-len-concordant?
  [sv1 sv2 length-fn]
  (letfn []
    (every? sv-ends-overlap?
            (partition 2 (interleave (get-ci-start-end sv1 length-fn)
                                     (get-ci-start-end sv2 length-fn))))))</pre></td></tr><tr><td class="docs"><p>Check if structural variants are concordant.</p>
</td><td class="codes"><pre class="brush: clojure">(defn sv-concordant?
  [sv1 sv2]
  (and (apply = (map :sv-type [sv1 sv2]))
       (case (:sv-type sv1)
         :DEL (sv-len-concordant? sv1 sv2 length-from-svlen)
         :INS (sv-len-concordant? sv1 sv2 insertion-length)
         :INV (sv-len-concordant? sv1 sv2 length-from-svlen)
         :DUP (sv-len-concordant? sv1 sv2 duplication-length)
         :BND true
         (throw (Exception. (str &quot;Structural variant type not handled: &quot; (:sv-type sv1)))))))</pre></td></tr><tr><td class="docs"><p>Lazy sequence of items that overlap a region in a nested IntervalTree.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-itree-overlap
  [itree chrom start end]
  (letfn [(itree-seq [iter]
            (lazy-seq
             (when (.hasNext iter)
               (cons (.getValue (.next iter)) (itree-seq iter)))))]
    (-&gt; itree
        (get chrom)
        (.overlappers start end)
        itree-seq)))</pre></td></tr><tr><td class="docs"><p>Compare two structural variant files, returning variant contexts keyed by concordance.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- find-concordant-svs
  [fname1 fname2 ref interval-file]
  (let [cmp-tree (parse-vcf-sv fname2 ref :out-format :itree :interval-file interval-file)]
    (letfn [(check-sv-concordance [vc]
              (let [matches (filter (partial sv-concordant? vc)
                                    (get-itree-overlap cmp-tree (:chr vc)
                                                       (:start-ci vc) (inc (:end-ci vc))))]
              [(if (seq matches) :concordant :discordant1) (:vc vc)]))]
      (map check-sv-concordance (parse-vcf-sv fname1 ref :interval-file interval-file)))))</pre></td></tr><tr><td class="docs"><p>Compare structural variants, producing concordant and discordant outputs</p>
</td><td class="codes"><pre class="brush: clojure">(defn compare-sv
  [sample c1 c2 ref &amp; {:keys [out-dir interval-file]}]
  (let [base-out (str (fs/file (if (nil? out-dir) (fs/parent (:file c1)) out-dir)
                               (str sample &quot;-%s-%s-%s.vcf&quot;)))
        out-files {:concordant (format base-out (:name c1) (:name c2) &quot;svconcordance&quot;)
                   :discordant1 (format base-out (:name c1) (:name c2) &quot;svdiscordance&quot;)
                   :discordant2 (format base-out (:name c2) (:name c1) &quot;svdiscordance&quot;)}]
    (when (itx/needs-run? (vals out-files))
      (write-vcf-w-template (:file c1) out-files
                            (find-concordant-svs (:file c1) (:file c2) ref interval-file)
                            ref))
    out-files))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.utils.background" name="bcbio.variation.utils.background"><h1 class="project-name">bcbio.variation.utils.background</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Prepare annotated VCF files to use as background for variant calling and recalibration.
  Batch variant calling and recalibration with GATK improves resulting calls. This
  provides a ready to use set of calls to batch with a single sample using 1000 genomes data.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.utils.background
  (:use [clojure.java.io]
        [bcbio.variation.compare :only [load-config]]
        [bcbio.variation.combine :only [select-by-sample combine-variants]]
        [bcbio.variation.annotation :only [add-gatk-annotations]])
  (:require [clojure.java.shell :as shell]
            [clojure.string :as string]
            [clj-yaml.core :as yaml]
            [fs.core :as fs]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><h2>Combine and annotate VCFs</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Download BAM file and index for a sample from 1000 genomes FTP.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- download-sample-bam
  [sample ftp-config out-dir]
  (letfn [(download [url fname]
            (when-not (fs/exists? fname)
              (println &quot;Downloading&quot; url &quot;to&quot; fname)
              (shell/with-sh-dir out-dir
                (shell/sh &quot;wget&quot; &quot;-O&quot; fname url))))]
    (let [dl-url (format (:bam-url ftp-config) sample sample)
          local-file (str (fs/file out-dir (string/replace (fs/base-name dl-url) &quot;.*&quot; &quot;&quot;)))]
      (download dl-url local-file)
      (download (str dl-url &quot;.bai&quot;) (str local-file &quot;.bai&quot;))
      local-file)))</pre></td></tr><tr><td class="docs"><p>Annotate genome sample VCFs with GATK metrics.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- annotate-sample
  [sample-info ref ftp-config prep-dir out-dir]
  (let [final-file (str (fs/file out-dir (format &quot;%s-annotated.vcf&quot; (:sample sample-info))))]
    (when (itx/needs-run? final-file)
      (let [sample-bam (download-sample-bam (:sample sample-info) ftp-config prep-dir)
            ann-vcf (add-gatk-annotations (:file sample-info) sample-bam ref)]
        (fs/rename ann-vcf final-file)
        (itx/remove-path sample-bam)))
    final-file))</pre></td></tr><tr><td class="docs"><p>Combine sample VCFs split by chromosome.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- combine-samples
  [sample-info ref out-dir]
  (letfn [(combine-sample [[name xs]]
            {:sample name
             :file (combine-variants (map :file xs) ref :merge-type :full
                                     :out-dir out-dir)})]
    (map combine-sample
         (group-by :sample (flatten sample-info)))))</pre></td></tr><tr><td class="docs"><h2>Subset VCF by sample</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Download chromosome VCF from 1000 genomes for processing.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- download-chrom-vcf
  [chrom ftp-config out-dir]
  (letfn [(download-vcf [url fname]
            (println &quot;Downloading&quot; url &quot;to&quot; fname)
            (shell/with-sh-dir out-dir
              (shell/sh &quot;wget&quot; &quot;-O&quot; fname url)
              (shell/sh &quot;gunzip&quot; (str (fs/base-name fname)))))]
    (let [dl-url (format (:vcf-url ftp-config) chrom)
          local-file (str (fs/file out-dir (fs/base-name dl-url)))
          final-file (itx/remove-zip-ext local-file)]
      (when-not (fs/exists? final-file)
        (download-vcf dl-url local-file))
      final-file)))</pre></td></tr><tr><td class="docs"><p>Select samples from input 1000 genomes chromosome VCF.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- select-samples-at-chrom
  [chrom samples ref ftp-config out-dir]
  (let [sample-info (map (fn [x] {:sample x
                                  :file (str (fs/file out-dir (format &quot;%s-%s.vcf&quot; x chrom)))})
                         samples)]
    (when (apply itx/needs-run? (map :file sample-info))
      (let [chrom-vcf (download-chrom-vcf chrom ftp-config out-dir)]
        (doseq [sample samples]
          (select-by-sample sample chrom-vcf chrom ref :out-dir out-dir
                            :remove-refcalls true))
        (itx/remove-path chrom-vcf)))
    sample-info))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn make-work-dirs [config]
  (doseq [dir-name (-&gt; config :dir keys)]
    (let [cur-dir (get-in config [:dir dir-name])]
      (when-not (fs/exists? cur-dir)
        (fs/mkdirs cur-dir)))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main [config-file]
  (let [config (load-config config-file)]
    (make-work-dirs config)
    (let [prep-dir (get-in config [:dir :prep])
          samples (map #(select-samples-at-chrom % (:genomes config) (:ref config)
                                                 (:ftp config) prep-dir)
                                        (get-in config [:ftp :chromosomes]))
          combo-samples (combine-samples samples (:ref config) prep-dir)
          ann-samples (map #(annotate-sample % (:ref config) (:ftp config)
                                             prep-dir (get-in config [:dir :out]))
                           combo-samples)]
      (println ann-samples))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.utils.cgmetrics" name="bcbio.variation.utils.cgmetrics"><h1 class="project-name">bcbio.variation.utils.cgmetrics</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Add metrics from Complete Genomics masterVar file to a VCF.
  This updates a converted VCF from Complete Genomics with metrics information
  allowing assessment and filtering.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.utils.cgmetrics
  (:import [org.broadinstitute.sting.utils.variantcontext VariantContextBuilder]
           [org.broadinstitute.sting.utils.codecs.vcf VCFHeader VCFInfoHeaderLine
            VCFHeaderLineCount VCFHeaderLineType])
  (:use [clojure.java.io]
        [ordered.set :only (ordered-set)]
        [bcbio.variation.normalize :only [hg19-map]]
        [bcbio.variation.variantcontext :only [parse-vcf write-vcf-w-template
                                               get-vcf-source]])
  (:require [clojure.data.csv :as csv]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><p>Get lookup dictionary of CG variant metrics by position.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-masterVar-metrics
  [in-file]
  (letfn [(variant-score [line name]
            (let [alleles [&quot;1&quot; &quot;2&quot;]]
              (/ (apply + (map #(Float/parseFloat (get line (format &quot;allele%sVarScore%s&quot; % name)))
                               alleles))
                 (count alleles))))
          (allele-balance [line]
            (/ (Float/parseFloat (get line &quot;referenceAlleleReadCount&quot;))
               (Float/parseFloat (get line &quot;totalReadCount&quot;))))]
    (with-open [rdr (reader in-file)]
      (let [csv-iter (drop-while #(&lt; (count %) 3)
                                 (csv/read-csv rdr :separator \tab))
            header (first csv-iter)]
        (reduce (fn [coll xs]
                  (let [line (zipmap header xs)]
                    (assoc coll [(get hg19-map (get line &quot;chromosome&quot;))
                                 (inc (Integer/parseInt (get line &quot;begin&quot;)))]
                           {:depth (get line &quot;totalReadCount&quot;)
                            :qual-eaf (variant-score line &quot;EAF&quot;)
                            :qual-vaf (variant-score line &quot;VAF&quot;)
                            :ab (allele-balance line)})))
                {} (rest csv-iter))))))</pre></td></tr><tr><td class="docs"><p>Provide iterator of variants with CG metrics added</p>
</td><td class="codes"><pre class="brush: clojure">(defn- add-cgmetrics-iter
  [vcf-source metrics]
  (letfn [(update-cgmetrics [vc x]
            (-&gt; (VariantContextBuilder. (:vc vc))
                (.attributes (assoc (:attributes vc)
                               &quot;DPCALL&quot; (:depth x)
                               &quot;AB&quot; (:ab x)
                               &quot;QUALEAF&quot; (:qual-eaf x)
                               &quot;QUALVAF&quot; (:qual-vaf x)))
                .make))]
    (map (fn [vc]
           (if-let [cur-metrics (get metrics [(:chr vc) (:start vc)])]
             (update-cgmetrics vc cur-metrics)
             (:vc vc)))
         (parse-vcf vcf-source))))</pre></td></tr><tr><td class="docs"><p>Add CG metrics definitions to the VCF input header.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- add-cgmetrics-header
  [header]
  (let [new #{(VCFInfoHeaderLine. &quot;DPCALL&quot; 1
                                  VCFHeaderLineType/Integer &quot;Total depth used for calls&quot;)
              (VCFInfoHeaderLine. &quot;QUALEAF&quot; 1
                                  VCFHeaderLineType/Float
                                  &quot;Variant quality under equal allele fraction model (EAF)&quot;)
              (VCFInfoHeaderLine. &quot;QUALVAF&quot; 1
                                  VCFHeaderLineType/Float
                                  &quot;Variant quality under maximum likelihood variable allele fraction model (VAF)&quot;)
              (VCFInfoHeaderLine. &quot;AB&quot; 1
                                  VCFHeaderLineType/Float &quot;Allele Balance&quot;)}]
    (VCFHeader. (apply ordered-set (concat (.getMetaData header) new))
                (.getGenotypeSamples header))))</pre></td></tr><tr><td class="docs"><p>Add metrics from Complete Genomics masterVar file to VCF.</p>
</td><td class="codes"><pre class="brush: clojure">(defn add-cgmetrics
  [vcf-file mastervar-file ref-file &amp; {:keys [out-dir]}]
  (let [out-file (itx/add-file-part vcf-file &quot;cgmetrics&quot; out-dir)
        metrics (get-masterVar-metrics mastervar-file)]
    (with-open [vcf-source (get-vcf-source vcf-file ref-file)]
      (write-vcf-w-template vcf-file {:out out-file}
                            (add-cgmetrics-iter vcf-source metrics)
                            ref-file :header-update-fn add-cgmetrics-header))
    out-file))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.utils.popfreq" name="bcbio.variation.utils.popfreq"><h1 class="project-name">bcbio.variation.utils.popfreq</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Associate population allele frequency with a list of variants.
  Annotates the original file with population frequencies if found.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.utils.popfreq
  (:import [org.broadinstitute.sting.utils.variantcontext VariantContextBuilder])
  (:use [bcbio.variation.variantcontext :only [parse-vcf write-vcf-w-template
                                               get-vcf-source]])
  (:require [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><p>Retrieve all rsIDs from the input vcf-file</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-rsids
  [vcf-file ref]
  (with-open [vcf-source (get-vcf-source vcf-file ref)]
    (set (remove nil? (map :id (parse-vcf vcf-source))))))</pre></td></tr><tr><td class="docs"><p>Retrieve allele frequencies from population VCF for IDs of interest.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-allele-freqs
  [vcf-file ref want-ids freq-id]
  (with-open [vcf-source (get-vcf-source vcf-file ref)]
    (reduce (fn [coll vc]
              (if (and (contains? want-ids (:id vc))
                       (not (nil? (get (:attributes vc) freq-id))))
                (assoc coll (:id vc) (get (:attributes vc) freq-id))
                coll))
            {} (parse-vcf vcf-source))))</pre></td></tr><tr><td class="docs"><p>Lazy generator of variant contexts with added population frequencies.</p>
</td><td class="codes"><pre class="brush: clojure">(defn add-pop-freqs
  [vcf-source allele-freqs]
  (letfn [(update-allele-freq [vc new-freq]
            (-&gt; (VariantContextBuilder. (:vc vc))
                (.attributes (assoc (:attributes vc) &quot;AF&quot; new-freq))
                .make))]
    (remove nil?
            (map #(when-let [freq (get allele-freqs (:id %))]
                    (update-allele-freq % freq))
                 (parse-vcf vcf-source)))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main [orig-vcf pop-vcf ref-file]
  (let [freq-id &quot;AF&quot;
        out-file (itx/add-file-part orig-vcf &quot;popfreq&quot;)
        allele-freqs (get-allele-freqs pop-vcf ref-file
                                       (get-rsids orig-vcf ref-file)
                                       freq-id)]
    (with-open [vcf-source (get-vcf-source orig-vcf ref-file)]
      (write-vcf-w-template orig-vcf {:out out-file}
                            (add-pop-freqs vcf-source allele-freqs)
                            ref-file))
    out-file))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.validate" name="bcbio.variation.validate"><h1 class="project-name">bcbio.variation.validate</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Combine calls from a multiple technology comparison to produce a set of final
  variants plus a list for validation. The inputs are:
   - Target technology: The outlier technology for picking additional targets. This
     should be well understood enough to set threshold for validation.
   - Validation info: Details for prepping a set of variants for validation
      - thresholds: min and max thresholds for validation
      - approach: validation along the full range of thresholds, or validate top variants
      - count: total number of variants for validation.
  Produces:
   - Final calls
       - calls that overlap in all of the technologies
       - calls that overlap in all but the target, where the target technology quality
         is below the validation threshold.
   - Validate calls
       - calls that overlap in all but the target and fall below configurable threshold.
         These are either sampled from the distribution or picked off the top.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.validate
  (:use [ordered.map :only [ordered-map]]
        [bcbio.variation.combine :only [combine-variants]]
        [bcbio.variation.multiple :only [prep-cmp-name-lookup
                                         multiple-overlap-analysis]]
        [bcbio.variation.variantcontext :only [parse-vcf get-vcf-source
                                               write-vcf-w-template]])
  (:require [bcbio.run.broad :as broad]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><p>Base functionality for subsetting a file with SelectVariants.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- select-by-general
  [select-args ext in-vcf ref]
  (let [file-info {:out-vcf (itx/add-file-part in-vcf ext)}
        args (concat [&quot;-R&quot; ref
                      &quot;--variant&quot; in-vcf
                      &quot;-o&quot; :out-vcf]
                      select-args)]
    (broad/run-gatk &quot;SelectVariants&quot; args file-info {:out [:out-vcf]})
    (:out-vcf file-info)))</pre></td></tr><tr><td class="docs"><p>Subset a VCF file with specific hard filters.</p>
</td><td class="codes"><pre class="brush: clojure">(defn select-by-filters
  [filters in-vcf ext ref]
  (select-by-general (interleave (repeat &quot;--select_expressions&quot;) filters)
                     ext in-vcf ref))</pre></td></tr><tr><td class="docs"><h2>Validation targets by random sampling</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Subset a VCF file with a random number of variants.</p>
</td><td class="codes"><pre class="brush: clojure">(defn select-by-random
  [count in-vcf ref]
  (select-by-general [&quot;--select_random_number&quot; count] &quot;randsubset&quot; in-vcf ref))</pre></td></tr><tr><td class="docs"><p>Select set of variants to validate from total set of potentials.</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti get-to-validate
  (fn [in-vcf params ref] (keyword (get-in params [:validate :approach]))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-to-validate :random
  [in-vcf params ref]
  (select-by-random (get-in params [:validate :count]) in-vcf ref))</pre></td></tr><tr><td class="docs"><p>Provide function to extract metric used in sorting from a variant context.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- extract-sort-metrics
  [params]
  {:pre [(= 1 (count (:top-metric params)))]}
  (let [metric (get-in params [:top-metric 0 :name])
        mod (get-in params [:top-metric 0 :mod])]
    (fn [vc]
      (when-let [base (-&gt; vc :attributes (get metric) (Float/parseFloat))]
        (if mod (* mod base) base)))))</pre></td></tr><tr><td class="docs"><p>Retrieve top variants sorted by metrics of interest.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-top-variants
  [vcf-file params ref]
  (with-open [vcf-source (get-vcf-source vcf-file ref)]
    (let [metric-gettr (extract-sort-metrics (:validate params))]
      (set
       (map (juxt :chr :start)
            (take (get-in params [:validate :count])
                  (sort-by metric-gettr &gt; (parse-vcf vcf-source))))))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-to-validate :top
  [in-vcf params ref]
  (let [out-file (itx/add-file-part in-vcf &quot;topsubset&quot;)]
    (when (itx/needs-run? out-file)
      (let [to-keep (get-top-variants in-vcf params ref)]
        (with-open [vcf-source (get-vcf-source in-vcf ref)]
          (write-vcf-w-template in-vcf {:out out-file}
                                (map :vc
                                     (filter #(contains? to-keep ((juxt :chr :start) %))
                                             (parse-vcf vcf-source)))
                                ref))))
    out-file))</pre></td></tr><tr><td class="docs"><p>Prepare files of calls: finalized and validation targets.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-final-and-tovalidate
  [cmps finalizer config]
  (let [cmps-by-name (prep-cmp-name-lookup (vals cmps) :remove-mods? true
                                           :ignore #{&quot;all&quot; &quot;validate&quot;})
        ref (-&gt; cmps-by-name vals first :exp :ref)
        multi-prep (multiple-overlap-analysis cmps-by-name config (:target finalizer)
                                              :dirname &quot;validate&quot;)]
    (ordered-map
     :final (combine-variants [(:true-positives multi-prep)
                               (select-by-filters (get-in finalizer [:params :filters :keep])
                                                  (:false-negatives multi-prep) &quot;keepsubset&quot; ref)]
                              ref :merge-type :full)
     :validate (get-to-validate (select-by-filters (get-in finalizer [:params :filters :validate])
                                                   (:false-negatives multi-prep) &quot;checksubset&quot; ref)
                                (:params finalizer) ref))))</pre></td></tr><tr><td class="docs"><p>High level pipeline entry for producing final and to-validate call sets.</p>
</td><td class="codes"><pre class="brush: clojure">(defn pipeline-validate
  [cmps finalizer exp config]
  {:c-files (get-final-and-tovalidate cmps finalizer config)
   :c1 {:name (:target finalizer)}
   :c2 {:name &quot;validate&quot;}
   :exp exp :dir (:dir config)})</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.variantcontext" name="bcbio.variation.variantcontext"><h1 class="project-name">bcbio.variation.variantcontext</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Helper functions to retrieve information from GATK VariantContext
   objects, which represent variant data stored in VCF files.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.variantcontext
  (:import [org.broad.tribble.index IndexFactory]
           [org.broad.tribble.source BasicFeatureSource]
           [org.broad.tribble.readers AsciiLineReader]
           [org.broadinstitute.sting.utils.codecs.vcf VCFCodec StandardVCFWriter]
           [org.broadinstitute.sting.gatk.refdata.tracks RMDTrackBuilder]
           [org.broadinstitute.sting.gatk.arguments ValidationExclusion$TYPE])
  (:use [clojure.java.io]
        [bcbio.align.ref :only [get-seq-dict]])
  (:require [clojure.string :as string]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><h2>Represent VariantContext objects</h2>

<p>Provide simple map-based access to important attributes of
VariantContexts. There are 3 useful levels of abstraction:</p>

<ul>
<li>VariantContext: Details about a variation. This captures a
single line in a VCF file</li>
<li>Genotype: An individual genotype for a sample, at a variant position.</li>
<li>Allele: The actual alleles at a genotype.</li>
</ul>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Represent a sample genotype including alleles.
   :genotype stores the original java genotype object for direct access.</p>
</td><td class="codes"><pre class="brush: clojure">(defn from-genotype
  [g]
  {:sample-name (.getSampleName g)
   :qual (.getPhredScaledQual g)
   :type (-&gt; g .getType .name)
   :attributes (into {} (.getAttributes g))
   :alleles (vec (.getAlleles g))
   :genotype g})</pre></td></tr><tr><td class="docs"><p>Provide a top level map of information from a variant context.
   :vc stores the original java VariantContext object for direct access.</p>
</td><td class="codes"><pre class="brush: clojure">(defn from-vc
  [vc]
  {:chr (.getChr vc)
   :start (.getStart vc)
   :end (.getEnd vc)
   :id (when (.hasID vc) (.getID vc))
   :ref-allele (.getReference vc)
   :alt-alleles (.getAlternateAlleles vc)
   :type (-&gt; vc .getType .name)
   :filters (set (.getFilters vc))
   :attributes (into {} (.getAttributes vc))
   :genotypes (map from-genotype
                   (-&gt; vc .getGenotypes .toArray vec))
   :vc vc})</pre></td></tr><tr><td class="docs"><h2>Parsing VCF files</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Lazy iterator over variant contexts in the VCF source iterator.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- vcf-iterator
  [iter]
  (lazy-seq
   (when (.hasNext iter)
     (cons (from-vc (.next iter)) (vcf-iterator iter)))))</pre></td></tr><tr><td class="docs"><p>Create a Tribble FeatureSource for VCF file.
   Handles indexing and parsing of VCF into VariantContexts.
   We treat gzipped files as tabix indexed VCFs.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-vcf-source
  [in-file ref-file &amp; {:keys [ensure-safe codec]}]
  (let [cur-codec (if (nil? codec) (VCFCodec.) codec)]
    (if (.endsWith in-file &quot;.gz&quot;)
      (BasicFeatureSource/getFeatureSource in-file cur-codec false)
      (let [validate (when (false? ensure-safe)
                       ValidationExclusion$TYPE/ALLOW_SEQ_DICT_INCOMPATIBILITY)
            idx (.loadIndex (RMDTrackBuilder. (get-seq-dict ref-file) nil validate)
                            (file in-file) cur-codec)]
        (BasicFeatureSource. (.getAbsolutePath (file in-file)) idx cur-codec)))))</pre></td></tr><tr><td class="docs"><p>Indexed VCF file retrieval.
   Returns function that fetches all variants in a region (chromosome:start-end)</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-vcf-retriever
  [vcf-source]
  (fn [chr start end]
    (vcf-iterator (.query vcf-source chr start end))))</pre></td></tr><tr><td class="docs"><p>Lazy iterator of VariantContext information from VCF file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn parse-vcf
  [vcf-source]
  (vcf-iterator (.iterator vcf-source)))</pre></td></tr><tr><td class="docs"><p>Retrieve parser to do line-by-line parsing of VCF files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-vcf-line-parser
  [vcf-reader]
  (let [codec (VCFCodec.)]
    (.readHeader codec vcf-reader)
    (fn [line]
      (from-vc (.decode codec line)))))</pre></td></tr><tr><td class="docs"><p>Retrieve header from input VCF file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-vcf-header
  [vcf-file]
  (with-open [vcf-reader (AsciiLineReader. (input-stream vcf-file))]
    (.readHeader (VCFCodec.) vcf-reader)))</pre></td></tr><tr><td class="docs"><p>Retrieve a VariantContext for a single line from a VCF file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn parse-vcf-line
  [line]
  (.decode (VCFCodec.) line))</pre></td></tr><tr><td class="docs"><h2>Writing VCF files</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Write VCF output files starting with an original input template VCF.
   Handles writing to multiple VCF files simultaneously with the different
   file handles represented as keywords. This allows lazy splitting of VCF files:
   <code>vc-iter</code> is a lazy sequence of <code>(writer-keyword variant-context)</code>.
   <code>out-file-map</code> is a map of writer-keywords to output filenames.</p>
</td><td class="codes"><pre class="brush: clojure">(defn write-vcf-w-template
  [tmpl-file out-file-map vc-iter ref &amp; {:keys [header-update-fn]}]
  (letfn [(make-vcf-writer [f ref]
            (StandardVCFWriter. (file f) (get-seq-dict ref)))]
    (let [tmpl-header (get-vcf-header tmpl-file)
          writer-map (zipmap (keys out-file-map)
                             (map #(make-vcf-writer % ref) (vals out-file-map)))]
      (itx/with-open-map writer-map
        (doseq [out-vcf (vals writer-map)]
          (.writeHeader out-vcf (if-not (nil? header-update-fn)
                                  (header-update-fn tmpl-header)
                                  tmpl-header)))
        (doseq [info vc-iter]
          (let [[category vc] (if (and (coll? info) (= 2 (count info)))
                                info
                                [:out info])]
            (.add (get writer-map category) vc)))))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.vcfwalker" name="bcbio.variation.vcfwalker"><h1 class="project-name">bcbio.variation.vcfwalker</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Simple walker to parse a VCF file and display distribution of call
  quality scores</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.vcfwalker
  (:import [bcbio.variation BaseVariantWalker])
  (:use [bcbio.variation.variantcontext :only [from-vc]])
  (:require [incanter.charts :as icharts]
            [incanter.core :as icore])
  (:gen-class
   :name bcbio.variation.vcfwalker.VcfSimpleStatsWalker
   :extends bcbio.variation.BaseVariantWalker))</pre></td></tr><tr><td class="docs"><p>Retrieve VariantContexts and extract the variant quality score.</p>
</td><td class="codes"><pre class="brush: clojure">(defn -map
  [this tracker ref context]
  (if-not (nil? tracker)
    (for [vc (map from-vc
                    (.getValues tracker (.variants (.invrns this))
                                (.getLocation context)))]
      (-&gt; vc :genotypes first :qual))))</pre></td></tr><tr><td class="docs"><p>Initialize an empty list to collect our quality information</p>
</td><td class="codes"><pre class="brush: clojure">(defn -reduceInit
  [this]
  [])</pre></td></tr><tr><td class="docs"><p>Add current quality information to the collected list.</p>
</td><td class="codes"><pre class="brush: clojure">(defn -reduce
  [this cur coll]
  (if-not (nil? cur)
    (vec (flatten [coll cur]))
    coll))</pre></td></tr><tr><td class="docs"><p>Plot histogram of quality scores.</p>
</td><td class="codes"><pre class="brush: clojure">(defn -onTraversalDone
  [this result]
  (doto (icharts/histogram result
                           :x-label &quot;Variant quality&quot;
                           :nbins 50)
    (icore/save (.out this) :width 500 :height 400)))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.web.process" name="bcbio.variation.web.process"><h1 class="project-name">bcbio.variation.web.process</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Run scoring analysis, handling preparation of input files and run configuration.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.web.process
  (:import [java.util.UUID])
  (:use [clojure.java.io]
        [ring.util.response :only (response content-type)]
        [bcbio.variation.compare :only (variant-comparison-from-config)]
        [bcbio.variation.report :only (prep-scoring-table)])
  (:require [fs.core :as fs]
            [clj-yaml.core :as yaml]
            [net.cgrand.enlive-html :as html]
            [doric.core :as doric]))</pre></td></tr><tr><td class="docs"><h2>Run scoring based on inputs from web or API</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Create configuration for processing inputs using references supplied in config.</p>
</td><td class="codes"><pre class="brush: clojure">(defn create-work-config
  [in-files work-info config]
  (if-not (fs/exists? (:dir work-info))
    (fs/mkdirs (:dir work-info)))
  (let [config-file (str (fs/file (:dir work-info) &quot;process.yaml&quot;))]
    (-&gt;&gt; {:dir {:out (str (fs/file (:dir work-info) &quot;grading&quot;))
                :prep (str (fs/file (:dir work-info) &quot;grading&quot; &quot;prep&quot;))}
          :experiments [{:sample (-&gt; config :ref :sample)
                         :ref (-&gt; config :ref :genome)
                         :intervals (-&gt; config :ref :intervals)
                         :calls [{:name &quot;reference&quot;
                                  :file (-&gt; config :ref :variants)
                                  :remove-refcalls true}
                                 {:name &quot;contestant&quot;
                                  :prep true
                                  :preclean true
                                  :remove-refcalls true
                                  :file (if-let [x (:variant-file in-files)]
                                          x
                                          (-&gt; config :ref :default-compare))
                                  :intervals (if-let [x (:region-file in-files)]
                                               x
                                               (-&gt; config :ref :intervals))}]}]}
         yaml/generate-string
         (spit config-file))
    config-file))</pre></td></tr><tr><td class="docs"><p>Generate a summary table of scoring results.</p>
</td><td class="codes"><pre class="brush: clojure">(defn html-summary-table
  [comparisons]
  {:pre [(= 1 (count comparisons))]}
  (let [scoring-table (prep-scoring-table (-&gt; comparisons first :metrics))]
    (-&gt; (str (doric/table ^{:format doric/html} [:metric :value] scoring-table))
     java.io.StringReader.
     html/html-resource
     (html/transform [:table] (html/set-attr :class &quot;table table-condensed&quot;)))))</pre></td></tr><tr><td class="docs"><p>Generate summary of scoring results for display.</p>
</td><td class="codes"><pre class="brush: clojure">(defn html-scoring-summary
  [request comparisons]
  (let [template-dir (-&gt; request :config :dir :template)
        sum-table (html-summary-table comparisons)]
    (html/transform (html/html-resource (fs/file template-dir &quot;scoresum.html&quot;))
                    [:div#score-table]
                    (html/content sum-table))))</pre></td></tr><tr><td class="docs"><p>Update main page HTML with content for scoring.</p>
</td><td class="codes"><pre class="brush: clojure">(defn scoring-html
  [request]
  (let [html-dir (-&gt; request :config :dir :html-root)
        template-dir (-&gt; request :config :dir :template)]
    (apply str (html/emit*
                (html/transform (html/html-resource (fs/file html-dir &quot;index.html&quot;))
                                [:div#main-content]
                                (-&gt; (fs/file template-dir &quot;score.html&quot;)
                                    html/html-resource
                                    (html/select [:body])
                                    first
                                    html/content))))))</pre></td></tr><tr><td class="docs"><p>Run scoring analysis from details provided in current session.</p>
</td><td class="codes"><pre class="brush: clojure">(defn run-scoring
  [request]
  (let [process-config (create-work-config (-&gt; request :session :in-files)
                                           (-&gt; request :session :work-info)
                                           (:config request))
        comparisons (variant-comparison-from-config process-config)]
    (apply str (html/emit*
                (html-scoring-summary request comparisons)))))</pre></td></tr><tr><td class="docs"><p>Download form-supplied input files and prep directory for scoring analysis.</p>
</td><td class="codes"><pre class="brush: clojure">(defn prep-scoring
  [request]
  (letfn [(prep-tmp-dir [request]
            (let [tmp-dir (-&gt; request :config :dir :work)
                  work-id (str (java.util.UUID/randomUUID))
                  cur-dir (fs/file tmp-dir work-id)]
              (fs/mkdirs cur-dir)
              {:id work-id :dir (str cur-dir)}))
          (download-file [tmp-dir request name]
            (let [cur-param (-&gt; request :params (get name))
                  out-file (fs/file tmp-dir (:filename cur-param))]
              [(keyword name) (if (&gt; (:size cur-param) 0)
                                (do
                                  (copy (:tempfile cur-param) out-file)
                                  (str out-file)))]))]
    (let [work-info (prep-tmp-dir request)
          in-files (into {} (map (partial download-file (:dir work-info) request)
                                 [&quot;variant-file&quot; &quot;region-file&quot;]))]
      (-&gt; (response (scoring-html request))
          (content-type &quot;text/html&quot;)
          (assoc :session
            (-&gt; (:session request)
                (assoc :work-info work-info)
                (assoc :in-files in-files)))))))</pre></td></tr><tr><td class="docs"><h2>File retrieval from processing</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Retrieve processed output file for web display.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-variant-file
  [request]
  (letfn [(sample-file [ext]
            (str (-&gt; request :config :ref :sample) ext))]
    (let [file-map {&quot;concordant&quot; (sample-file &quot;-contestant-concordant.vcf&quot;)
                    &quot;discordant&quot; (sample-file &quot;-contestant-discordant.vcf&quot;)
                    &quot;phasing&quot; (sample-file &quot;-contestant-phasing-error.vcf&quot;)}
          base-dir (-&gt; request :session :work-info :dir)
          work-dir (if-not (nil? base-dir) (fs/file base-dir &quot;grading&quot;))
          name (get file-map (-&gt; request :params :name))
          fname (if-not (or (nil? work-dir)
                            (nil? name)) (str (fs/file work-dir name)))]
      (if (and (not (nil? fname)) (fs/exists? fname))
        (-&gt; (response (slurp fname))
            (content-type &quot;text/plain&quot;))
        &quot;Variant file not found&quot;))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.web.server" name="bcbio.variation.web.server"><h1 class="project-name">bcbio.variation.web.server</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Server providing routes for serving up static pages.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.web.server
  (:use [clojure.java.io]
        [ring.adapter.jetty :only (run-jetty)]
        [ring.middleware.file :only (wrap-file)]
        [ring.middleware.file-info :only (wrap-file-info)]
        [ring.middleware.params :only (wrap-params)]
        [ring.middleware.multipart-params :only (wrap-multipart-params)]
        [ring.middleware.reload :only (wrap-reload)]
        [ring.middleware.session :only (wrap-session)]
        [ring.util.response :only (file-response redirect)]
        [compojure.core :only (defroutes ANY POST GET)])
  (:require [clj-yaml.core :as yaml]
            [bcbio.variation.web.process :as web-process]))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(def ^:private config (atom nil))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defroutes app-routes
  (POST &quot;/score&quot; request web-process/prep-scoring)
  (GET &quot;/summary&quot; request web-process/run-scoring)
  (GET &quot;/scorefile/:name&quot; request web-process/get-variant-file)
  (ANY &quot;*&quot; request (file-response &quot;404.html&quot; {:root (-&gt; @config :dir :html-root)})))</pre></td></tr><tr><td class="docs"><p>Add configuration information to the current request, loaded from input YAML file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn wrap-add-config
  [handler]
  (fn [request]
    (handler (assoc request :config @config))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn app []
  (-&gt; app-routes
      (wrap-reload '(web-process))
      (wrap-file (-&gt; @config :dir :html-root))
      wrap-file-info
      wrap-session
      wrap-params
      wrap-multipart-params
      wrap-add-config))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main
  ([config-file]
     (-main config-file &quot;8080&quot;))
  ([config-file port]
     (reset! config (-&gt; config-file slurp yaml/parse-string))
     (println (str &quot;Running server on http://localhost:&quot; port))
     (run-jetty (app) {:join? false :port (Integer/parseInt port)})))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.score" name="bcbio.variation.score"><h1 class="project-name">bcbio.variation.score</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Interactive functionality for scoring based web pages.</p>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.score
  (:require [goog.dom :as dom]
            [goog.net.XhrIo :as xhr]))</pre></td></tr><tr><td class="docs"><p>Run scoring and fetch results</p>
</td><td class="codes"><pre class="brush: clojure">(defn ^:export run
  []
  (xhr/send &quot;/summary&quot;
            (fn [x]
              (set! (.-innerHTML (dom/getElement &quot;scoring-summary&quot;))
                    (-&gt; x .-target .getResponseText)))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr></table><div class="footer">Generated by <a href="https://github.com/fogus/marginalia">Marginalia</a>.&nbsp;&nbsp;Syntax highlighting provided by Alex Gorbatchev's <a href="http://alexgorbatchev.com/SyntaxHighlighter/">SyntaxHighlighter</a></div><script type="text/javascript">SyntaxHighlighter.defaults['gutter'] = false;
       SyntaxHighlighter.all()</script></body></html>